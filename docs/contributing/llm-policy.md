# LLM Usage Policy

We're not against using AI tools. They can be genuinely helpful for drafting code, catching bugs, or exploring ideas. What we don't want is the obvious copy-paste output that hasn't been reviewed, understood, or adapted to our project.

You can tell when something was generated by an LLM and submitted without a second thought. The overly formal language, the generic explanations that don't quite fit the context, the boilerplate comments that add nothing, the solutions that technically work but ignore our existing patterns. That's what we're trying to avoid.

If you use an LLM to help with your contribution, that's fine. Just make sure you actually read what it produced, verify it works, check it follows our coding standards, and adjust it to match how we do things here. Add your own context. Remove the fluff. Make it yours.

The same goes for issues. Don't submit LLM-generated bug reports or feature requests that are verbose, generic, and obviously haven't been thought through. If an AI helped you articulate something, great, but the issue should still sound like it came from someone who actually encountered a problem or has a real use case.

We value contributions from humans who understand what they're submitting, even if they had some algorithmic assistance along the way. The goal is quality and genuine engagement with the project, not quantity of AI-generated content.
