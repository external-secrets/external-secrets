{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction External Secrets Operator is a Kubernetes operator that integrates external secret management systems like AWS Secrets Manager , HashiCorp Vault , Google Secrets Manager , Azure Key Vault and many more. The operator reads information from external APIs and automatically injects the values into a Kubernetes Secret . What is the goal of External Secrets Operator? The goal of External Secrets Operator is to synchronize secrets from external APIs into Kubernetes. ESO is a collection of custom API resources - ExternalSecret , SecretStore and ClusterSecretStore that provide a user-friendly abstraction for the external API that stores and manages the lifecycle of the secrets for you. Where to get started To get started, please read through API overview this should give you a high-level overview to understand the API and use-cases. After that please follow one of our guides to get a jump start using the operator. See our getting started guide for installation instructions. For a complete reference of the API types please refer to our API Reference . How to get involved This project is driven by it's users and contributors and we welcome everybody to get involved. Join our meetings, open issues or ask questions in Slack. The success of this project depends on your input: No contribution is too small - even opinions matter! How to get involved: Bi-weekly Development Meeting every odd week at 5:30 PM Berlin Time ( agenda , jitsi call ) Kubernetes Slack #external-secrets Contributing Process Twitter Kicked off by Sponsored by","title":"Introduction"},{"location":"#introduction","text":"External Secrets Operator is a Kubernetes operator that integrates external secret management systems like AWS Secrets Manager , HashiCorp Vault , Google Secrets Manager , Azure Key Vault and many more. The operator reads information from external APIs and automatically injects the values into a Kubernetes Secret .","title":"Introduction"},{"location":"#what-is-the-goal-of-external-secrets-operator","text":"The goal of External Secrets Operator is to synchronize secrets from external APIs into Kubernetes. ESO is a collection of custom API resources - ExternalSecret , SecretStore and ClusterSecretStore that provide a user-friendly abstraction for the external API that stores and manages the lifecycle of the secrets for you.","title":"What is the goal of External Secrets Operator?"},{"location":"#where-to-get-started","text":"To get started, please read through API overview this should give you a high-level overview to understand the API and use-cases. After that please follow one of our guides to get a jump start using the operator. See our getting started guide for installation instructions. For a complete reference of the API types please refer to our API Reference .","title":"Where to get started"},{"location":"#how-to-get-involved","text":"This project is driven by it's users and contributors and we welcome everybody to get involved. Join our meetings, open issues or ask questions in Slack. The success of this project depends on your input: No contribution is too small - even opinions matter! How to get involved: Bi-weekly Development Meeting every odd week at 5:30 PM Berlin Time ( agenda , jitsi call ) Kubernetes Slack #external-secrets Contributing Process Twitter","title":"How to get involved"},{"location":"#kicked-off-by","text":"","title":"Kicked off by"},{"location":"#sponsored-by","text":"","title":"Sponsored by"},{"location":"deprecation-policy/","text":"Deprecation Policy We follow the Kubernetes Deprecation Policy and API Versioning Scheme : alpha, beta, GA. The project is currently in beta state. Please try the beta features and provide feedback. After the features exits beta, it may not be practical to make more changes. alpha The support for a feature may be dropped at any time without notice. The API may change in incompatible ways in a later software release without notice. The software is recommended for use only in short-lived testing clusters, due to increased risk of bugs and lack of long-term support. beta The software is well tested. Enabling a feature is considered safe. Features are enabled by default. The support for a feature will not be dropped, though the details may change. The schema and/or semantics of objects may change in incompatible ways in a subsequent beta or stable release. When this happens, migration instructions are provided. Schema changes may require deleting, editing, and re-creating API objects. The editing process may not be straightforward. The migration may require downtime for applications that rely on the feature. The software is not recommended for production uses. Subsequent releases may introduce incompatible changes. If you have multiple clusters which can be upgraded independently, you may be able to relax this restriction. GA The stable versions of features appear in released software for many subsequent versions. Use it in production ;) API Surface We define the following scope that is covered by our deprecation policy. We follow the 9 Rules of the Kuberenetes Deprecation Policy . Scope API Objects and fields: .Spec , .Status and .Status.Conditions[] Enums and constant values Controller Configuration: CLI flags & environment variables Metrics as defined in the Kubernetes docs a feature or specific behavior: ExternalSecret update mechanics Non-Scope We do not provide stability guarantee for source code imports . The Interfaces and the behavior will change in a unexpected and backwards-incompatible way. However, The maintained helm chart is not part of this deprecation policy.","title":"Deprecation Policy"},{"location":"deprecation-policy/#deprecation-policy","text":"We follow the Kubernetes Deprecation Policy and API Versioning Scheme : alpha, beta, GA. The project is currently in beta state. Please try the beta features and provide feedback. After the features exits beta, it may not be practical to make more changes. alpha The support for a feature may be dropped at any time without notice. The API may change in incompatible ways in a later software release without notice. The software is recommended for use only in short-lived testing clusters, due to increased risk of bugs and lack of long-term support. beta The software is well tested. Enabling a feature is considered safe. Features are enabled by default. The support for a feature will not be dropped, though the details may change. The schema and/or semantics of objects may change in incompatible ways in a subsequent beta or stable release. When this happens, migration instructions are provided. Schema changes may require deleting, editing, and re-creating API objects. The editing process may not be straightforward. The migration may require downtime for applications that rely on the feature. The software is not recommended for production uses. Subsequent releases may introduce incompatible changes. If you have multiple clusters which can be upgraded independently, you may be able to relax this restriction. GA The stable versions of features appear in released software for many subsequent versions. Use it in production ;)","title":"Deprecation Policy"},{"location":"deprecation-policy/#api-surface","text":"We define the following scope that is covered by our deprecation policy. We follow the 9 Rules of the Kuberenetes Deprecation Policy .","title":"API Surface"},{"location":"deprecation-policy/#scope","text":"API Objects and fields: .Spec , .Status and .Status.Conditions[] Enums and constant values Controller Configuration: CLI flags & environment variables Metrics as defined in the Kubernetes docs a feature or specific behavior: ExternalSecret update mechanics","title":"Scope"},{"location":"deprecation-policy/#non-scope","text":"We do not provide stability guarantee for source code imports . The Interfaces and the behavior will change in a unexpected and backwards-incompatible way. However, The maintained helm chart is not part of this deprecation policy.","title":"Non-Scope"},{"location":"eso-blogs/","text":"ESO Blogs A list of blogs written by people all over the community. Feel free to let us know if you are writing about ESO at some place! We would be happy to mention you here! Comparing External Secrets Operator with Secret Storage CSI as Kubernetes External Secrets is Deprecated @riddle writes about choosing ESO when comparing with Secret Store CSI Driver in their specific use case. They show us the relevant differences between the projects when looking at their scenario and requirements while integrating with ArgoCD. Comparing External Secrets Operator with Secret Storage CSI as Kubernetes External Secrets is Deprecated Tutorial: Getting Started with External Secrets Operator on Kubernetes using AWS Secrets Manager Puru writes about getting started using ESO with AWS Secrets Manager. He uses illustrations to explain ESO to new users and get's you to quickly start using ESO, as article is easy to follow along. Getting Started with External Secrets Operator on Kubernetes using AWS Secrets Manager Tutorial: How to Set External-Secrets with Azure KeyVault Gustavo writes about how to setup ESO with Azure Key Vault and adds an guide on how to make it a bit more secure with OPA (Open Policy Agent). How to Set External-Secrets with Azure KeyVault Tutorial: How to Set External-Secrets with GCP Secret Manager Gustavo writes about how to setup ESO with GCP Secret Manager. He also shows you how to make a simple multi tenant setup with a ClusterSecretStore. How to Set External-Secrets with GCP Secret Manager Tutorial: How to Set External-Secrets with Hashicorp Vault Gustavo writes about how to setup ESO with Hashicorp Vault. He also shows you how to make this scale with multiple replicas of the operator and leader election enabled to lead balance handling synchronization work. How to Set External-Secrets with Hashicorp Vault Tutorial: How to Set External-Secrets with AWS Gustavo writes about how to setup ESO with AWS Secrets Manager. He also shows you how to limit access and give granular permissions with better policies and roles for your service accounts to use. How to Set External-Secrets with AWS Tutorial: How to Set External-Secrets with IBM Secrets Manager In this multi-articles series, Xavier writes about how to setup ESO with IBM Secrets Manager using the web user-interface. Xavier also shares how it is integrated into his pipeline scripts. How to Set External-Secrets with IBM Secrets Manager Kubernetes Hardening Tutorial Part 2: Network Tiexin Guo Writes about Kubernetes hardening in this series of blogs. He mentions ESO as one of the convenient options when dealing with secrets in Kubernetes, and how to use it with AWS Secret Manager using AWS credentials. Kubernetes Hardening Tutorial Part 2: Network Tutorial: How to manage secrets in OpenShift using Vault and External Secrets Operator Balkrishna Pandey published a video tutorial and a blog post on integrating HashiCorp Vault and External Secret Operator (ESO) to manage application secrets on OpenShift Cluster. In this blog, he demonstrates the strength of the ClusterSecretStore functionality, a cluster scoped SecretStore and is global to the Cluster that all ExternalSecrets can reference from all namespaces. Tutorial: Leverage AWS secrets stores from EKS Fargate with External Secrets Operator In this AWS Containers blog post, Ryan writes about how to leverage External Secret Operator with an EKS Fargate cluster using IAM Roles for Service Accounts (IRSA). This setup supports the requirements of Fargate based workloads. Leverage AWS secrets stores from EKS Fargate with External Secrets Operator Cloud Native Secret Management with External Secrets Operator Emin writes about what problems ESO can solve and how to setup ESO on an Amazon EKS Cluster with integrations for AWS Secrets Manager using IAM Roles for Service Accounts (IRSA). In this blog post, there is also a GitHub repository with example codes for everyone to follow this demonstration.","title":"Blogs"},{"location":"eso-blogs/#eso-blogs","text":"A list of blogs written by people all over the community. Feel free to let us know if you are writing about ESO at some place! We would be happy to mention you here!","title":"ESO Blogs"},{"location":"eso-blogs/#comparing-external-secrets-operator-with-secret-storage-csi-as-kubernetes-external-secrets-is-deprecated","text":"@riddle writes about choosing ESO when comparing with Secret Store CSI Driver in their specific use case. They show us the relevant differences between the projects when looking at their scenario and requirements while integrating with ArgoCD. Comparing External Secrets Operator with Secret Storage CSI as Kubernetes External Secrets is Deprecated","title":"Comparing External Secrets Operator with Secret Storage CSI as Kubernetes External Secrets is Deprecated"},{"location":"eso-blogs/#tutorial-getting-started-with-external-secrets-operator-on-kubernetes-using-aws-secrets-manager","text":"Puru writes about getting started using ESO with AWS Secrets Manager. He uses illustrations to explain ESO to new users and get's you to quickly start using ESO, as article is easy to follow along. Getting Started with External Secrets Operator on Kubernetes using AWS Secrets Manager","title":"Tutorial: Getting Started with External Secrets Operator on Kubernetes using AWS Secrets Manager"},{"location":"eso-blogs/#tutorial-how-to-set-external-secrets-with-azure-keyvault","text":"Gustavo writes about how to setup ESO with Azure Key Vault and adds an guide on how to make it a bit more secure with OPA (Open Policy Agent). How to Set External-Secrets with Azure KeyVault","title":"Tutorial: How to Set External-Secrets with Azure KeyVault"},{"location":"eso-blogs/#tutorial-how-to-set-external-secrets-with-gcp-secret-manager","text":"Gustavo writes about how to setup ESO with GCP Secret Manager. He also shows you how to make a simple multi tenant setup with a ClusterSecretStore. How to Set External-Secrets with GCP Secret Manager","title":"Tutorial: How to Set External-Secrets with GCP Secret Manager"},{"location":"eso-blogs/#tutorial-how-to-set-external-secrets-with-hashicorp-vault","text":"Gustavo writes about how to setup ESO with Hashicorp Vault. He also shows you how to make this scale with multiple replicas of the operator and leader election enabled to lead balance handling synchronization work. How to Set External-Secrets with Hashicorp Vault","title":"Tutorial: How to Set External-Secrets with Hashicorp Vault"},{"location":"eso-blogs/#tutorial-how-to-set-external-secrets-with-aws","text":"Gustavo writes about how to setup ESO with AWS Secrets Manager. He also shows you how to limit access and give granular permissions with better policies and roles for your service accounts to use. How to Set External-Secrets with AWS","title":"Tutorial: How to Set External-Secrets with AWS"},{"location":"eso-blogs/#tutorial-how-to-set-external-secrets-with-ibm-secrets-manager","text":"In this multi-articles series, Xavier writes about how to setup ESO with IBM Secrets Manager using the web user-interface. Xavier also shares how it is integrated into his pipeline scripts. How to Set External-Secrets with IBM Secrets Manager","title":"Tutorial: How to Set External-Secrets with IBM Secrets Manager"},{"location":"eso-blogs/#kubernetes-hardening-tutorial-part-2-network","text":"Tiexin Guo Writes about Kubernetes hardening in this series of blogs. He mentions ESO as one of the convenient options when dealing with secrets in Kubernetes, and how to use it with AWS Secret Manager using AWS credentials. Kubernetes Hardening Tutorial Part 2: Network","title":"Kubernetes Hardening Tutorial Part 2: Network"},{"location":"eso-blogs/#tutorial-how-to-manage-secrets-in-openshift-using-vault-and-external-secrets-operator","text":"Balkrishna Pandey published a video tutorial and a blog post on integrating HashiCorp Vault and External Secret Operator (ESO) to manage application secrets on OpenShift Cluster. In this blog, he demonstrates the strength of the ClusterSecretStore functionality, a cluster scoped SecretStore and is global to the Cluster that all ExternalSecrets can reference from all namespaces.","title":"Tutorial: How to manage secrets in OpenShift using Vault and External Secrets Operator"},{"location":"eso-blogs/#tutorial-leverage-aws-secrets-stores-from-eks-fargate-with-external-secrets-operator","text":"In this AWS Containers blog post, Ryan writes about how to leverage External Secret Operator with an EKS Fargate cluster using IAM Roles for Service Accounts (IRSA). This setup supports the requirements of Fargate based workloads. Leverage AWS secrets stores from EKS Fargate with External Secrets Operator","title":"Tutorial: Leverage AWS secrets stores from EKS Fargate with External Secrets Operator"},{"location":"eso-blogs/#cloud-native-secret-management-with-external-secrets-operator","text":"Emin writes about what problems ESO can solve and how to setup ESO on an Amazon EKS Cluster with integrations for AWS Secrets Manager using IAM Roles for Service Accounts (IRSA). In this blog post, there is also a GitHub repository with example codes for everyone to follow this demonstration.","title":"Cloud Native Secret Management with External Secrets Operator"},{"location":"eso-demos/","text":"ESO Demos A list of demos given by people going through simple setups with ESO. Feel free to let us know if you have a demo that you want to include here! Manage Kubernetes Secrets With External Secrets Operator on DevOps Toolkit Viktor Farvik shows us how to use ESO with GCP provider and explores a simple workflow with the project. Managing Kubernetes Secrets: Comparing External Secrets Operator and Secrets Store CSI Driver Kim Schlesinger and Daniel Hix show us how to install and use both projects, comparing their features and limitations in different situations. GCP SM + AWS SM + Azure Key Vault Demo This was an old demo going through an old version of ESO. Most of it is still valid, but beware of CRD and breaking change differences. How to manage secrets in OpenShift using Vault and External Secrets Operator Balkrishna Pandey shows us here how to use ClusterSecretStore and how to integrate ESO with Hashicorp Vault on Openshift. Managing Sensitive Data in Kubernetes with Sealed Secrets and External Secrets Operator (ESO) Lukonde Mwila demonstrates how ESO works and how to fetch secrets from AWS Secrets Manager into your Kubernetes cluster. External Secrets Operator: A Cloud Native way to manage your secrets Charl Klein gives an overview of the external secrets project, and a walkthrough of getting ESO up and running with Azure Key Vault","title":"Demos"},{"location":"eso-demos/#eso-demos","text":"A list of demos given by people going through simple setups with ESO. Feel free to let us know if you have a demo that you want to include here!","title":"ESO Demos"},{"location":"eso-demos/#manage-kubernetes-secrets-with-external-secrets-operator-on-devops-toolkit","text":"Viktor Farvik shows us how to use ESO with GCP provider and explores a simple workflow with the project.","title":"Manage Kubernetes Secrets With External Secrets Operator on DevOps Toolkit"},{"location":"eso-demos/#managing-kubernetes-secrets-comparing-external-secrets-operator-and-secrets-store-csi-driver","text":"Kim Schlesinger and Daniel Hix show us how to install and use both projects, comparing their features and limitations in different situations.","title":"Managing Kubernetes Secrets: Comparing External Secrets Operator and Secrets Store CSI Driver"},{"location":"eso-demos/#gcp-sm-aws-sm-azure-key-vault-demo","text":"This was an old demo going through an old version of ESO. Most of it is still valid, but beware of CRD and breaking change differences.","title":"GCP SM + AWS SM + Azure Key Vault Demo"},{"location":"eso-demos/#how-to-manage-secrets-in-openshift-using-vault-and-external-secrets-operator","text":"Balkrishna Pandey shows us here how to use ClusterSecretStore and how to integrate ESO with Hashicorp Vault on Openshift.","title":"How to manage secrets in OpenShift using Vault and External Secrets Operator"},{"location":"eso-demos/#managing-sensitive-data-in-kubernetes-with-sealed-secrets-and-external-secrets-operator-eso","text":"Lukonde Mwila demonstrates how ESO works and how to fetch secrets from AWS Secrets Manager into your Kubernetes cluster.","title":"Managing Sensitive Data in Kubernetes with Sealed Secrets and External Secrets Operator (ESO)"},{"location":"eso-demos/#external-secrets-operator-a-cloud-native-way-to-manage-your-secrets","text":"Charl Klein gives an overview of the external secrets project, and a walkthrough of getting ESO up and running with Azure Key Vault","title":"External Secrets Operator: A Cloud Native way to manage your secrets"},{"location":"eso-talks/","text":"ESO Talks A list of talks given by people at conferences and events. Feel free to let us know if you are talking about ESO at some place! We would be happy to mention you here! Kubernetes Community Days UK CNCF Community Groups Canada Container Days Hamburg","title":"Talks"},{"location":"eso-talks/#eso-talks","text":"A list of talks given by people at conferences and events. Feel free to let us know if you are talking about ESO at some place! We would be happy to mention you here!","title":"ESO Talks"},{"location":"eso-talks/#kubernetes-community-days-uk","text":"","title":"Kubernetes Community Days UK"},{"location":"eso-talks/#cncf-community-groups-canada","text":"","title":"CNCF Community Groups Canada"},{"location":"eso-talks/#container-days-hamburg","text":"","title":"Container Days Hamburg"},{"location":"faq/","text":"Can i manually trigger a secret refresh? You can trigger a secret refresh by using kubectl or any other kubernetes api client. You just need to change an annotation, label or the spec of the resource: kubectl annotate es my-es force-sync=$(date +%s) --overwrite How do i know when my secret was last synced? Every ExternalSecret resource contains a status condition that indicates the time when the secret was last synced: kubectl get es my-external-secret -o yaml | grep condition -A 5 conditions: - lastTransitionTime: \"2022-05-21T21:02:47Z\" message: Secret was synced reason: SecretSynced status: \"True\" type: Ready Differences to csi-secret-store Please take a look at this issue comment here . How do i debug an external-secret that doesn't sync? First, check the status of the ExternalSecret resource using kubectl describe . That displays the status conditions as well as recent events. You should expect a status condition with Type=Ready , Status=True . Further you shouldn't see any events with Type=Warning . Read carefully if they exist. kubectl describe es my-external-secret [...] Status: Conditions: Last Transition Time: 2022-05-21T21:02:47Z Message: Secret was synced Reason: SecretSynced Status: True Type: Ready Refresh Time: 2022-05-21T21:06:47Z Synced Resource Version: 1-5c833527afd7ba3f426cb0082ee7e083 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning UpdateFailed 4m12s external-secrets secrets \"yyyyyyy\" already exists Normal Updated 12s (x4 over 3m12s) external-secrets Updated Secret If everything looks good you should check the corresponding secret store resource that is referenced from an ExternalSecret. Again, use kubectl describe to show status conditions and events and look for warning signs as described above. In an ideally, the store should be validated and Ready. kubectl describe css kubernetes [...] Status: Conditions: Last Transition Time: 2022-05-21T21:02:47Z Message: store validated Reason: Valid Status: True Type: Ready Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Valid 52s (x4 over 10m) cluster-secret-store store validated Normal Valid 52s (x4 over 10m) cluster-secret-store store validated If everything looks normal so far, please go ahead and ensure that the created secret has the expected value. Also, take a look at the logs of the controller. Upgrading from KES to ESO Migrating from KES to ESO is quite tricky! There is a tool we built to help users out available here , and there is a small migration procedure. There are some incompatibilities between KES to ESO, and while the tool tries to cover most of them, some of them will require manual intervention. We recommend to first convert the manifest files, and actually see if the tool provides a warning about any file needed to be changed. Beware that the tool points the SecretStores to use KES Service Account, so you'll also need to tweak that if you plan to uninstall KES after the upgrade.","title":"FAQ"},{"location":"faq/#can-i-manually-trigger-a-secret-refresh","text":"You can trigger a secret refresh by using kubectl or any other kubernetes api client. You just need to change an annotation, label or the spec of the resource: kubectl annotate es my-es force-sync=$(date +%s) --overwrite","title":"Can i manually trigger a secret refresh?"},{"location":"faq/#how-do-i-know-when-my-secret-was-last-synced","text":"Every ExternalSecret resource contains a status condition that indicates the time when the secret was last synced: kubectl get es my-external-secret -o yaml | grep condition -A 5 conditions: - lastTransitionTime: \"2022-05-21T21:02:47Z\" message: Secret was synced reason: SecretSynced status: \"True\" type: Ready","title":"How do i know when my secret was last synced?"},{"location":"faq/#differences-to-csi-secret-store","text":"Please take a look at this issue comment here .","title":"Differences to csi-secret-store"},{"location":"faq/#how-do-i-debug-an-external-secret-that-doesnt-sync","text":"First, check the status of the ExternalSecret resource using kubectl describe . That displays the status conditions as well as recent events. You should expect a status condition with Type=Ready , Status=True . Further you shouldn't see any events with Type=Warning . Read carefully if they exist. kubectl describe es my-external-secret [...] Status: Conditions: Last Transition Time: 2022-05-21T21:02:47Z Message: Secret was synced Reason: SecretSynced Status: True Type: Ready Refresh Time: 2022-05-21T21:06:47Z Synced Resource Version: 1-5c833527afd7ba3f426cb0082ee7e083 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning UpdateFailed 4m12s external-secrets secrets \"yyyyyyy\" already exists Normal Updated 12s (x4 over 3m12s) external-secrets Updated Secret If everything looks good you should check the corresponding secret store resource that is referenced from an ExternalSecret. Again, use kubectl describe to show status conditions and events and look for warning signs as described above. In an ideally, the store should be validated and Ready. kubectl describe css kubernetes [...] Status: Conditions: Last Transition Time: 2022-05-21T21:02:47Z Message: store validated Reason: Valid Status: True Type: Ready Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Valid 52s (x4 over 10m) cluster-secret-store store validated Normal Valid 52s (x4 over 10m) cluster-secret-store store validated If everything looks normal so far, please go ahead and ensure that the created secret has the expected value. Also, take a look at the logs of the controller.","title":"How do i debug an external-secret that doesn't sync?"},{"location":"faq/#upgrading-from-kes-to-eso","text":"Migrating from KES to ESO is quite tricky! There is a tool we built to help users out available here , and there is a small migration procedure. There are some incompatibilities between KES to ESO, and while the tool tries to cover most of them, some of them will require manual intervention. We recommend to first convert the manifest files, and actually see if the tool provides a warning about any file needed to be changed. Beware that the tool points the SecretStores to use KES Service Account, so you'll also need to tweak that if you plan to uninstall KES after the upgrade.","title":"Upgrading from KES to ESO"},{"location":"overview/","text":"API Overview Architecture The External Secrets Operator extends Kubernetes with Custom Resources , which define where secrets live and how to synchronize them. The controller fetches secrets from an external API and creates Kubernetes secrets . If the secret from the external API changes, the controller will reconcile the state in the cluster and update the secrets accordingly. Resource model To understand the mechanics of the operator let's start with the data model. The SecretStore references a bucket of key/value pairs. But because every external API is slightly different this bucket may be e.g. an instance of an Azure KeyVault or a AWS Secrets Manager in a certain AWS Account and region. Please take a look at the provider documentation to see what the Bucket actually maps to. SecretStore The idea behind the SecretStore resource is to separate concerns of authentication/access and the actual Secret and configuration needed for workloads. The ExternalSecret specifies what to fetch, the SecretStore specifies how to access. This resource is namespaced. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : us-east-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key The SecretStore contains references to secrets which hold credentials to access the external API. ExternalSecret An ExternalSecret declares what data to fetch. It has a reference to a SecretStore which knows how to access that data. The controller uses that ExternalSecret as a blueprint to create secrets. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property dataFrom : - extract : key : remote-key-in-the-provider ClusterSecretStore The ClusterSecretStore is a global, cluster-wide SecretStore that can be referenced from all namespaces. You can use it to provide a central gateway to your secret provider. Behavior The External Secret Operator (ESO for brevity) reconciles ExternalSecrets in the following manner: ESO uses spec.secretStoreRef to find an appropriate SecretStore . If it doesn't exist or the spec.controller field doesn't match it won't further process this ExternalSecret. ESO instanciates an external API client using the specified credentials from the SecretStore spec. ESO fetches the secrets as requested by the ExternalSecret , it will decode the secrets if required ESO creates an Kind=Secret based on the template provided by ExternalSecret.target.template . The Secret.data can be templated using the secret values from the external API. ESO ensures that the secret values stay in sync with the external API Roles and responsibilities The External Secret Operator is designed to target the following persona: Cluster Operator : The cluster operator is responsible for setting up the External Secret Operator, managing access policies and creating ClusterSecretStores. Application developer : The Application developer is responsible for defining ExternalSecrets and the application configuration Each persona will roughly map to a Kubernetes RBAC role. Depending on your environment these roles can map to a single user. Note: There is no Secret Operator that handles the lifecycle of the secret, this is out of the scope of ESO. Access Control The External Secrets Operator runs as a deployment in your cluster with elevated privileges. It will create/read/update secrets in all namespaces and has access to secrets stored in some external API. Ensure that the credentials you provide give ESO the least privilege necessary. Design your SecretStore / ClusterSecretStore carefully! Be sure to restrict access of application developers to read only certain keys in a shared environment. You should also consider using Kubernetes' admission control system (e.g. OPA or Kyverno ) for fine-grained access control. Running multiple Controller You can run multiple controllers within the cluster. One controller can be limited to only process SecretStores with a predefined spec.controller field. Testers welcome This is not widely tested. Please help us test the setup and/or document use-cases.","title":"Overview"},{"location":"overview/#api-overview","text":"","title":"API Overview"},{"location":"overview/#architecture","text":"The External Secrets Operator extends Kubernetes with Custom Resources , which define where secrets live and how to synchronize them. The controller fetches secrets from an external API and creates Kubernetes secrets . If the secret from the external API changes, the controller will reconcile the state in the cluster and update the secrets accordingly.","title":"Architecture"},{"location":"overview/#resource-model","text":"To understand the mechanics of the operator let's start with the data model. The SecretStore references a bucket of key/value pairs. But because every external API is slightly different this bucket may be e.g. an instance of an Azure KeyVault or a AWS Secrets Manager in a certain AWS Account and region. Please take a look at the provider documentation to see what the Bucket actually maps to.","title":"Resource model"},{"location":"overview/#secretstore","text":"The idea behind the SecretStore resource is to separate concerns of authentication/access and the actual Secret and configuration needed for workloads. The ExternalSecret specifies what to fetch, the SecretStore specifies how to access. This resource is namespaced. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : us-east-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key The SecretStore contains references to secrets which hold credentials to access the external API.","title":"SecretStore"},{"location":"overview/#externalsecret","text":"An ExternalSecret declares what data to fetch. It has a reference to a SecretStore which knows how to access that data. The controller uses that ExternalSecret as a blueprint to create secrets. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property dataFrom : - extract : key : remote-key-in-the-provider","title":"ExternalSecret"},{"location":"overview/#clustersecretstore","text":"The ClusterSecretStore is a global, cluster-wide SecretStore that can be referenced from all namespaces. You can use it to provide a central gateway to your secret provider.","title":"ClusterSecretStore"},{"location":"overview/#behavior","text":"The External Secret Operator (ESO for brevity) reconciles ExternalSecrets in the following manner: ESO uses spec.secretStoreRef to find an appropriate SecretStore . If it doesn't exist or the spec.controller field doesn't match it won't further process this ExternalSecret. ESO instanciates an external API client using the specified credentials from the SecretStore spec. ESO fetches the secrets as requested by the ExternalSecret , it will decode the secrets if required ESO creates an Kind=Secret based on the template provided by ExternalSecret.target.template . The Secret.data can be templated using the secret values from the external API. ESO ensures that the secret values stay in sync with the external API","title":"Behavior"},{"location":"overview/#roles-and-responsibilities","text":"The External Secret Operator is designed to target the following persona: Cluster Operator : The cluster operator is responsible for setting up the External Secret Operator, managing access policies and creating ClusterSecretStores. Application developer : The Application developer is responsible for defining ExternalSecrets and the application configuration Each persona will roughly map to a Kubernetes RBAC role. Depending on your environment these roles can map to a single user. Note: There is no Secret Operator that handles the lifecycle of the secret, this is out of the scope of ESO.","title":"Roles and responsibilities"},{"location":"overview/#access-control","text":"The External Secrets Operator runs as a deployment in your cluster with elevated privileges. It will create/read/update secrets in all namespaces and has access to secrets stored in some external API. Ensure that the credentials you provide give ESO the least privilege necessary. Design your SecretStore / ClusterSecretStore carefully! Be sure to restrict access of application developers to read only certain keys in a shared environment. You should also consider using Kubernetes' admission control system (e.g. OPA or Kyverno ) for fine-grained access control.","title":"Access Control"},{"location":"overview/#running-multiple-controller","text":"You can run multiple controllers within the cluster. One controller can be limited to only process SecretStores with a predefined spec.controller field. Testers welcome This is not widely tested. Please help us test the setup and/or document use-cases.","title":"Running multiple Controller"},{"location":"spec/","text":"Packages: external-secrets.io/v1beta1 external-secrets.io/v1beta1 Package v1beta1 contains resources for external-secrets Resource Types: AWSAuth ( Appears on: AWSProvider ) AWSAuth tells the controller how to do authentication with aws. Only one of secretRef or jwt can be specified. if none is specified the controller will load credentials using the aws sdk defaults. Field Description secretRef AWSAuthSecretRef (Optional) jwt AWSJWTAuth (Optional) AWSAuthSecretRef ( Appears on: AWSAuth ) AWSAuthSecretRef holds secret references for AWS credentials both AccessKeyID and SecretAccessKey must be defined in order to properly authenticate. Field Description accessKeyIDSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector The AccessKeyID is used for authentication secretAccessKeySecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector The SecretAccessKey is used for authentication AWSJWTAuth ( Appears on: AWSAuth ) Authenticate against AWS using service account tokens. Field Description serviceAccountRef github.com/external-secrets/external-secrets/apis/meta/v1.ServiceAccountSelector AWSProvider ( Appears on: SecretStoreProvider ) AWSProvider configures a store to sync secrets with AWS. Field Description service AWSServiceType Service defines which service should be used to fetch the secrets auth AWSAuth (Optional) Auth defines the information necessary to authenticate against AWS if not set aws sdk will infer credentials from your environment see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials role string (Optional) Role is a Role ARN which the SecretManager provider will assume region string AWS Region to be used for the provider AWSServiceType ( string alias) ( Appears on: AWSProvider ) AWSServiceType is a enum that defines the service/API that is used to fetch the secrets. Value Description \"ParameterStore\" AWSServiceParameterStore is the AWS SystemsManager ParameterStore. see: https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html \"SecretsManager\" AWSServiceSecretsManager is the AWS SecretsManager. see: https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html AkeylessAuth ( Appears on: AkeylessProvider ) Field Description secretRef AkeylessAuthSecretRef AkeylessAuthSecretRef ( Appears on: AkeylessAuth ) AkeylessAuthSecretRef AKEYLESS_ACCESS_TYPE_PARAM: AZURE_OBJ_ID OR GCP_AUDIENCE OR ACCESS_KEY OR KUB_CONFIG_NAME. Field Description accessID github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector The SecretAccessID is used for authentication accessType github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector accessTypeParam github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector AkeylessProvider ( Appears on: SecretStoreProvider ) AkeylessProvider Configures an store to sync secrets using Akeyless KV. Field Description akeylessGWApiURL string Akeyless GW API Url from which the secrets to be fetched from. authSecretRef AkeylessAuth Auth configures how the operator authenticates with Akeyless. AlibabaAuth ( Appears on: AlibabaProvider ) AlibabaAuth contains a secretRef for credentials. Field Description secretRef AlibabaAuthSecretRef AlibabaAuthSecretRef ( Appears on: AlibabaAuth ) AlibabaAuthSecretRef holds secret references for Alibaba credentials. Field Description accessKeyIDSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector The AccessKeyID is used for authentication accessKeySecretSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector The AccessKeySecret is used for authentication AlibabaProvider ( Appears on: SecretStoreProvider ) AlibabaProvider configures a store to sync secrets using the Alibaba Secret Manager provider. Field Description auth AlibabaAuth endpoint string (Optional) regionID string Alibaba Region to be used for the provider AzureAuthType ( string alias) ( Appears on: AzureKVProvider ) AuthType describes how to authenticate to the Azure Keyvault Only one of the following auth types may be specified. If none of the following auth type is specified, the default one is ServicePrincipal. Value Description \"ManagedIdentity\" Using Managed Identity to authenticate. Used with aad-pod-identity installed in the cluster. \"ServicePrincipal\" Using service principal to authenticate, which needs a tenantId, a clientId and a clientSecret. \"WorkloadIdentity\" Using Workload Identity service accounts to authenticate. AzureEnvironmentType ( string alias) ( Appears on: AzureKVProvider ) AzureEnvironmentType specifies the Azure cloud environment endpoints to use for connecting and authenticating with Azure. By default it points to the public cloud AAD endpoint. The following endpoints are available, also see here: https://github.com/Azure/go-autorest/blob/main/autorest/azure/environments.go#L152 PublicCloud, USGovernmentCloud, ChinaCloud, GermanCloud Value Description \"ChinaCloud\" \"GermanCloud\" \"PublicCloud\" \"USGovernmentCloud\" AzureKVAuth ( Appears on: AzureKVProvider ) Configuration used to authenticate with Azure. Field Description clientId github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) The Azure clientId of the service principle used for authentication. clientSecret github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) The Azure ClientSecret of the service principle used for authentication. AzureKVProvider ( Appears on: SecretStoreProvider ) Configures an store to sync secrets using Azure KV. Field Description authType AzureAuthType (Optional) Auth type defines how to authenticate to the keyvault service. Valid values are: - \u201cServicePrincipal\u201d (default): Using a service principal (tenantId, clientId, clientSecret) - \u201cManagedIdentity\u201d: Using Managed Identity assigned to the pod (see aad-pod-identity) vaultUrl string Vault Url from which the secrets to be fetched from. tenantId string (Optional) TenantID configures the Azure Tenant to send requests to. Required for ServicePrincipal auth type. environmentType AzureEnvironmentType EnvironmentType specifies the Azure cloud environment endpoints to use for connecting and authenticating with Azure. By default it points to the public cloud AAD endpoint. The following endpoints are available, also see here: https://github.com/Azure/go-autorest/blob/main/autorest/azure/environments.go#L152 PublicCloud, USGovernmentCloud, ChinaCloud, GermanCloud authSecretRef AzureKVAuth (Optional) Auth configures how the operator authenticates with Azure. Required for ServicePrincipal auth type. serviceAccountRef github.com/external-secrets/external-secrets/apis/meta/v1.ServiceAccountSelector (Optional) ServiceAccountRef specified the service account that should be used when authenticating with WorkloadIdentity. identityId string (Optional) If multiple Managed Identity is assigned to the pod, you can select the one to be used CAProvider ( Appears on: KubernetesServer , VaultProvider ) Used to provide custom certificate authority (CA) certificates for a secret store. The CAProvider points to a Secret or ConfigMap resource that contains a PEM-encoded certificate. Field Description type CAProviderType The type of provider to use such as \u201cSecret\u201d, or \u201cConfigMap\u201d. name string The name of the object located at the provider type. key string The key where the CA certificate can be found in the Secret or ConfigMap. namespace string (Optional) The namespace the Provider type is in. Can only be defined when used in a ClusterSecretStore. CAProviderType ( string alias) ( Appears on: CAProvider ) Value Description \"ConfigMap\" \"Secret\" CertAuth ( Appears on: KubernetesAuth ) Field Description clientCert github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector clientKey github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector ClusterExternalSecret ClusterExternalSecret is the Schema for the clusterexternalsecrets API. Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec ClusterExternalSecretSpec externalSecretSpec ExternalSecretSpec The spec for the ExternalSecrets to be created externalSecretName string (Optional) The name of the external secrets to be created defaults to the name of the ClusterExternalSecret namespaceSelector Kubernetes meta/v1.LabelSelector The labels to select by to find the Namespaces to create the ExternalSecrets in. refreshTime Kubernetes meta/v1.Duration The time in which the controller should reconcile it\u2019s objects and recheck namespaces for labels. status ClusterExternalSecretStatus ClusterExternalSecretConditionType ( string alias) ( Appears on: ClusterExternalSecretStatusCondition ) Value Description \"NotReady\" \"PartiallyReady\" \"Ready\" ClusterExternalSecretNamespaceFailure ( Appears on: ClusterExternalSecretStatus ) ClusterExternalSecretNamespaceFailure represents a failed namespace deployment and it\u2019s reason. Field Description namespace string Namespace is the namespace that failed when trying to apply an ExternalSecret reason string (Optional) Reason is why the ExternalSecret failed to apply to the namespace ClusterExternalSecretSpec ( Appears on: ClusterExternalSecret ) ClusterExternalSecretSpec defines the desired state of ClusterExternalSecret. Field Description externalSecretSpec ExternalSecretSpec The spec for the ExternalSecrets to be created externalSecretName string (Optional) The name of the external secrets to be created defaults to the name of the ClusterExternalSecret namespaceSelector Kubernetes meta/v1.LabelSelector The labels to select by to find the Namespaces to create the ExternalSecrets in. refreshTime Kubernetes meta/v1.Duration The time in which the controller should reconcile it\u2019s objects and recheck namespaces for labels. ClusterExternalSecretStatus ( Appears on: ClusterExternalSecret ) ClusterExternalSecretStatus defines the observed state of ClusterExternalSecret. Field Description failedNamespaces []ClusterExternalSecretNamespaceFailure (Optional) Failed namespaces are the namespaces that failed to apply an ExternalSecret provisionedNamespaces []string (Optional) ProvisionedNamespaces are the namespaces where the ClusterExternalSecret has secrets conditions []ClusterExternalSecretStatusCondition (Optional) ClusterExternalSecretStatusCondition ( Appears on: ClusterExternalSecretStatus ) Field Description type ClusterExternalSecretConditionType status Kubernetes core/v1.ConditionStatus message string (Optional) ClusterSecretStore ClusterSecretStore represents a secure external location for storing secrets, which can be referenced as part of storeRef fields. Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec SecretStoreSpec controller string (Optional) Used to select the correct KES controller (think: ingress.ingressClassName) The KES controller is instantiated with a specific controller name and filters ES based on this property provider SecretStoreProvider Used to configure the provider. Only one provider may be set retrySettings SecretStoreRetrySettings (Optional) Used to configure http retries if failed refreshInterval int (Optional) Used to configure store refresh interval in seconds. Empty or 0 will default to the controller config. status SecretStoreStatus ExternalSecret ExternalSecret is the Schema for the external-secrets API. Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec ExternalSecretSpec secretStoreRef SecretStoreRef target ExternalSecretTarget (Optional) refreshInterval Kubernetes meta/v1.Duration RefreshInterval is the amount of time before the values are read again from the SecretStore provider Valid time units are \u201cns\u201d, \u201cus\u201d (or \u201c\u00b5s\u201d), \u201cms\u201d, \u201cs\u201d, \u201cm\u201d, \u201ch\u201d May be set to zero to fetch and create it once. Defaults to 1h. data []ExternalSecretData (Optional) Data defines the connection between the Kubernetes Secret keys and the Provider data dataFrom []ExternalSecretDataFromRemoteRef (Optional) DataFrom is used to fetch all properties from a specific Provider data If multiple entries are specified, the Secret keys are merged in the specified order status ExternalSecretStatus ExternalSecretConditionType ( string alias) ( Appears on: ExternalSecretStatusCondition ) Value Description \"Deleted\" \"Ready\" ExternalSecretConversionStrategy ( string alias) ( Appears on: ExternalSecretDataRemoteRef , ExternalSecretFind ) Value Description \"Default\" \"Unicode\" ExternalSecretCreationPolicy ( string alias) ( Appears on: ExternalSecretTarget ) ExternalSecretCreationPolicy defines rules on how to create the resulting Secret. Value Description \"Merge\" Merge does not create the Secret, but merges the data fields to the Secret. \"None\" None does not create a Secret (future use with injector). \"Orphan\" Orphan creates the Secret and does not set the ownerReference. I.e. it will be orphaned after the deletion of the ExternalSecret. \"Owner\" Owner creates the Secret and sets .metadata.ownerReferences to the ExternalSecret resource. ExternalSecretData ( Appears on: ExternalSecretSpec ) ExternalSecretData defines the connection between the Kubernetes Secret key (spec.data. ) and the Provider data. Field Description secretKey string remoteRef ExternalSecretDataRemoteRef ExternalSecretDataFromRemoteRef ( Appears on: ExternalSecretSpec ) Field Description extract ExternalSecretDataRemoteRef (Optional) Used to extract multiple key/value pairs from one secret find ExternalSecretFind (Optional) Used to find secrets based on tags or regular expressions rewrite []ExternalSecretRewrite (Optional) Used to rewrite secret Keys after getting them from the secret Provider Multiple Rewrite operations can be provided. They are applied in a layered order (first to last) ExternalSecretDataRemoteRef ( Appears on: ExternalSecretData , ExternalSecretDataFromRemoteRef ) ExternalSecretDataRemoteRef defines Provider data location. Field Description key string Key is the key used in the Provider, mandatory metadataPolicy ExternalSecretMetadataPolicy (Optional) Policy for fetching tags/labels from provider secrets, possible options are Fetch, None. Defaults to None property string (Optional) Used to select a specific property of the Provider value (if a map), if supported version string (Optional) Used to select a specific version of the Provider value, if supported conversionStrategy ExternalSecretConversionStrategy (Optional) Used to define a conversion Strategy decodingStrategy ExternalSecretDecodingStrategy (Optional) Used to define a decoding Strategy ExternalSecretDecodingStrategy ( string alias) ( Appears on: ExternalSecretDataRemoteRef , ExternalSecretFind ) Value Description \"Auto\" \"Base64\" \"Base64URL\" \"None\" ExternalSecretDeletionPolicy ( string alias) ( Appears on: ExternalSecretTarget ) ExternalSecretDeletionPolicy defines rules on how to delete the resulting Secret. Value Description \"Delete\" Delete deletes the secret if all provider secrets are deleted. If a secret gets deleted on the provider side and is not accessible anymore this is not considered an error and the ExternalSecret does not go into SecretSyncedError status. \"Merge\" Merge removes keys in the secret, but not the secret itself. If a secret gets deleted on the provider side and is not accessible anymore this is not considered an error and the ExternalSecret does not go into SecretSyncedError status. \"Retain\" Retain will retain the secret if all provider secrets have been deleted. If a provider secret does not exist the ExternalSecret gets into the SecretSyncedError status. ExternalSecretFind ( Appears on: ExternalSecretDataFromRemoteRef ) Field Description path string (Optional) A root path to start the find operations. name FindName (Optional) Finds secrets based on the name. tags map[string]string (Optional) Find secrets based on tags. conversionStrategy ExternalSecretConversionStrategy (Optional) Used to define a conversion Strategy decodingStrategy ExternalSecretDecodingStrategy (Optional) Used to define a decoding Strategy ExternalSecretMetadataPolicy ( string alias) ( Appears on: ExternalSecretDataRemoteRef ) Value Description \"Fetch\" \"None\" ExternalSecretRewrite ( Appears on: ExternalSecretDataFromRemoteRef ) Field Description regexp ExternalSecretRewriteRegexp (Optional) Used to rewrite with regular expressions. The resulting key will be the output of a regexp.ReplaceAll operation. ExternalSecretRewriteRegexp ( Appears on: ExternalSecretRewrite ) Field Description source string Used to define the regular expression of a re.Compiler. target string Used to define the target pattern of a ReplaceAll operation. ExternalSecretSpec ( Appears on: ClusterExternalSecretSpec , ExternalSecret ) ExternalSecretSpec defines the desired state of ExternalSecret. Field Description secretStoreRef SecretStoreRef target ExternalSecretTarget (Optional) refreshInterval Kubernetes meta/v1.Duration RefreshInterval is the amount of time before the values are read again from the SecretStore provider Valid time units are \u201cns\u201d, \u201cus\u201d (or \u201c\u00b5s\u201d), \u201cms\u201d, \u201cs\u201d, \u201cm\u201d, \u201ch\u201d May be set to zero to fetch and create it once. Defaults to 1h. data []ExternalSecretData (Optional) Data defines the connection between the Kubernetes Secret keys and the Provider data dataFrom []ExternalSecretDataFromRemoteRef (Optional) DataFrom is used to fetch all properties from a specific Provider data If multiple entries are specified, the Secret keys are merged in the specified order ExternalSecretStatus ( Appears on: ExternalSecret ) Field Description refreshTime Kubernetes meta/v1.Time refreshTime is the time and date the external secret was fetched and the target secret updated syncedResourceVersion string SyncedResourceVersion keeps track of the last synced version conditions []ExternalSecretStatusCondition (Optional) ExternalSecretStatusCondition ( Appears on: ExternalSecretStatus ) Field Description type ExternalSecretConditionType status Kubernetes core/v1.ConditionStatus reason string (Optional) message string (Optional) lastTransitionTime Kubernetes meta/v1.Time (Optional) ExternalSecretTarget ( Appears on: ExternalSecretSpec ) ExternalSecretTarget defines the Kubernetes Secret to be created There can be only one target per ExternalSecret. Field Description name string (Optional) Name defines the name of the Secret resource to be managed This field is immutable Defaults to the .metadata.name of the ExternalSecret resource creationPolicy ExternalSecretCreationPolicy (Optional) CreationPolicy defines rules on how to create the resulting Secret Defaults to \u2018Owner\u2019 deletionPolicy ExternalSecretDeletionPolicy (Optional) DeletionPolicy defines rules on how to delete the resulting Secret Defaults to \u2018Retain\u2019 template ExternalSecretTemplate (Optional) Template defines a blueprint for the created Secret resource. immutable bool (Optional) Immutable defines if the final secret will be immutable ExternalSecretTemplate ( Appears on: ExternalSecretTarget ) ExternalSecretTemplate defines a blueprint for the created Secret resource. we can not use native corev1.Secret, it will have empty ObjectMeta values: https://github.com/kubernetes-sigs/controller-tools/issues/448 Field Description type Kubernetes core/v1.SecretType (Optional) engineVersion TemplateEngineVersion metadata ExternalSecretTemplateMetadata (Optional) data map[string]string (Optional) templateFrom []TemplateFrom (Optional) ExternalSecretTemplateMetadata ( Appears on: ExternalSecretTemplate ) ExternalSecretTemplateMetadata defines metadata fields for the Secret blueprint. Field Description annotations map[string]string (Optional) labels map[string]string (Optional) ExternalSecretValidator FakeProvider ( Appears on: SecretStoreProvider ) FakeProvider configures a fake provider that returns static values. Field Description data []FakeProviderData FakeProviderData ( Appears on: FakeProvider ) Field Description key string value string valueMap map[string]string version string FindName ( Appears on: ExternalSecretFind ) Field Description regexp string (Optional) Finds secrets base GCPSMAuth ( Appears on: GCPSMProvider ) Field Description secretRef GCPSMAuthSecretRef (Optional) workloadIdentity GCPWorkloadIdentity (Optional) GCPSMAuthSecretRef ( Appears on: GCPSMAuth ) Field Description secretAccessKeySecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) The SecretAccessKey is used for authentication GCPSMProvider ( Appears on: SecretStoreProvider ) GCPSMProvider Configures a store to sync secrets using the GCP Secret Manager provider. Field Description auth GCPSMAuth (Optional) Auth defines the information necessary to authenticate against GCP projectID string ProjectID project where secret is located GCPWorkloadIdentity ( Appears on: GCPSMAuth ) Field Description serviceAccountRef github.com/external-secrets/external-secrets/apis/meta/v1.ServiceAccountSelector clusterLocation string clusterName string clusterProjectID string GenericStore GenericStore is a common interface for interacting with ClusterSecretStore or a namespaced SecretStore. GenericStoreValidator GitlabAuth ( Appears on: GitlabProvider ) Field Description SecretRef GitlabSecretRef GitlabProvider ( Appears on: SecretStoreProvider ) Configures a store to sync secrets with a GitLab instance. Field Description url string URL configures the GitLab instance URL. Defaults to https://gitlab.com/ . auth GitlabAuth Auth configures how secret-manager authenticates with a GitLab instance. projectID string ProjectID specifies a project where secrets are located. GitlabSecretRef ( Appears on: GitlabAuth ) Field Description accessToken github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector AccessToken is used for authentication. IBMAuth ( Appears on: IBMProvider ) Field Description secretRef IBMAuthSecretRef containerAuth IBMAuthContainerAuth IBMAuthContainerAuth ( Appears on: IBMAuth ) IBM Container-based auth with IAM Trusted Profile. Field Description profile string the IBM Trusted Profile tokenLocation string Location the token is mounted on the pod iamEndpoint string IBMAuthSecretRef ( Appears on: IBMAuth ) Field Description secretApiKeySecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector The SecretAccessKey is used for authentication IBMProvider ( Appears on: SecretStoreProvider ) Configures an store to sync secrets using a IBM Cloud Secrets Manager backend. Field Description auth IBMAuth Auth configures how secret-manager authenticates with the IBM secrets manager. serviceUrl string ServiceURL is the Endpoint URL that is specific to the Secrets Manager service instance KubernetesAuth ( Appears on: KubernetesProvider ) Field Description cert CertAuth (Optional) has both clientCert and clientKey as secretKeySelector token TokenAuth (Optional) use static token to authenticate with serviceAccount github.com/external-secrets/external-secrets/apis/meta/v1.ServiceAccountSelector (Optional) points to a service account that should be used for authentication KubernetesProvider ( Appears on: SecretStoreProvider ) Configures a store to sync secrets with a Kubernetes instance. Field Description server KubernetesServer configures the Kubernetes server Address. auth KubernetesAuth Auth configures how secret-manager authenticates with a Kubernetes instance. remoteNamespace string (Optional) Remote namespace to fetch the secrets from KubernetesServer ( Appears on: KubernetesProvider ) Field Description url string (Optional) configures the Kubernetes server Address. caBundle []byte (Optional) CABundle is a base64-encoded CA certificate caProvider CAProvider (Optional) see: https://external-secrets.io/v0.4.1/spec/#external-secrets.io/v1alpha1.CAProvider NoSecretError NoSecretError shall be returned when a GetSecret can not find the desired secret. This is used for deletionPolicy. OnePasswordAuth ( Appears on: OnePasswordProvider ) OnePasswordAuth contains a secretRef for credentials. Field Description secretRef OnePasswordAuthSecretRef OnePasswordAuthSecretRef ( Appears on: OnePasswordAuth ) OnePasswordAuthSecretRef holds secret references for 1Password credentials. Field Description connectTokenSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector The ConnectToken is used for authentication to a 1Password Connect Server. OnePasswordProvider ( Appears on: SecretStoreProvider ) OnePasswordProvider configures a store to sync secrets using the 1Password Secret Manager provider. Field Description auth OnePasswordAuth Auth defines the information necessary to authenticate against OnePassword Connect Server connectHost string ConnectHost defines the OnePassword Connect Server to connect to vaults map[string]int Vaults defines which OnePassword vaults to search in which order OracleAuth ( Appears on: OracleProvider ) Field Description tenancy string Tenancy is the tenancy OCID where user is located. user string User is an access OCID specific to the account. secretRef OracleSecretRef SecretRef to pass through sensitive information. OracleProvider ( Appears on: SecretStoreProvider ) Configures an store to sync secrets using a Oracle Vault backend. Field Description region string Region is the region where vault is located. vault string Vault is the vault\u2019s OCID of the specific vault where secret is located. auth OracleAuth (Optional) Auth configures how secret-manager authenticates with the Oracle Vault. If empty, use the instance principal, otherwise the user credentials specified in Auth. OracleSecretRef ( Appears on: OracleAuth ) Field Description privatekey github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector PrivateKey is the user\u2019s API Signing Key in PEM format, used for authentication. fingerprint github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector Fingerprint is the fingerprint of the API private key. Provider Provider is a common interface for interacting with secret backends. SecretStore SecretStore represents a secure external location for storing secrets, which can be referenced as part of storeRef fields. Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec SecretStoreSpec controller string (Optional) Used to select the correct KES controller (think: ingress.ingressClassName) The KES controller is instantiated with a specific controller name and filters ES based on this property provider SecretStoreProvider Used to configure the provider. Only one provider may be set retrySettings SecretStoreRetrySettings (Optional) Used to configure http retries if failed refreshInterval int (Optional) Used to configure store refresh interval in seconds. Empty or 0 will default to the controller config. status SecretStoreStatus SecretStoreConditionType ( string alias) ( Appears on: SecretStoreStatusCondition ) Value Description \"Ready\" SecretStoreProvider ( Appears on: SecretStoreSpec ) SecretStoreProvider contains the provider-specific configration. Field Description aws AWSProvider (Optional) AWS configures this store to sync secrets using AWS Secret Manager provider azurekv AzureKVProvider (Optional) AzureKV configures this store to sync secrets using Azure Key Vault provider akeyless AkeylessProvider (Optional) Akeyless configures this store to sync secrets using Akeyless Vault provider vault VaultProvider (Optional) Vault configures this store to sync secrets using Hashi provider gcpsm GCPSMProvider (Optional) GCPSM configures this store to sync secrets using Google Cloud Platform Secret Manager provider oracle OracleProvider (Optional) Oracle configures this store to sync secrets using Oracle Vault provider ibm IBMProvider (Optional) IBM configures this store to sync secrets using IBM Cloud provider yandexcertificatemanager YandexCertificateManagerProvider (Optional) YandexCertificateManager configures this store to sync secrets using Yandex Certificate Manager provider yandexlockbox YandexLockboxProvider (Optional) YandexLockbox configures this store to sync secrets using Yandex Lockbox provider gitlab GitlabProvider (Optional) Gitlab configures this store to sync secrets using Gitlab Variables provider alibaba AlibabaProvider (Optional) Alibaba configures this store to sync secrets using Alibaba Cloud provider onepassword OnePasswordProvider (Optional) OnePassword configures this store to sync secrets using the 1Password Cloud provider webhook WebhookProvider (Optional) Webhook configures this store to sync secrets using a generic templated webhook kubernetes KubernetesProvider (Optional) Kubernetes configures this store to sync secrets using a Kubernetes cluster provider fake FakeProvider (Optional) Fake configures a store with static key/value pairs senhasegura SenhaseguraProvider (Optional) Senhasegura configures this store to sync secrets using senhasegura provider SecretStoreRef ( Appears on: ExternalSecretSpec ) SecretStoreRef defines which SecretStore to fetch the ExternalSecret data. Field Description name string Name of the SecretStore resource kind string (Optional) Kind of the SecretStore resource (SecretStore or ClusterSecretStore) Defaults to SecretStore SecretStoreRetrySettings ( Appears on: SecretStoreSpec ) Field Description maxRetries int32 retryInterval string SecretStoreSpec ( Appears on: ClusterSecretStore , SecretStore ) SecretStoreSpec defines the desired state of SecretStore. Field Description controller string (Optional) Used to select the correct KES controller (think: ingress.ingressClassName) The KES controller is instantiated with a specific controller name and filters ES based on this property provider SecretStoreProvider Used to configure the provider. Only one provider may be set retrySettings SecretStoreRetrySettings (Optional) Used to configure http retries if failed refreshInterval int (Optional) Used to configure store refresh interval in seconds. Empty or 0 will default to the controller config. SecretStoreStatus ( Appears on: ClusterSecretStore , SecretStore ) SecretStoreStatus defines the observed state of the SecretStore. Field Description conditions []SecretStoreStatusCondition (Optional) SecretStoreStatusCondition ( Appears on: SecretStoreStatus ) Field Description type SecretStoreConditionType status Kubernetes core/v1.ConditionStatus reason string (Optional) message string (Optional) lastTransitionTime Kubernetes meta/v1.Time (Optional) SecretsClient SecretsClient provides access to secrets. SenhaseguraAuth ( Appears on: SenhaseguraProvider ) SenhaseguraAuth tells the controller how to do auth in senhasegura Field Description clientId string clientSecretSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector SenhaseguraModuleType ( string alias) ( Appears on: SenhaseguraProvider ) SenhaseguraModuleType enum defines senhasegura target module to fetch secrets Value Description \"DSM\" SenhaseguraModuleDSM is the senhasegura DevOps Secrets Management module see: https://senhasegura.com/devops SenhaseguraProvider ( Appears on: SecretStoreProvider ) SenhaseguraProvider setup a store to sync secrets with senhasegura Field Description url string URL of senhasegura module SenhaseguraModuleType Module defines which senhasegura module should be used to get secrets auth SenhaseguraAuth Auth defines parameters to authenticate in senhasegura ignoreSslCertificate bool IgnoreSslCertificate defines if SSL certificate must be ignored TemplateEngineVersion ( string alias) ( Appears on: ExternalSecretTemplate ) Value Description \"v1\" \"v2\" TemplateFrom ( Appears on: ExternalSecretTemplate ) Field Description configMap TemplateRef secret TemplateRef TemplateRef ( Appears on: TemplateFrom ) Field Description name string items []TemplateRefItem TemplateRefItem ( Appears on: TemplateRef ) Field Description key string TokenAuth ( Appears on: KubernetesAuth ) Field Description bearerToken github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector ValidationResult ( byte alias) Value Description 2 Error indicates that there is a misconfiguration. 0 Ready indicates that the client is confgured correctly and can be used. 1 Unknown indicates that the client can be used but information is missing and it can not be validated. VaultAppRole ( Appears on: VaultAuth ) VaultAppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource. Field Description path string Path where the App Role authentication backend is mounted in Vault, e.g: \u201capprole\u201d roleId string RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault. secretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The key field must be specified and denotes which entry within the Secret resource is used as the app role secret. VaultAuth ( Appears on: VaultProvider ) VaultAuth is the configuration used to authenticate with a Vault server. Only one of tokenSecretRef , appRole , kubernetes , ldap , jwt or cert can be specified. Field Description tokenSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) TokenSecretRef authenticates with Vault by presenting a token. appRole VaultAppRole (Optional) AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource. kubernetes VaultKubernetesAuth (Optional) Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server. ldap VaultLdapAuth (Optional) Ldap authenticates with Vault by passing username/password pair using the LDAP authentication method jwt VaultJwtAuth (Optional) Jwt authenticates with Vault by passing role and JWT token using the JWT/OIDC authentication method cert VaultCertAuth (Optional) Cert authenticates with TLS Certificates by passing client certificate, private key and ca certificate Cert authentication method VaultCertAuth ( Appears on: VaultAuth ) VaultJwtAuth authenticates with Vault using the JWT/OIDC authentication method, with the role name and token stored in a Kubernetes Secret resource. Field Description clientCert github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) ClientCert is a certificate to authenticate using the Cert Vault authentication method secretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector SecretRef to a key in a Secret resource containing client private key to authenticate with Vault using the Cert authentication method VaultJwtAuth ( Appears on: VaultAuth ) VaultJwtAuth authenticates with Vault using the JWT/OIDC authentication method, with the role name and a token stored in a Kubernetes Secret resource or a Kubernetes service account token retrieved via TokenRequest . Field Description path string Path where the JWT authentication backend is mounted in Vault, e.g: \u201cjwt\u201d role string (Optional) Role is a JWT role to authenticate using the JWT/OIDC Vault authentication method secretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) Optional SecretRef that refers to a key in a Secret resource containing JWT token to authenticate with Vault using the JWT/OIDC authentication method. kubernetesServiceAccountToken VaultKubernetesServiceAccountTokenAuth (Optional) Optional ServiceAccountToken specifies the Kubernetes service account for which to request a token for with the TokenRequest API. VaultKVStoreVersion ( string alias) ( Appears on: VaultProvider ) Value Description \"v1\" \"v2\" VaultKubernetesAuth ( Appears on: VaultAuth ) Authenticate against Vault using a Kubernetes ServiceAccount token stored in a Secret. Field Description mountPath string Path where the Kubernetes authentication backend is mounted in Vault, e.g: \u201ckubernetes\u201d serviceAccountRef github.com/external-secrets/external-secrets/apis/meta/v1.ServiceAccountSelector (Optional) Optional service account field containing the name of a kubernetes ServiceAccount. If the service account is specified, the service account secret token JWT will be used for authenticating with Vault. If the service account selector is not supplied, the secretRef will be used instead. secretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) Optional secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. If a name is specified without a key, token is the default. If one is not specified, the one bound to the controller will be used. role string A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies. VaultKubernetesServiceAccountTokenAuth ( Appears on: VaultJwtAuth ) VaultKubernetesServiceAccountTokenAuth authenticates with Vault using a temporary Kubernetes service account token retrieved by the TokenRequest API. Field Description serviceAccountRef github.com/external-secrets/external-secrets/apis/meta/v1.ServiceAccountSelector Service account field containing the name of a kubernetes ServiceAccount. audiences []string (Optional) Optional audiences field that will be used to request a temporary Kubernetes service account token for the service account referenced by serviceAccountRef . Defaults to a single audience vault it not specified. Deprecated: use serviceAccountRef.Audiences instead expirationSeconds int64 (Optional) Optional expiration time in seconds that will be used to request a temporary Kubernetes service account token for the service account referenced by serviceAccountRef . Deprecated: this will be removed in the future. Defaults to 10 minutes. VaultLdapAuth ( Appears on: VaultAuth ) VaultLdapAuth authenticates with Vault using the LDAP authentication method, with the username and password stored in a Kubernetes Secret resource. Field Description path string Path where the LDAP authentication backend is mounted in Vault, e.g: \u201cldap\u201d username string Username is a LDAP user name used to authenticate using the LDAP Vault authentication method secretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector SecretRef to a key in a Secret resource containing password for the LDAP user used to authenticate with Vault using the LDAP authentication method VaultProvider ( Appears on: SecretStoreProvider ) Configures an store to sync secrets using a HashiCorp Vault KV backend. Field Description auth VaultAuth Auth configures how secret-manager authenticates with the Vault server. server string Server is the connection address for the Vault server, e.g: \u201c https://vault.example.com:8200\u201d . path string (Optional) Path is the mount path of the Vault KV backend endpoint, e.g: \u201csecret\u201d. The v2 KV secret engine version specific \u201c/data\u201d path suffix for fetching secrets from Vault is optional and will be appended if not present in specified path. version VaultKVStoreVersion Version is the Vault KV secret engine version. This can be either \u201cv1\u201d or \u201cv2\u201d. Version defaults to \u201cv2\u201d. namespace string (Optional) Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: \u201cns1\u201d. More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces caBundle []byte (Optional) PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection. caProvider CAProvider (Optional) The provider for the CA bundle to use to validate Vault server certificate. readYourWrites bool (Optional) ReadYourWrites ensures isolated read-after-write semantics by providing discovered cluster replication states in each request. More information about eventual consistency in Vault can be found here https://www.vaultproject.io/docs/enterprise/consistency forwardInconsistent bool (Optional) ForwardInconsistent tells Vault to forward read-after-write requests to the Vault leader instead of simply retrying within a loop. This can increase performance if the option is enabled serverside. https://www.vaultproject.io/docs/configuration/replication#allow_forwarding_via_header WebhookCAProvider ( Appears on: WebhookProvider ) Defines a location to fetch the cert for the webhook provider from. Field Description type WebhookCAProviderType The type of provider to use such as \u201cSecret\u201d, or \u201cConfigMap\u201d. name string The name of the object located at the provider type. key string The key the value inside of the provider type to use, only used with \u201cSecret\u201d type namespace string (Optional) The namespace the Provider type is in. WebhookCAProviderType ( string alias) ( Appears on: WebhookCAProvider ) Value Description \"ConfigMap\" \"Secret\" WebhookProvider ( Appears on: SecretStoreProvider ) AkeylessProvider Configures an store to sync secrets using Akeyless KV. Field Description method string Webhook Method url string Webhook url to call headers map[string]string (Optional) Headers body string (Optional) Body timeout Kubernetes meta/v1.Duration (Optional) Timeout result WebhookResult Result formatting secrets []WebhookSecret (Optional) Secrets to fill in templates These secrets will be passed to the templating function as key value pairs under the given name caBundle []byte (Optional) PEM encoded CA bundle used to validate webhook server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection. caProvider WebhookCAProvider (Optional) The provider for the CA bundle to use to validate webhook server certificate. WebhookResult ( Appears on: WebhookProvider ) Field Description jsonPath string (Optional) Json path of return value WebhookSecret ( Appears on: WebhookProvider ) Field Description name string Name of this secret in templates secretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector Secret ref to fill in credentials YandexCertificateManagerAuth ( Appears on: YandexCertificateManagerProvider ) Field Description authorizedKeySecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) The authorized key used for authentication YandexCertificateManagerCAProvider ( Appears on: YandexCertificateManagerProvider ) Field Description certSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector YandexCertificateManagerProvider ( Appears on: SecretStoreProvider ) YandexCertificateManagerProvider Configures a store to sync secrets using the Yandex Certificate Manager provider. Field Description apiEndpoint string (Optional) Yandex.Cloud API endpoint (e.g. \u2018api.cloud.yandex.net:443\u2019) auth YandexCertificateManagerAuth Auth defines the information necessary to authenticate against Yandex Certificate Manager caProvider YandexCertificateManagerCAProvider (Optional) The provider for the CA bundle to use to validate Yandex.Cloud server certificate. YandexLockboxAuth ( Appears on: YandexLockboxProvider ) Field Description authorizedKeySecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector (Optional) The authorized key used for authentication YandexLockboxCAProvider ( Appears on: YandexLockboxProvider ) Field Description certSecretRef github.com/external-secrets/external-secrets/apis/meta/v1.SecretKeySelector YandexLockboxProvider ( Appears on: SecretStoreProvider ) YandexLockboxProvider Configures a store to sync secrets using the Yandex Lockbox provider. Field Description apiEndpoint string (Optional) Yandex.Cloud API endpoint (e.g. \u2018api.cloud.yandex.net:443\u2019) auth YandexLockboxAuth Auth defines the information necessary to authenticate against Yandex Lockbox caProvider YandexLockboxCAProvider (Optional) The provider for the CA bundle to use to validate Yandex.Cloud server certificate. Generated with gen-crd-api-reference-docs .","title":"API specification"},{"location":"stability-support/","text":"This page lists the status, timeline and policy for currently supported ESO releases and its providers. Please also see our deprecation policy that describes API versioning, deprecation and API surface. External Secrets Operator We are currently in beta and support only the latest release for the time being. ESO Version Kubernetes Version 0.5.x 1.19 \u2192 1.24 0.4.x 1.16 \u2192 1.24 0.3.x 1.16 \u2192 1.24 Provider Stability and Support Level The following table describes the stability level of each provider and who's responsible. Provider Stability Maintainer AWS Secrets Manager stable external-secrets AWS Parameter Store stable external-secrets Hashicorp Vault stable external-secrets GCP Secret Manager stable external-secrets Azure Keyvault stable external-secrets Kubernetes alpha external-secrets IBM Secrets Manager alpha @knelasevero @sebagomez @ricardoptcosta Yandex Lockbox alpha @AndreyZamyslov @knelasevero Gitlab Project Variables alpha @Jabray5 Alibaba Cloud KMS alpha @ElsaChelala Oracle Vault alpha @KianTigger @EladGabay Akeyless alpha @renanaAkeyless 1Password alpha @SimSpaceCorp @snarlysodboxer Generic Webhook alpha @willemm senhasegura DevOps Secrets Management (DSM) alpha @lfraga Provider Feature Support The following table show the support for features across different providers. Provider find by name find by tags metadataPolicy Fetch referent authentication store validation push secret AWS Secrets Manager x x x AWS Parameter Store x x x Hashicorp Vault x x x GCP Secret Manager x x x Azure Keyvault x x x x x Kubernetes x x x x IBM Secrets Manager x Yandex Lockbox x Gitlab Project Variables x Alibaba Cloud KMS x Oracle Vault x Akeyless x 1Password x x Generic Webhook senhasegura DSM x Support Policy We provide technical support and security / bug fixes for the above listed versions. Technical support We provide assistance for deploying/upgrading etc. on a best-effort basis. You can request support through the following channels: Kubernetes Slack #external-secrets GitHub Issues GitHub Discussions Even though we have active maintainers and people assigned to this project, we kindly ask for patience when asking for support. We will try to get to priority issues as fast as possible, but there may be some delays.","title":"Stability and Support"},{"location":"stability-support/#external-secrets-operator","text":"We are currently in beta and support only the latest release for the time being. ESO Version Kubernetes Version 0.5.x 1.19 \u2192 1.24 0.4.x 1.16 \u2192 1.24 0.3.x 1.16 \u2192 1.24","title":"External Secrets Operator"},{"location":"stability-support/#provider-stability-and-support-level","text":"The following table describes the stability level of each provider and who's responsible. Provider Stability Maintainer AWS Secrets Manager stable external-secrets AWS Parameter Store stable external-secrets Hashicorp Vault stable external-secrets GCP Secret Manager stable external-secrets Azure Keyvault stable external-secrets Kubernetes alpha external-secrets IBM Secrets Manager alpha @knelasevero @sebagomez @ricardoptcosta Yandex Lockbox alpha @AndreyZamyslov @knelasevero Gitlab Project Variables alpha @Jabray5 Alibaba Cloud KMS alpha @ElsaChelala Oracle Vault alpha @KianTigger @EladGabay Akeyless alpha @renanaAkeyless 1Password alpha @SimSpaceCorp @snarlysodboxer Generic Webhook alpha @willemm senhasegura DevOps Secrets Management (DSM) alpha @lfraga","title":"Provider Stability and Support Level"},{"location":"stability-support/#provider-feature-support","text":"The following table show the support for features across different providers. Provider find by name find by tags metadataPolicy Fetch referent authentication store validation push secret AWS Secrets Manager x x x AWS Parameter Store x x x Hashicorp Vault x x x GCP Secret Manager x x x Azure Keyvault x x x x x Kubernetes x x x x IBM Secrets Manager x Yandex Lockbox x Gitlab Project Variables x Alibaba Cloud KMS x Oracle Vault x Akeyless x 1Password x x Generic Webhook senhasegura DSM x","title":"Provider Feature Support"},{"location":"stability-support/#support-policy","text":"We provide technical support and security / bug fixes for the above listed versions.","title":"Support Policy"},{"location":"stability-support/#technical-support","text":"We provide assistance for deploying/upgrading etc. on a best-effort basis. You can request support through the following channels: Kubernetes Slack #external-secrets GitHub Issues GitHub Discussions Even though we have active maintainers and people assigned to this project, we kindly ask for patience when asking for support. We will try to get to priority issues as fast as possible, but there may be some delays.","title":"Technical support"},{"location":"api/clusterexternalsecret/","text":"The ClusterExternalSecret is a cluster scoped resource that can be used to push an ExternalSecret to specific namespaces. Using the namespaceSelector you can select namespaces, and any matching namespaces will have the ExternalSecret specified in the externalSecretSpec created in it. Example Below is an example of the ClusterExternalSecret in use. apiVersion : external-secrets.io/v1beta1 kind : ClusterExternalSecret metadata : name : \"hello-world\" spec : # The name to be used on the ExternalSecrets externalSecretName : \"hello-world-es\" # This is a basic label selector to select the namespaces to deploy ExternalSecrets to. # you can read more about them here https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#resources-that-support-set-based-requirements namespaceSelector : matchLabels : cool : label # How often the ClusterExternalSecret should reconcile itself # This will decide how often to check and make sure that the ExternalSecrets exist in the matching namespaces refreshTime : \"1m\" # This is the spec of the ExternalSecrets to be created # The content of this was taken from our ExternalSecret example externalSecretSpec : secretStoreRef : name : secret-store-name kind : SecretStore refreshInterval : \"1h\" target : name : my-secret creationPolicy : 'Merge' template : type : kubernetes.io/dockerconfigjson metadata : annotations : {} labels : {} data : config.yml : | endpoints: - https://{{ .data.user }}:{{ .data.password }}@api.exmaple.com templateFrom : - configMap : name : alertmanager items : - key : alertmanager.yaml data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property dataFrom : - key : provider-key version : provider-key-version property : provider-key-property status : # This will list any namespaces where the creation of the ExternalSecret failed # This will not list any issues with the ExternalSecrets, you will have to check the # ExternalSecrets to see any issues with them. failedNamespaces : - namespace : \"matching-ns-1\" # This is one of the possible messages, and likely the most common reason : \"external secret already exists in namespace\" # You can find all matching and successfully deployed namespaces here provisionedNamespaces : - \"matching-ns-3\" - \"matching-ns-2\" # The condition can be Ready, PartiallyReady, or NotReady # PartiallyReady would indicate an error in 1 or more namespaces # NotReady would indicate errors in all namespaces meaning all ExternalSecrets resulted in errors conditions : - type : PartiallyReady status : \"True\" lastTransitionTime : \"2022-01-12T12:33:02Z\"","title":"ClusterExternalSecret"},{"location":"api/clusterexternalsecret/#example","text":"Below is an example of the ClusterExternalSecret in use. apiVersion : external-secrets.io/v1beta1 kind : ClusterExternalSecret metadata : name : \"hello-world\" spec : # The name to be used on the ExternalSecrets externalSecretName : \"hello-world-es\" # This is a basic label selector to select the namespaces to deploy ExternalSecrets to. # you can read more about them here https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#resources-that-support-set-based-requirements namespaceSelector : matchLabels : cool : label # How often the ClusterExternalSecret should reconcile itself # This will decide how often to check and make sure that the ExternalSecrets exist in the matching namespaces refreshTime : \"1m\" # This is the spec of the ExternalSecrets to be created # The content of this was taken from our ExternalSecret example externalSecretSpec : secretStoreRef : name : secret-store-name kind : SecretStore refreshInterval : \"1h\" target : name : my-secret creationPolicy : 'Merge' template : type : kubernetes.io/dockerconfigjson metadata : annotations : {} labels : {} data : config.yml : | endpoints: - https://{{ .data.user }}:{{ .data.password }}@api.exmaple.com templateFrom : - configMap : name : alertmanager items : - key : alertmanager.yaml data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property dataFrom : - key : provider-key version : provider-key-version property : provider-key-property status : # This will list any namespaces where the creation of the ExternalSecret failed # This will not list any issues with the ExternalSecrets, you will have to check the # ExternalSecrets to see any issues with them. failedNamespaces : - namespace : \"matching-ns-1\" # This is one of the possible messages, and likely the most common reason : \"external secret already exists in namespace\" # You can find all matching and successfully deployed namespaces here provisionedNamespaces : - \"matching-ns-3\" - \"matching-ns-2\" # The condition can be Ready, PartiallyReady, or NotReady # PartiallyReady would indicate an error in 1 or more namespaces # NotReady would indicate errors in all namespaces meaning all ExternalSecrets resulted in errors conditions : - type : PartiallyReady status : \"True\" lastTransitionTime : \"2022-01-12T12:33:02Z\"","title":"Example"},{"location":"api/clustersecretstore/","text":"The ClusterSecretStore is a cluster scoped SecretStore that can be referenced by all ExternalSecrets from all namespaces. Use it to offer a central gateway to your secret backend. apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : example spec : # Used to select the correct ESO controller (think: ingress.ingressClassName) # The ESO controller is instantiated with a specific controller name # and filters ES based on this property # Optional controller : dev # provider field contains the configuration to access the provider # which contains the secret exactly one provider must be configured. provider : # (1): AWS Secrets Manager # aws configures this store to sync secrets using AWS Secret Manager provider aws : service : SecretsManager # Role is a Role ARN which the SecretManager provider will assume role : iam-role # AWS Region to be used for the provider region : eu-central-1 # Auth defines the information necessary to authenticate against AWS auth : # Getting the accessKeyID and secretAccessKey from an already created Kubernetes Secret secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key # IAM roles for service accounts # https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts-technical-overview.html jwt : serviceAccountRef : name : my-serviceaccount namespace : sa-namespace vault : server : \"https://vault.acme.org\" # Path is the mount path of the Vault KV backend endpoint path : \"secret\" # Version is the Vault KV secret engine version. # This can be either \"v1\" or \"v2\", defaults to \"v2\" version : \"v2\" # vault enterprise namespace: https://www.vaultproject.io/docs/enterprise/namespaces namespace : \"a-team\" # base64 encoded string of certificate caBundle : \"...\" # Instead of caBundle you can also specify a caProvider # this will retrieve the cert from a Secret or ConfigMap caProvider : # Can be Secret or ConfigMap type : \"Secret\" # This is mandatory for ClusterSecretStore and not relevant for SecretStore namespace : \"my-cert-secret-namespace\" name : \"my-cert-secret\" key : \"cert-key\" auth : # static token: https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"my-secret\" namespace : \"secret-admin\" key : \"vault-token\" # AppRole auth: https://www.vaultproject.io/docs/auth/approle appRole : path : \"approle\" roleId : \"db02de05-fa39-4855-059b-67221c5c2f63\" secretRef : name : \"my-secret\" namespace : \"secret-admin\" key : \"vault-token\" # Kubernetes auth: https://www.vaultproject.io/docs/auth/kubernetes kubernetes : mountPath : \"kubernetes\" role : \"demo\" # Optional service account reference serviceAccountRef : name : \"my-sa\" namespace : \"secret-admin\" # Optional secret field containing a Kubernetes ServiceAccount JWT # used for authenticating with Vault secretRef : name : \"my-secret\" namespace : \"secret-admin\" key : \"vault\" # (2): GCP Secret Manager gcpsm : # Auth defines the information necessary to authenticate against GCP by getting # the credentials from an already created Kubernetes Secret. auth : secretRef : secretAccessKeySecretRef : name : gcpsm-secret key : secret-access-credentials namespace : example projectID : myproject # (3): Kubernetes provider kubernetes : server : url : \"https://myapiserver.tld\" caProvider : type : Secret name : my-cluster-secrets namespace : example key : ca.crt auth : serviceAccount : name : \"example-sa\" namespace : \"example\" # (TODO): add more provider examples here status : # Standard condition schema conditions : # SecretStore ready condition indicates the given store is in ready # state and able to referenced by ExternalSecrets # If the `status` of this condition is `False`, ExternalSecret controllers # should prevent attempts to fetch secrets - type : Ready status : \"False\" reason : \"ConfigError\" message : \"SecretStore validation failed\" lastTransitionTime : \"2019-08-12T12:33:02Z\"","title":"ClusterSecretStore"},{"location":"api/externalsecret/","text":"The ExternalSecret describes what data should be fetched, how the data should be transformed and saved as a Kind=Secret : tells the operator what secrets should be synced by using spec.data to explicitly sync individual keys or use spec.dataFrom to get all values from the external API. you can specify how the secret should look like by specifying a spec.target.template Template When the controller reconciles the ExternalSecret it will use the spec.template as a blueprint to construct a new Kind=Secret . You can use golang templates to define the blueprint and use template functions to transform secret values. You can also pull in ConfigMaps that contain golang-template data using templateFrom . See advanced templating for details. Update Behavior The Kind=Secret is updated when: the spec.refreshInterval has passed and is not 0 the ExternalSecret 's labels or annotations are changed the ExternalSecret 's spec has been changed You can trigger a secret refresh by using kubectl or any other kubernetes api client: kubectl annotate es my-es force-sync=$(date +%s) --overwrite Example Take a look at an annotated example to understand the design behind the ExternalSecret . apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : \"hello-world\" # labels and annotations are copied over to the # secret that will be created labels : acme.org/owned-by : \"q-team\" annotations : acme.org/sha : 1234 spec : # SecretStoreRef defines which SecretStore to use when fetching the secret data secretStoreRef : name : secret-store-name kind : SecretStore # or ClusterSecretStore # RefreshInterval is the amount of time before the values reading again from the SecretStore provider # Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\" (from time.ParseDuration) # May be set to zero to fetch and create it once refreshInterval : \"1h\" # the target describes the secret that shall be created # there can only be one target per ExternalSecret target : # The secret name of the resource # Defaults to .metadata.name of the ExternalSecret # It is immutable name : my-secret # Enum with values: 'Owner', 'Merge', or 'None' # Default value of 'Owner' # Owner creates the secret and sets .metadata.ownerReferences of the resource # Merge does not create the secret, but merges in the data fields to the secret # None does not create a secret (future use with injector) creationPolicy : 'Merge' # DeletionPolicy defines how/when to delete the Secret in Kubernetes # if the provider secret gets deleted. # Valid values are Delete, Merge, Retain deletionPolicy : \"Retain\" # Specify a blueprint for the resulting Kind=Secret template : type : kubernetes.io/dockerconfigjson # or TLS... metadata : annotations : {} labels : {} # Use inline templates to construct your desired config file that contains your secret data : config.yml : | endpoints: - https://{{ .data.user }}:{{ .data.password }}@api.exmaple.com # Uses an existing template from configmap # Secret is fetched, merged and templated within the referenced configMap data # It does not update the configmap, it creates a secret with: data[\"alertmanager.yml\"] = ...result... templateFrom : - configMap : name : alertmanager items : - key : alertmanager.yaml # Data defines the connection between the Kubernetes Secret keys and the Provider data data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property decodingStrategy : None # can be None, Base64, Base64URL or Auto # Used to fetch all properties from the Provider key # If multiple dataFrom are specified, secrets are merged in the specified order dataFrom : - extract : key : provider-key version : provider-key-version property : provider-key-property conversionStrategy : Default decodingStrategy : Auto rewrite : - regexp : source : \"foo\" target : \"bar\" - regexp : source : \"exp-(.*?)-ression\" target : \"rewriting-$1-with-groups\" - find : path : path-to-filter source : \"exp-(.*?)-ression\" target : \"rewriting-$1-with-groups\" name : regexp : \".*foobar.*\" tags : foo : bar conversionStrategy : Unicode decodingStrategy : Base64 rewrite : - regexp : source : \"foo\" target : \"bar\" - regexp : status : # refreshTime is the time and date the external secret was fetched and # the target secret updated refreshTime : \"2019-08-12T12:33:02Z\" # Standard condition schema conditions : # ExternalSecret ready condition indicates the secret is ready for use. # This is defined as: # - The target secret exists # - The target secret has been refreshed within the last refreshInterval # - The target secret content is up-to-date based on any target templates - type : Ready status : \"True\" # False if last refresh was not successful reason : \"SecretSynced\" message : \"Secret was synced\" lastTransitionTime : \"2019-08-12T12:33:02Z\"","title":"ExternalSecret"},{"location":"api/externalsecret/#template","text":"When the controller reconciles the ExternalSecret it will use the spec.template as a blueprint to construct a new Kind=Secret . You can use golang templates to define the blueprint and use template functions to transform secret values. You can also pull in ConfigMaps that contain golang-template data using templateFrom . See advanced templating for details.","title":"Template"},{"location":"api/externalsecret/#update-behavior","text":"The Kind=Secret is updated when: the spec.refreshInterval has passed and is not 0 the ExternalSecret 's labels or annotations are changed the ExternalSecret 's spec has been changed You can trigger a secret refresh by using kubectl or any other kubernetes api client: kubectl annotate es my-es force-sync=$(date +%s) --overwrite","title":"Update Behavior"},{"location":"api/externalsecret/#example","text":"Take a look at an annotated example to understand the design behind the ExternalSecret . apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : \"hello-world\" # labels and annotations are copied over to the # secret that will be created labels : acme.org/owned-by : \"q-team\" annotations : acme.org/sha : 1234 spec : # SecretStoreRef defines which SecretStore to use when fetching the secret data secretStoreRef : name : secret-store-name kind : SecretStore # or ClusterSecretStore # RefreshInterval is the amount of time before the values reading again from the SecretStore provider # Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\" (from time.ParseDuration) # May be set to zero to fetch and create it once refreshInterval : \"1h\" # the target describes the secret that shall be created # there can only be one target per ExternalSecret target : # The secret name of the resource # Defaults to .metadata.name of the ExternalSecret # It is immutable name : my-secret # Enum with values: 'Owner', 'Merge', or 'None' # Default value of 'Owner' # Owner creates the secret and sets .metadata.ownerReferences of the resource # Merge does not create the secret, but merges in the data fields to the secret # None does not create a secret (future use with injector) creationPolicy : 'Merge' # DeletionPolicy defines how/when to delete the Secret in Kubernetes # if the provider secret gets deleted. # Valid values are Delete, Merge, Retain deletionPolicy : \"Retain\" # Specify a blueprint for the resulting Kind=Secret template : type : kubernetes.io/dockerconfigjson # or TLS... metadata : annotations : {} labels : {} # Use inline templates to construct your desired config file that contains your secret data : config.yml : | endpoints: - https://{{ .data.user }}:{{ .data.password }}@api.exmaple.com # Uses an existing template from configmap # Secret is fetched, merged and templated within the referenced configMap data # It does not update the configmap, it creates a secret with: data[\"alertmanager.yml\"] = ...result... templateFrom : - configMap : name : alertmanager items : - key : alertmanager.yaml # Data defines the connection between the Kubernetes Secret keys and the Provider data data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property decodingStrategy : None # can be None, Base64, Base64URL or Auto # Used to fetch all properties from the Provider key # If multiple dataFrom are specified, secrets are merged in the specified order dataFrom : - extract : key : provider-key version : provider-key-version property : provider-key-property conversionStrategy : Default decodingStrategy : Auto rewrite : - regexp : source : \"foo\" target : \"bar\" - regexp : source : \"exp-(.*?)-ression\" target : \"rewriting-$1-with-groups\" - find : path : path-to-filter source : \"exp-(.*?)-ression\" target : \"rewriting-$1-with-groups\" name : regexp : \".*foobar.*\" tags : foo : bar conversionStrategy : Unicode decodingStrategy : Base64 rewrite : - regexp : source : \"foo\" target : \"bar\" - regexp : status : # refreshTime is the time and date the external secret was fetched and # the target secret updated refreshTime : \"2019-08-12T12:33:02Z\" # Standard condition schema conditions : # ExternalSecret ready condition indicates the secret is ready for use. # This is defined as: # - The target secret exists # - The target secret has been refreshed within the last refreshInterval # - The target secret content is up-to-date based on any target templates - type : Ready status : \"True\" # False if last refresh was not successful reason : \"SecretSynced\" message : \"Secret was synced\" lastTransitionTime : \"2019-08-12T12:33:02Z\"","title":"Example"},{"location":"api/secretstore/","text":"The SecretStore is namespaced and specifies how to access the external API. The SecretStore maps to exactly one instance of an external API. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example namespace : example-ns spec : # Used to select the correct ESO controller (think: ingress.ingressClassName) # The ESO controller is instantiated with a specific controller name # and filters ES based on this property # Optional controller : dev # You can specify retry settings for the http connection # these fields allow you to set a maxRetries before failure, and # an interval between the retries. # Current supported providers: AWS, IBM retrySettings : maxRetries : 5 retryInterval : \"10s\" # provider field contains the configuration to access the provider # which contains the secret exactly one provider must be configured. provider : # (1): AWS Secrets Manager # aws configures this store to sync secrets using AWS Secret Manager provider aws : service : SecretsManager # Role is a Role ARN which the SecretManager provider will assume role : iam-role # AWS Region to be used for the provider region : eu-central-1 # Auth defines the information necessary to authenticate against AWS by # getting the accessKeyID and secretAccessKey from an already created Kubernetes Secret auth : secretRef : accessKeyID : name : awssm-secret key : access-key secretAccessKey : name : awssm-secret key : secret-access-key vault : server : \"https://vault.acme.org\" # Path is the mount path of the Vault KV backend endpoint path : \"secret\" # Version is the Vault KV secret engine version. # This can be either \"v1\" or \"v2\", defaults to \"v2\" version : \"v2\" # vault enterprise namespace: https://www.vaultproject.io/docs/enterprise/namespaces namespace : \"a-team\" # base64 encoded string of certificate caBundle : \"...\" # Instead of caBundle you can also specify a caProvider # this will retrieve the cert from a Secret or ConfigMap caProvider : # Can be Secret or ConfigMap type : \"Secret\" name : \"my-cert-secret\" key : \"cert-key\" auth : # static token: https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"my-secret\" key : \"vault-token\" # AppRole auth: https://www.vaultproject.io/docs/auth/approle appRole : path : \"approle\" roleId : \"db02de05-fa39-4855-059b-67221c5c2f63\" secretRef : name : \"my-secret\" key : \"vault-token\" # Kubernetes auth: https://www.vaultproject.io/docs/auth/kubernetes kubernetes : mountPath : \"kubernetes\" role : \"demo\" # Optional service account reference serviceAccountRef : name : \"my-sa\" # Optional secret field containing a Kubernetes ServiceAccount JWT # used for authenticating with Vault secretRef : name : \"my-secret\" key : \"vault\" # (2): GCP Secret Manager gcpsm : # Auth defines the information necessary to authenticate against GCP by getting # the credentials from an already created Kubernetes Secret. auth : secretRef : secretAccessKeySecretRef : name : gcpsm-secret key : secret-access-credentials projectID : myproject # (TODO): add more provider examples here status : # Standard condition schema conditions : # SecretStore ready condition indicates the given store is in ready # state and able to referenced by ExternalSecrets # If the `status` of this condition is `False`, ExternalSecret controllers # should prevent attempts to fetch secrets - type : Ready status : \"False\" reason : \"ConfigError\" message : \"SecretStore validation failed\" lastTransitionTime : \"2019-08-12T12:33:02Z\"","title":"SecretStore"},{"location":"contributing/coc/","text":"Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at contact@external-secrets.io. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Code of Conduct"},{"location":"contributing/coc/#code-of-conduct","text":"","title":"Code of Conduct"},{"location":"contributing/coc/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"contributing/coc/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"contributing/coc/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"contributing/coc/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"contributing/coc/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at contact@external-secrets.io. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"contributing/coc/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"contributing/coc/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"contributing/coc/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"contributing/coc/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"contributing/coc/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"contributing/coc/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"contributing/devguide/","text":"Getting Started You must have a working Go environment and then clone the repo: git clone https://github.com/external-secrets/external-secrets.git cd external-secrets Note: many of the make commands use yq , version 4.2X.X or higher. If you want to run controller tests you also need to install kubebuilder's envtest . The recommended way to do so is to install setup-envtest Here is an example on how to set it up: go install sigs.k8s.io/controller-runtime/tools/setup-envtest@latest # list available versions setup-envtest list --os $(go env GOOS) --arch $(go env GOARCH) # To use a specific version setup-envtest use -p path 1.20.2 #To set environment variables source <(setup-envtest use 1.20.2 -p env --os $(go env GOOS) --arch $(go env GOARCH)) for more information, please see setup-envtest docs Building & Testing The project uses the make build system. It'll run code generators, tests and static code analysis. Building the operator binary and docker image: make build make docker.build IMG = external-secrets:latest Run tests and lint the code: (golangci-lint@1.45.2 is needed.) make test make lint # OR docker run --rm -v $( pwd ) :/app -w /app golangci/golangci-lint:v1.42.1 golangci-lint run Build the documentation: make docs Installing To install the External Secret Operator into a Kubernetes Cluster run: helm repo add external-secrets https://charts.external-secrets.io helm repo update helm install external-secrets external-secrets/external-secrets You can alternatively run the controller on your host system for development purposes: make crds.install make run To remove the CRDs run: make crds.uninstall If you need to test some other k8s integrations and need the operator to be deployed to the actuall cluster while developing, you can use the following workflow: kind create cluster --name external-secrets export TAG=v2 export IMAGE=eso-local #For building in linux docker build . -t $IMAGE:$TAG --build-arg TARGETARCH=amd64 --build-arg TARGETOS=linux #For building in MacOS (OSX) #docker build . -t $IMAGE:$TAG --build-arg TARGETARCH=amd64 --build-arg TARGETOS=darwin #For building in ARM #docker build . -t $IMAGE:$TAG --build-arg TARGETARCH=arm --build-arg TARGETOS=linux make helm.generate helm upgrade --install external-secrets ./deploy/charts/external-secrets/ --set image.repository=$IMAGE --set image.tag=$TAG Contributing Flow The HOW TO guide for contributing is at the Contributing Process page. Documentation We use mkdocs material and mike to generate this documentation. See /docs for the source code and /hack/api-docs for the build process. When writing documentation it is advised to run the mkdocs server with livereload: make docs.serve Run the following command to run a complete build. The rendered assets are available under /site . make docs make docs.serve Open http://localhost:8000 in your browser. Since mike uses a branch to create/update documentation, any docs operation will create a diff on your local gh-pages branch. When finished writing/reviewing the docs, clean up your local docs branch changes with git branch -D gh-pages","title":"Developer guide"},{"location":"contributing/devguide/#getting-started","text":"You must have a working Go environment and then clone the repo: git clone https://github.com/external-secrets/external-secrets.git cd external-secrets Note: many of the make commands use yq , version 4.2X.X or higher. If you want to run controller tests you also need to install kubebuilder's envtest . The recommended way to do so is to install setup-envtest Here is an example on how to set it up: go install sigs.k8s.io/controller-runtime/tools/setup-envtest@latest # list available versions setup-envtest list --os $(go env GOOS) --arch $(go env GOARCH) # To use a specific version setup-envtest use -p path 1.20.2 #To set environment variables source <(setup-envtest use 1.20.2 -p env --os $(go env GOOS) --arch $(go env GOARCH)) for more information, please see setup-envtest docs","title":"Getting Started"},{"location":"contributing/devguide/#building-testing","text":"The project uses the make build system. It'll run code generators, tests and static code analysis. Building the operator binary and docker image: make build make docker.build IMG = external-secrets:latest Run tests and lint the code: (golangci-lint@1.45.2 is needed.) make test make lint # OR docker run --rm -v $( pwd ) :/app -w /app golangci/golangci-lint:v1.42.1 golangci-lint run Build the documentation: make docs","title":"Building &amp; Testing"},{"location":"contributing/devguide/#installing","text":"To install the External Secret Operator into a Kubernetes Cluster run: helm repo add external-secrets https://charts.external-secrets.io helm repo update helm install external-secrets external-secrets/external-secrets You can alternatively run the controller on your host system for development purposes: make crds.install make run To remove the CRDs run: make crds.uninstall If you need to test some other k8s integrations and need the operator to be deployed to the actuall cluster while developing, you can use the following workflow: kind create cluster --name external-secrets export TAG=v2 export IMAGE=eso-local #For building in linux docker build . -t $IMAGE:$TAG --build-arg TARGETARCH=amd64 --build-arg TARGETOS=linux #For building in MacOS (OSX) #docker build . -t $IMAGE:$TAG --build-arg TARGETARCH=amd64 --build-arg TARGETOS=darwin #For building in ARM #docker build . -t $IMAGE:$TAG --build-arg TARGETARCH=arm --build-arg TARGETOS=linux make helm.generate helm upgrade --install external-secrets ./deploy/charts/external-secrets/ --set image.repository=$IMAGE --set image.tag=$TAG Contributing Flow The HOW TO guide for contributing is at the Contributing Process page.","title":"Installing"},{"location":"contributing/devguide/#documentation","text":"We use mkdocs material and mike to generate this documentation. See /docs for the source code and /hack/api-docs for the build process. When writing documentation it is advised to run the mkdocs server with livereload: make docs.serve Run the following command to run a complete build. The rendered assets are available under /site . make docs make docs.serve Open http://localhost:8000 in your browser. Since mike uses a branch to create/update documentation, any docs operation will create a diff on your local gh-pages branch. When finished writing/reviewing the docs, clean up your local docs branch changes with git branch -D gh-pages","title":"Documentation"},{"location":"contributing/process/","text":"Project Management The Code, our TODOs and Documentation is maintained on GitHub . All Issues should be opened in that repository. We have a Roadmap to track progress for our road towards GA. Issues Features, bugs and any issues regarding the documentation should be filed as GitHub Issue in our repository. We use labels like kind/feature , kind/bug , area/aws to organize the issues. Issues labeled good first issue and help wanted are especially good for a first contribution. If you want to pick up an issue just leave a comment. Submitting a Pull Request This project uses the well-known pull request process from GitHub. To submit a pull request, fork the repository and push any changes to a branch on the copy, from there a pull request can be made in the main repo. Merging a pull request requires the following steps to be completed before the pull request will be merged: ideally, there is an issue that documents the problem or feature in depth. code must have a reasonable amount of test coverage tests must pass PR needs be reviewed and approved Once these steps are completed the PR will be merged by a code owner. We're using the pull request assignee feature to track who is responsible for the lifecycle of the PR: review, merging, ping on inactivity, close. We close pull requests or issues if there is no response from the author for a period of time. Feel free to reopen if you want to get back on it. Triggering e2e tests We have an extensive set of e2e tests that test the integration with real cloud provider APIs. Maintainers must trigger these kind of tests manually for PRs that come from forked repositories. These tests run inside a kind cluster in the GitHub Actions runner: /ok-to-test sha=xxxxxx Executing e2e tests locally You have to prepare your shell environment with the necessary variables so the e2e test runner knows what credentials to use. See e2e/run.sh for the variables that are passed in. If you e.g. want to test AWS integration make sure set all AWS_* variables mentioned in that file. Use ginkgo labels to select the tests you want to execute. You have to specify !managed to ensure that you do not run managed tests. make test.e2e GINKGO_LABELS='gcp&&!managed' Managed Kubernetes e2e tests There's another suite of e2e tests that integrate with managed Kuberentes offerings. They create real infrastructure at a cloud provider and deploy the controller into that environment. This is necessary to test the authentication integration ( GCP Workload Identity , EKS IRSA ...). These tests are time intensive (~20-45min) and must be triggered manually by a maintainer when a particular provider or authentication mechanism was changed: /ok-to-test-managed sha=xxxxxx provider=aws # or /ok-to-test-managed sha=xxxxxx provider=gcp Both tests can run in parallel. Once started they add a dynamic GitHub check integration-managed-(gcp|aws) to the PR that triggered the test. Executing Managed Kubernetes e2e tests locally You have to prepare your shell environment with the necessary variables so the e2e test runner knows what credentials to use. See .github/workflows/e2e-managed.yml for the variables that are passed in. If you e.g. want to test AWS integration make sure set all variables containing AWS_* and TF_VAR_AWS_* mentioned in that file. Then execute tf.apply.aws or tf.apply.gcp to create the infrastructure. make tf.apply.aws Then run the managed testsuite. You will need push permissions to the external-secrets ghcr repository. You can set IMAGE_REGISTRY to control which image registry is used to store the controller and e2e test images in. You also have to setup a proper Kubeconfig so the e2e test pod gets deployed into the managed cluster. aws eks update-kubeconfig --name ${AWS_CLUSTER_NAME} or gcloud container clusters get-credentials ${GCP_GKE_CLUSTER} --region europe-west1-b Use ginkgo labels to select the tests you want to execute. # you may have to set IMAGE_REGISTRY=docker.io/your-user/external-secrets make test.e2e.managed GINKGO_LABELS='gcp' Proposal Process Before we introduce significant changes to the project we want to gather feedback from the community to ensure that we progress in the right direction before we develop and release big changes. Significant changes include for example: creating new custom resources proposing breaking changes changing the behavior of the controller significantly Please create a document in the design/ directory based on the template 000-template.md and fill in your proposal. Open a pull request in draft mode and request feedback. Once the proposal is accepted and the pull request is merged we can create work packages and proceed with the implementation. Release Planning We have a GitHub Project Board where we organize issues on a high level. We group issues by milestone. Once all issues of a given milestone are closed we should prepare a new feature release. Issues of the next milestone have priority over other issues - but that does not mean that no one is allowed to start working on them. Issues must be manually added to that board (at least for now, see GH Roadmap ). Milestones must be assigned manually as well. If no milestone is assigned it is basically a backlog item. It is the responsibility of the maintainers to: assign new issues to the GH Project add a milestone if needed add appropriate labels If you would like to raise the priority of an issue for whatever reason feel free to comment on the issue or ping a maintainer. Support & Questions Providing support to end users is an important and difficult task. We have three different channels through which support questions arise: Kubernetes Slack #external-secrets GitHub Discussions GitHub Issues We use labels to identify GitHub Issues. Specifically for managing support cases we use the following labels to identify the state a support case is in: triage/needs-information : Indicates an issue needs more information in order to work on it. triage/not-reproducible : Indicates an issue can not be reproduced as described. triage/support : Indicates an issue that is a support question. Cutting Releases The external-secrets project is released on a as-needed basis. Feel free to open a issue to request a release. Details on how to cut a release can be found in the release page.","title":"Contributing Process"},{"location":"contributing/process/#project-management","text":"The Code, our TODOs and Documentation is maintained on GitHub . All Issues should be opened in that repository. We have a Roadmap to track progress for our road towards GA.","title":"Project Management"},{"location":"contributing/process/#issues","text":"Features, bugs and any issues regarding the documentation should be filed as GitHub Issue in our repository. We use labels like kind/feature , kind/bug , area/aws to organize the issues. Issues labeled good first issue and help wanted are especially good for a first contribution. If you want to pick up an issue just leave a comment.","title":"Issues"},{"location":"contributing/process/#submitting-a-pull-request","text":"This project uses the well-known pull request process from GitHub. To submit a pull request, fork the repository and push any changes to a branch on the copy, from there a pull request can be made in the main repo. Merging a pull request requires the following steps to be completed before the pull request will be merged: ideally, there is an issue that documents the problem or feature in depth. code must have a reasonable amount of test coverage tests must pass PR needs be reviewed and approved Once these steps are completed the PR will be merged by a code owner. We're using the pull request assignee feature to track who is responsible for the lifecycle of the PR: review, merging, ping on inactivity, close. We close pull requests or issues if there is no response from the author for a period of time. Feel free to reopen if you want to get back on it.","title":"Submitting a Pull Request"},{"location":"contributing/process/#triggering-e2e-tests","text":"We have an extensive set of e2e tests that test the integration with real cloud provider APIs. Maintainers must trigger these kind of tests manually for PRs that come from forked repositories. These tests run inside a kind cluster in the GitHub Actions runner: /ok-to-test sha=xxxxxx","title":"Triggering e2e tests"},{"location":"contributing/process/#executing-e2e-tests-locally","text":"You have to prepare your shell environment with the necessary variables so the e2e test runner knows what credentials to use. See e2e/run.sh for the variables that are passed in. If you e.g. want to test AWS integration make sure set all AWS_* variables mentioned in that file. Use ginkgo labels to select the tests you want to execute. You have to specify !managed to ensure that you do not run managed tests. make test.e2e GINKGO_LABELS='gcp&&!managed'","title":"Executing e2e tests locally"},{"location":"contributing/process/#managed-kubernetes-e2e-tests","text":"There's another suite of e2e tests that integrate with managed Kuberentes offerings. They create real infrastructure at a cloud provider and deploy the controller into that environment. This is necessary to test the authentication integration ( GCP Workload Identity , EKS IRSA ...). These tests are time intensive (~20-45min) and must be triggered manually by a maintainer when a particular provider or authentication mechanism was changed: /ok-to-test-managed sha=xxxxxx provider=aws # or /ok-to-test-managed sha=xxxxxx provider=gcp Both tests can run in parallel. Once started they add a dynamic GitHub check integration-managed-(gcp|aws) to the PR that triggered the test.","title":"Managed Kubernetes e2e tests"},{"location":"contributing/process/#executing-managed-kubernetes-e2e-tests-locally","text":"You have to prepare your shell environment with the necessary variables so the e2e test runner knows what credentials to use. See .github/workflows/e2e-managed.yml for the variables that are passed in. If you e.g. want to test AWS integration make sure set all variables containing AWS_* and TF_VAR_AWS_* mentioned in that file. Then execute tf.apply.aws or tf.apply.gcp to create the infrastructure. make tf.apply.aws Then run the managed testsuite. You will need push permissions to the external-secrets ghcr repository. You can set IMAGE_REGISTRY to control which image registry is used to store the controller and e2e test images in. You also have to setup a proper Kubeconfig so the e2e test pod gets deployed into the managed cluster. aws eks update-kubeconfig --name ${AWS_CLUSTER_NAME} or gcloud container clusters get-credentials ${GCP_GKE_CLUSTER} --region europe-west1-b Use ginkgo labels to select the tests you want to execute. # you may have to set IMAGE_REGISTRY=docker.io/your-user/external-secrets make test.e2e.managed GINKGO_LABELS='gcp'","title":"Executing Managed Kubernetes e2e tests locally"},{"location":"contributing/process/#proposal-process","text":"Before we introduce significant changes to the project we want to gather feedback from the community to ensure that we progress in the right direction before we develop and release big changes. Significant changes include for example: creating new custom resources proposing breaking changes changing the behavior of the controller significantly Please create a document in the design/ directory based on the template 000-template.md and fill in your proposal. Open a pull request in draft mode and request feedback. Once the proposal is accepted and the pull request is merged we can create work packages and proceed with the implementation.","title":"Proposal Process"},{"location":"contributing/process/#release-planning","text":"We have a GitHub Project Board where we organize issues on a high level. We group issues by milestone. Once all issues of a given milestone are closed we should prepare a new feature release. Issues of the next milestone have priority over other issues - but that does not mean that no one is allowed to start working on them. Issues must be manually added to that board (at least for now, see GH Roadmap ). Milestones must be assigned manually as well. If no milestone is assigned it is basically a backlog item. It is the responsibility of the maintainers to: assign new issues to the GH Project add a milestone if needed add appropriate labels If you would like to raise the priority of an issue for whatever reason feel free to comment on the issue or ping a maintainer.","title":"Release Planning"},{"location":"contributing/process/#support-questions","text":"Providing support to end users is an important and difficult task. We have three different channels through which support questions arise: Kubernetes Slack #external-secrets GitHub Discussions GitHub Issues We use labels to identify GitHub Issues. Specifically for managing support cases we use the following labels to identify the state a support case is in: triage/needs-information : Indicates an issue needs more information in order to work on it. triage/not-reproducible : Indicates an issue can not be reproduced as described. triage/support : Indicates an issue that is a support question.","title":"Support &amp; Questions"},{"location":"contributing/process/#cutting-releases","text":"The external-secrets project is released on a as-needed basis. Feel free to open a issue to request a release. Details on how to cut a release can be found in the release page.","title":"Cutting Releases"},{"location":"contributing/release/","text":"ESO and the ESO Helm Chart have two distinct lifecycles and can be released independently. Helm Chart releases are named external-secrets-x.y.z . The external-secrets project is released on a as-needed basis. Feel free to open a issue to request a release. Release ESO Run Create Release Action to create a new release, pass in the desired version number to release. GitHub Release, Changelog will be created by the release.yml workflow which also promotes the container image. update Helm Chart, see below update OLM bundle, see helm-operator docs Announce the new release in the #external-secrets Kubernetes Slack Release Helm Chart Update version and/or appVersion in Chart.yaml push and merge PR CI picks up the new chart version and creates a new GitHub Release for it Release OLM Bundle In order to make the latest release available to OperatorHub.io we need to create a bundle and open a PR in the community-operators repository. To create a bundle first increment the VERSION in the Makefile as described above. Then run the following commands in the root of the repository: # clone repo git clone https://github.com/external-secrets/external-secrets-helm-operator cd external-secrets-helm-operator # bump version export VERSION = x.y.z sed -i \"s/^VERSION ?= .*/VERSION ?= ${ VERSION } /\" Makefile # prep release make prepare-stable-release Check the generated files in the bundle/ directory. If they look good add & commit them, open a PR against this repository. You can always use the OperatorHub.io/preview page to preview the generated CSV. git status git add . git commit -s -m \"chore: bump version xyz\" git push Once the PR is merged we need create a pull request against both community-operators repositories. There's a make target that does the heavy lifting for you: make bundle-operatorhub This command will add/commit/push and open pull requests in the respective repositories.","title":"Release Process"},{"location":"contributing/release/#release-eso","text":"Run Create Release Action to create a new release, pass in the desired version number to release. GitHub Release, Changelog will be created by the release.yml workflow which also promotes the container image. update Helm Chart, see below update OLM bundle, see helm-operator docs Announce the new release in the #external-secrets Kubernetes Slack","title":"Release ESO"},{"location":"contributing/release/#release-helm-chart","text":"Update version and/or appVersion in Chart.yaml push and merge PR CI picks up the new chart version and creates a new GitHub Release for it","title":"Release Helm Chart"},{"location":"contributing/release/#release-olm-bundle","text":"In order to make the latest release available to OperatorHub.io we need to create a bundle and open a PR in the community-operators repository. To create a bundle first increment the VERSION in the Makefile as described above. Then run the following commands in the root of the repository: # clone repo git clone https://github.com/external-secrets/external-secrets-helm-operator cd external-secrets-helm-operator # bump version export VERSION = x.y.z sed -i \"s/^VERSION ?= .*/VERSION ?= ${ VERSION } /\" Makefile # prep release make prepare-stable-release Check the generated files in the bundle/ directory. If they look good add & commit them, open a PR against this repository. You can always use the OperatorHub.io/preview page to preview the generated CSV. git status git add . git commit -s -m \"chore: bump version xyz\" git push Once the PR is merged we need create a pull request against both community-operators repositories. There's a make target that does the heavy lifting for you: make bundle-operatorhub This command will add/commit/push and open pull requests in the respective repositories.","title":"Release OLM Bundle"},{"location":"contributing/roadmap/","text":"The road to external-secrets GA The following external-secret custom resource APIs are considered stable: ExternalSecret ClusterExternalSecret SecretStore ClusterSecretStore These CRDs are currently at v1beta1 and are considered production ready. Going forward, breaking changes to these APIs will be accompanied by a conversion mechanism. We have identified the following areas of work. This is subject to change while we gather feedback. We have a GitHub Project Board where we organize issues and milestones on a high level. Conformance testing end to end testing with ArgoCD and Flux end to end testing for all project maintained providers API enhancements consolidate provider fields dataFrom key rewrites provider versioning strategy pushing secrets to a provider Documentation Improvements Troubleshooting Guides FAQ review multi tenancy docs provide security model for infosec teams provider specific guides Observability Provide Grafana Dashboard and Prometheus alerts add provider-level metrics Pentest & SBOM","title":"Roadmap"},{"location":"contributing/roadmap/#the-road-to-external-secrets-ga","text":"The following external-secret custom resource APIs are considered stable: ExternalSecret ClusterExternalSecret SecretStore ClusterSecretStore These CRDs are currently at v1beta1 and are considered production ready. Going forward, breaking changes to these APIs will be accompanied by a conversion mechanism. We have identified the following areas of work. This is subject to change while we gather feedback. We have a GitHub Project Board where we organize issues and milestones on a high level. Conformance testing end to end testing with ArgoCD and Flux end to end testing for all project maintained providers API enhancements consolidate provider fields dataFrom key rewrites provider versioning strategy pushing secrets to a provider Documentation Improvements Troubleshooting Guides FAQ review multi tenancy docs provide security model for infosec teams provider specific guides Observability Provide Grafana Dashboard and Prometheus alerts add provider-level metrics Pentest & SBOM","title":"The road to external-secrets GA"},{"location":"examples/anchore-engine-credentials/","text":"Getting started Anchore Engine is an open-source project that provides a centralized service for inspection, analysis, and certification of container images. With Kubernetes, it also brings nice features like preventing unscanned images from being deployed into your clusters Installing with Helm There are several parts of the installation that require credentials these being :- ANCHORE_ADMIN_USERNAME ANCHORE_ADMIN_PASSWORD ANCHORE_DB_PASSWORD db-url db-user postgres-password Creating the following external secret ensure the credentials are drawn from the backend provider of choice. The example shown here works with Hashicorp Vault and AWS Secrets Manager providers. Hashicorp Vault apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : anchore-access-credentials namespace : security spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : anchore-access-credentials template : data : ANCHORE_ADMIN_USERNAME : >- {{ printf \"{{ .username | toString }}\" }} ANCHORE_ADMIN_PASSWORD : >- {{ printf \"{{ .password | toString }}\" }} ANCHORE_DB_PASSWORD : >- {{ printf \"{{ .dbPassword | toString }}\" }} db-url : >- {{ printf \"{{ .dbUrl | toString }}\" }} db-user : >- {{ printf \"{{ .dbUser | toString }}\" }} postgres-password : >- {{ printf \"{{ .postgresPassword | toString }}\" }} data : - secretKey : password remoteRef : key : anchore-engine property : ANCHORE_ADMIN_PASSWORD - secretKey : username remoteRef : key : anchore-engine property : ANCHORE_ADMIN_USERNAME - secretKey : dbPassword remoteRef : key : anchore-engine property : ANCHORE_DB_PASSWORD - secretKey : dbUrl remoteRef : key : anchore-engine property : db-url - secretKey : dbUser remoteRef : key : anchore-engine property : db-user - secretKey : postgresPassword remoteRef : key : anchore-engine property : postgres-password AWS Secrets Manager --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : anchore-access-credentials namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-secrets-store kind : ClusterSecretStore target : name : anchore-access-credentials dataFrom : - extract : key : service/anchore-engine/engineAccess","title":"Anchore Engine"},{"location":"examples/anchore-engine-credentials/#getting-started","text":"Anchore Engine is an open-source project that provides a centralized service for inspection, analysis, and certification of container images. With Kubernetes, it also brings nice features like preventing unscanned images from being deployed into your clusters","title":"Getting started"},{"location":"examples/anchore-engine-credentials/#installing-with-helm","text":"There are several parts of the installation that require credentials these being :- ANCHORE_ADMIN_USERNAME ANCHORE_ADMIN_PASSWORD ANCHORE_DB_PASSWORD db-url db-user postgres-password Creating the following external secret ensure the credentials are drawn from the backend provider of choice. The example shown here works with Hashicorp Vault and AWS Secrets Manager providers.","title":"Installing with Helm"},{"location":"examples/anchore-engine-credentials/#hashicorp-vault","text":"apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : anchore-access-credentials namespace : security spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : anchore-access-credentials template : data : ANCHORE_ADMIN_USERNAME : >- {{ printf \"{{ .username | toString }}\" }} ANCHORE_ADMIN_PASSWORD : >- {{ printf \"{{ .password | toString }}\" }} ANCHORE_DB_PASSWORD : >- {{ printf \"{{ .dbPassword | toString }}\" }} db-url : >- {{ printf \"{{ .dbUrl | toString }}\" }} db-user : >- {{ printf \"{{ .dbUser | toString }}\" }} postgres-password : >- {{ printf \"{{ .postgresPassword | toString }}\" }} data : - secretKey : password remoteRef : key : anchore-engine property : ANCHORE_ADMIN_PASSWORD - secretKey : username remoteRef : key : anchore-engine property : ANCHORE_ADMIN_USERNAME - secretKey : dbPassword remoteRef : key : anchore-engine property : ANCHORE_DB_PASSWORD - secretKey : dbUrl remoteRef : key : anchore-engine property : db-url - secretKey : dbUser remoteRef : key : anchore-engine property : db-user - secretKey : postgresPassword remoteRef : key : anchore-engine property : postgres-password","title":"Hashicorp Vault"},{"location":"examples/anchore-engine-credentials/#aws-secrets-manager","text":"--- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : anchore-access-credentials namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-secrets-store kind : ClusterSecretStore target : name : anchore-access-credentials dataFrom : - extract : key : service/anchore-engine/engineAccess","title":"AWS Secrets Manager"},{"location":"examples/gitops-using-fluxcd/","text":"GitOps using FluxCD (v2) FluxCD is a GitOps operator for Kubernetes. It synchronizes the status of the cluster from manifests allocated in different repositories (Git or Helm). This approach fits perfectly with External Secrets on clusters which are dynamically created, to get credentials with no manual intervention from the beginning. Advantages This approach has several advantages as follows: Homogenize environments allowing developers to use the same toolset in Kind in the same way they do in the cloud provider distributions such as EKS or GKE. This accelerates the development Reduce security risks , because credentials can be easily obtained, so temptation to store them locally is reduced. Application compatibility increase : Applications are deployed in different ways, and sometimes they need to share credentials. This can be done using External Secrets as a wire for them at real time. Automation by default oh, come on! The approach FluxCD is composed by several controllers dedicated to manage different custom resources. The most important ones are Kustomization (to clarify, Flux one, not Kubernetes' one) and HelmRelease to deploy using the approaches of the same names. External Secrets can be deployed using Helm as explained here . The deployment includes the CRDs if enabled on the values.yaml , but after this, you need to deploy some SecretStore to start getting credentials from your secrets manager with External Secrets. The idea of this guide is to deploy the whole stack, using flux, needed by developers not to worry about the credentials, but only about the application and its code. The problem This can sound easy, but External Secrets is deployed using Helm, which is managed by the HelmController, and your custom resources, for example a ClusterSecretStore and the related Secret , are often deployed using a kustomization.yaml , which is deployed by the KustomizeController. Both controllers manage the resources independently, at different moments, with no possibility to wait each other. This means that we have a wonderful race condition where sometimes the CRs ( SecretStore , ClusterSecretStore ...) tries to be deployed before than the CRDs needed to recognize them. The solution Let's see the conditions to start working on a solution: The External Secrets operator is deployed with Helm, and admits disabling the CRDs deployment The race condition only affects the deployment of CustomResourceDefinition and the CRs needed later CRDs can be deployed directly from the Git repository of the project using a Flux Kustomization Required CRs can be deployed using a Flux Kustomization too, allowing dependency between CRDs and CRs All previous manifests can be applied with a Kubernetes kustomization Create the main kustomization To have a better view of things needed later, the first manifest to be created is the kustomization.yaml apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : # Deploy the Vault access secret - namespace.yaml - secret-token.yaml # Deploy the repositories - repositories.yaml # Deploy the CRDs - deployment-crds.yaml # Deploy the operator - deployment.yaml # Deploy default Custom Resources from 'crs' directory # INFO: This depends on the CRDs deployment. Will happen after it - deployment-crs.yaml Create the secret To access your secret manager, External Secrets needs some credentials. They are stored inside a Secret, which is intended to be deployed by automation as a good practise. This time, a placeholder called secret-token.yaml is show as an example: # The namespace.yaml first apiVersion : v1 kind : Namespace metadata : name : external-secrets apiVersion : v1 kind : Secret metadata : name : vault-token-global namespace : external-secrets stringData : # This token must be patched by overlays. Not here for security reasons token : change-me-placeholder Creating the references to repositories Create a manifest called repositories.yaml to store the references to external repositories for Flux # Reference to Helm repository apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : external-secrets namespace : flux-system spec : interval : 10m url : https://charts.external-secrets.io --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : external-secrets namespace : flux-system spec : interval : 10m ref : branch : main url : http://github.com/external-secrets/external-secrets Deploy the CRDs As mentioned, CRDs can be deployed using the official Helm package, but to solve the race condition, they will be deployed from our git repository using a Kustomization manifest called deployment-crds.yaml as follows: --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta2 kind : Kustomization metadata : name : external-secrets-crds namespace : flux-system spec : interval : 10m path : ./deploy/crds prune : true sourceRef : kind : GitRepository name : external-secrets Deploy the operator The operator is deployed using a HelmRelease manifest to deploy the Helm package, but due to the special race condition, the deployment must be disabled in the values of the manifest called deployment.yaml , as follows: # How to manage values files. Ref: https://fluxcd.io/docs/guides/helmreleases/#refer-to-values-inside-the-chart # How to inject values: https://fluxcd.io/docs/guides/helmreleases/#cloud-storage --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : external-secrets namespace : flux-system spec : # Override Release name to avoid the pattern Namespace-Release # Ref: https://fluxcd.io/docs/components/helm/api/#helm.toolkit.fluxcd.io/v2beta1.HelmRelease releaseName : external-secrets targetNamespace : external-secrets interval : 10m chart : spec : chart : external-secrets version : 0.3.9 sourceRef : kind : HelmRepository name : external-secrets namespace : flux-system values : installCRDs : false # Ref: https://fluxcd.io/docs/components/helm/api/#helm.toolkit.fluxcd.io/v2beta1.Install install : createNamespace : true Deploy the CRs Now, be ready for the arcane magic. Create a Kustomization manifest called deployment-crs.yaml with the following content: --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta2 kind : Kustomization metadata : name : external-secrets-crs namespace : flux-system spec : dependsOn : - name : external-secrets-crds interval : 10m path : ./infrastructure/external-secrets/crs prune : true sourceRef : kind : GitRepository name : flux-system There are several interesting details to see here, that finally solves the race condition: First one is the field dependsOn , which points to a previous Kustomization called external-secrets-crds . This dependency forces this deployment to wait for the other to be ready, before start being deployed. The reference to the place where to find the CRs path : ./infrastructure/external-secrets/crs sourceRef : kind : GitRepository name : flux-system Custom Resources will be searched in the relative path ./infrastructure/external-secrets/crs of the GitRepository called flux-system , which is a reference to the same repository that FluxCD watches to synchronize the cluster. With fewer words, a reference to itself, but going to another directory called crs Of course, allocate inside the mentioned path ./infrastructure/external-secrets/crs , all the desired CRs to be deployed, for example, a manifest clusterSecretStore.yaml to reach your Hashicorp Vault as follows: apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : vault-backend-global spec : provider : vault : server : \"https://vault.your-domain.com\" path : secret version : v2 auth : # points to a secret that contains a vault token # https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"vault-token-global\" key : \"token\" namespace : external-secrets Results At the end, the required files tree is shown in the following picture:","title":"FluxCD"},{"location":"examples/gitops-using-fluxcd/#gitops-using-fluxcd-v2","text":"FluxCD is a GitOps operator for Kubernetes. It synchronizes the status of the cluster from manifests allocated in different repositories (Git or Helm). This approach fits perfectly with External Secrets on clusters which are dynamically created, to get credentials with no manual intervention from the beginning.","title":"GitOps using FluxCD (v2)"},{"location":"examples/gitops-using-fluxcd/#advantages","text":"This approach has several advantages as follows: Homogenize environments allowing developers to use the same toolset in Kind in the same way they do in the cloud provider distributions such as EKS or GKE. This accelerates the development Reduce security risks , because credentials can be easily obtained, so temptation to store them locally is reduced. Application compatibility increase : Applications are deployed in different ways, and sometimes they need to share credentials. This can be done using External Secrets as a wire for them at real time. Automation by default oh, come on!","title":"Advantages"},{"location":"examples/gitops-using-fluxcd/#the-approach","text":"FluxCD is composed by several controllers dedicated to manage different custom resources. The most important ones are Kustomization (to clarify, Flux one, not Kubernetes' one) and HelmRelease to deploy using the approaches of the same names. External Secrets can be deployed using Helm as explained here . The deployment includes the CRDs if enabled on the values.yaml , but after this, you need to deploy some SecretStore to start getting credentials from your secrets manager with External Secrets. The idea of this guide is to deploy the whole stack, using flux, needed by developers not to worry about the credentials, but only about the application and its code.","title":"The approach"},{"location":"examples/gitops-using-fluxcd/#the-problem","text":"This can sound easy, but External Secrets is deployed using Helm, which is managed by the HelmController, and your custom resources, for example a ClusterSecretStore and the related Secret , are often deployed using a kustomization.yaml , which is deployed by the KustomizeController. Both controllers manage the resources independently, at different moments, with no possibility to wait each other. This means that we have a wonderful race condition where sometimes the CRs ( SecretStore , ClusterSecretStore ...) tries to be deployed before than the CRDs needed to recognize them.","title":"The problem"},{"location":"examples/gitops-using-fluxcd/#the-solution","text":"Let's see the conditions to start working on a solution: The External Secrets operator is deployed with Helm, and admits disabling the CRDs deployment The race condition only affects the deployment of CustomResourceDefinition and the CRs needed later CRDs can be deployed directly from the Git repository of the project using a Flux Kustomization Required CRs can be deployed using a Flux Kustomization too, allowing dependency between CRDs and CRs All previous manifests can be applied with a Kubernetes kustomization","title":"The solution"},{"location":"examples/gitops-using-fluxcd/#create-the-main-kustomization","text":"To have a better view of things needed later, the first manifest to be created is the kustomization.yaml apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : # Deploy the Vault access secret - namespace.yaml - secret-token.yaml # Deploy the repositories - repositories.yaml # Deploy the CRDs - deployment-crds.yaml # Deploy the operator - deployment.yaml # Deploy default Custom Resources from 'crs' directory # INFO: This depends on the CRDs deployment. Will happen after it - deployment-crs.yaml","title":"Create the main kustomization"},{"location":"examples/gitops-using-fluxcd/#create-the-secret","text":"To access your secret manager, External Secrets needs some credentials. They are stored inside a Secret, which is intended to be deployed by automation as a good practise. This time, a placeholder called secret-token.yaml is show as an example: # The namespace.yaml first apiVersion : v1 kind : Namespace metadata : name : external-secrets apiVersion : v1 kind : Secret metadata : name : vault-token-global namespace : external-secrets stringData : # This token must be patched by overlays. Not here for security reasons token : change-me-placeholder","title":"Create the secret"},{"location":"examples/gitops-using-fluxcd/#creating-the-references-to-repositories","text":"Create a manifest called repositories.yaml to store the references to external repositories for Flux # Reference to Helm repository apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : external-secrets namespace : flux-system spec : interval : 10m url : https://charts.external-secrets.io --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : external-secrets namespace : flux-system spec : interval : 10m ref : branch : main url : http://github.com/external-secrets/external-secrets","title":"Creating the references to repositories"},{"location":"examples/gitops-using-fluxcd/#deploy-the-crds","text":"As mentioned, CRDs can be deployed using the official Helm package, but to solve the race condition, they will be deployed from our git repository using a Kustomization manifest called deployment-crds.yaml as follows: --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta2 kind : Kustomization metadata : name : external-secrets-crds namespace : flux-system spec : interval : 10m path : ./deploy/crds prune : true sourceRef : kind : GitRepository name : external-secrets","title":"Deploy the CRDs"},{"location":"examples/gitops-using-fluxcd/#deploy-the-operator","text":"The operator is deployed using a HelmRelease manifest to deploy the Helm package, but due to the special race condition, the deployment must be disabled in the values of the manifest called deployment.yaml , as follows: # How to manage values files. Ref: https://fluxcd.io/docs/guides/helmreleases/#refer-to-values-inside-the-chart # How to inject values: https://fluxcd.io/docs/guides/helmreleases/#cloud-storage --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : external-secrets namespace : flux-system spec : # Override Release name to avoid the pattern Namespace-Release # Ref: https://fluxcd.io/docs/components/helm/api/#helm.toolkit.fluxcd.io/v2beta1.HelmRelease releaseName : external-secrets targetNamespace : external-secrets interval : 10m chart : spec : chart : external-secrets version : 0.3.9 sourceRef : kind : HelmRepository name : external-secrets namespace : flux-system values : installCRDs : false # Ref: https://fluxcd.io/docs/components/helm/api/#helm.toolkit.fluxcd.io/v2beta1.Install install : createNamespace : true","title":"Deploy the operator"},{"location":"examples/gitops-using-fluxcd/#deploy-the-crs","text":"Now, be ready for the arcane magic. Create a Kustomization manifest called deployment-crs.yaml with the following content: --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta2 kind : Kustomization metadata : name : external-secrets-crs namespace : flux-system spec : dependsOn : - name : external-secrets-crds interval : 10m path : ./infrastructure/external-secrets/crs prune : true sourceRef : kind : GitRepository name : flux-system There are several interesting details to see here, that finally solves the race condition: First one is the field dependsOn , which points to a previous Kustomization called external-secrets-crds . This dependency forces this deployment to wait for the other to be ready, before start being deployed. The reference to the place where to find the CRs path : ./infrastructure/external-secrets/crs sourceRef : kind : GitRepository name : flux-system Custom Resources will be searched in the relative path ./infrastructure/external-secrets/crs of the GitRepository called flux-system , which is a reference to the same repository that FluxCD watches to synchronize the cluster. With fewer words, a reference to itself, but going to another directory called crs Of course, allocate inside the mentioned path ./infrastructure/external-secrets/crs , all the desired CRs to be deployed, for example, a manifest clusterSecretStore.yaml to reach your Hashicorp Vault as follows: apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : vault-backend-global spec : provider : vault : server : \"https://vault.your-domain.com\" path : secret version : v2 auth : # points to a secret that contains a vault token # https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"vault-token-global\" key : \"token\" namespace : external-secrets","title":"Deploy the CRs"},{"location":"examples/gitops-using-fluxcd/#results","text":"At the end, the required files tree is shown in the following picture:","title":"Results"},{"location":"examples/jenkins-kubernetes-credentials/","text":"Getting started Jenkins is one of the most popular automation servers for continous integration, automation, scheduling jobs and for generic pipelining. It has an extensive set of plugins that extend or provide additional functionality including the kubernetes credentials plugin . This plugin takes kubernetes secrets and creates Jenkins credentials from them removing the need for manual entry of secrets, local storage and manual secret rotation. Examples The Jenkins credentials plugin uses labels and annotations on a kubernetes secret to create a Jenkins credential. The different types of Jenkins credentials that can be created are SecretText, privateSSHKey, UsernamePassword. SecretText Here are some examples of SecretText with the Hashicorp Vault and AWS External Secrets providers: Hashicorp Vault apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : sonarqube-api-token namespace : ci spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : sonarqube-api-token template : metadata : labels : \"jenkins.io/credentials-type\" : \"secretText\" annotations : \"jenkins.io/credentials-description\" : \"sonarqube api token\" data : text : >- {{ printf \"{{ .password | toString }}\" }} data : - secretKey : password remoteRef : key : jenkins-credentials property : sonarqube-api-token AWS Secrets Manager --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : sonarqube-api-token namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-secrets-store kind : ClusterSecretStore target : name : sonarqube-api-token template : metadata : labels : \"jenkins.io/credentials-type\" : \"secretText\" annotations : \"jenkins.io/credentials-description\" : \"Sonar API token\" data : - secretKey : text remoteRef : key : service/sonarqube/apiToken UsernamePassword Here are some examples of UsernamePassword credentials with the Hashicorp Vault and AWS External Secrets providers: Hashicorp Vault apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : harbor-chart-robot namespace : ci spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : harbor-chart-robot template : metadata : labels : \"jenkins.io/credentials-type\" : \"usernamePassword\" annotations : \"jenkins.io/credentials-description\" : \"harbor chart robot\" data : username : >- {{ printf \"{{ .username | toString }}\" }} password : >- {{ printf \"{{ .password | toString }}\" }} data : - secretKey : username remoteRef : key : my-kv property : harbor-chart-robot-username - secretKey : password remoteRef : key : my-kv property : harbor-chart-robot-token AWS Secrets Manager --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : harbor-chart-robot namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-secrets-store kind : ClusterSecretStore target : name : harbor-chart-robot template : metadata : labels : \"jenkins.io/credentials-type\" : \"usernamePassword\" annotations : \"jenkins.io/credentials-description\" : \"harbor chart robot access\" data : - secretKey : password remoteRef : key : service/harbor/chartRobot property : password - secretKey : username remoteRef : key : service/harbor/chartRobot property : username basicSSHUserPrivateKey Here are some examples of basicSSHUserPrivateKey credentials with the Hashicorp Vault and AWS External Secrets providers: Hashicorp Vault apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : github-ssh-access namespace : ci spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : github-ssh-access template : metadata : labels : \"jenkins.io/credentials-type\" : \"basicSSHUserPrivateKey\" annotations : \"jenkins.io/credentials-description\" : \"github-ssh-access key\" data : username : >- {{ printf \"{{ .username | toString }}\" }} privateKey : >- {{ printf \"{{ .privateKey | toString }}\" }} data : - secretKey : username remoteRef : key : my-kv property : github-ssh-access-username - secretKey : privateKey remoteRef : key : my-kv property : github-ssh-access-private-key AWS Secrets Manager --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : github-ssh-access namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-parameter-store kind : ClusterSecretStore target : name : github-ssh-access template : metadata : labels : \"jenkins.io/credentials-type\" : \"basicSSHUserPrivateKey\" annotations : \"jenkins.io/credentials-description\" : \"github-ssh-access key\" data : - secretKey : username remoteRef : key : /service/github/sshUserPrivateKeyUserName - secretKey : privateKey remoteRef : key : /service/github/sshUserPrivateKey","title":"Jenkins"},{"location":"examples/jenkins-kubernetes-credentials/#getting-started","text":"Jenkins is one of the most popular automation servers for continous integration, automation, scheduling jobs and for generic pipelining. It has an extensive set of plugins that extend or provide additional functionality including the kubernetes credentials plugin . This plugin takes kubernetes secrets and creates Jenkins credentials from them removing the need for manual entry of secrets, local storage and manual secret rotation.","title":"Getting started"},{"location":"examples/jenkins-kubernetes-credentials/#examples","text":"The Jenkins credentials plugin uses labels and annotations on a kubernetes secret to create a Jenkins credential. The different types of Jenkins credentials that can be created are SecretText, privateSSHKey, UsernamePassword.","title":"Examples"},{"location":"examples/jenkins-kubernetes-credentials/#secrettext","text":"Here are some examples of SecretText with the Hashicorp Vault and AWS External Secrets providers:","title":"SecretText"},{"location":"examples/jenkins-kubernetes-credentials/#hashicorp-vault","text":"apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : sonarqube-api-token namespace : ci spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : sonarqube-api-token template : metadata : labels : \"jenkins.io/credentials-type\" : \"secretText\" annotations : \"jenkins.io/credentials-description\" : \"sonarqube api token\" data : text : >- {{ printf \"{{ .password | toString }}\" }} data : - secretKey : password remoteRef : key : jenkins-credentials property : sonarqube-api-token","title":"Hashicorp Vault"},{"location":"examples/jenkins-kubernetes-credentials/#aws-secrets-manager","text":"--- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : sonarqube-api-token namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-secrets-store kind : ClusterSecretStore target : name : sonarqube-api-token template : metadata : labels : \"jenkins.io/credentials-type\" : \"secretText\" annotations : \"jenkins.io/credentials-description\" : \"Sonar API token\" data : - secretKey : text remoteRef : key : service/sonarqube/apiToken","title":"AWS Secrets Manager"},{"location":"examples/jenkins-kubernetes-credentials/#usernamepassword","text":"Here are some examples of UsernamePassword credentials with the Hashicorp Vault and AWS External Secrets providers:","title":"UsernamePassword"},{"location":"examples/jenkins-kubernetes-credentials/#hashicorp-vault_1","text":"apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : harbor-chart-robot namespace : ci spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : harbor-chart-robot template : metadata : labels : \"jenkins.io/credentials-type\" : \"usernamePassword\" annotations : \"jenkins.io/credentials-description\" : \"harbor chart robot\" data : username : >- {{ printf \"{{ .username | toString }}\" }} password : >- {{ printf \"{{ .password | toString }}\" }} data : - secretKey : username remoteRef : key : my-kv property : harbor-chart-robot-username - secretKey : password remoteRef : key : my-kv property : harbor-chart-robot-token","title":"Hashicorp Vault"},{"location":"examples/jenkins-kubernetes-credentials/#aws-secrets-manager_1","text":"--- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : harbor-chart-robot namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-secrets-store kind : ClusterSecretStore target : name : harbor-chart-robot template : metadata : labels : \"jenkins.io/credentials-type\" : \"usernamePassword\" annotations : \"jenkins.io/credentials-description\" : \"harbor chart robot access\" data : - secretKey : password remoteRef : key : service/harbor/chartRobot property : password - secretKey : username remoteRef : key : service/harbor/chartRobot property : username","title":"AWS Secrets Manager"},{"location":"examples/jenkins-kubernetes-credentials/#basicsshuserprivatekey","text":"Here are some examples of basicSSHUserPrivateKey credentials with the Hashicorp Vault and AWS External Secrets providers:","title":"basicSSHUserPrivateKey"},{"location":"examples/jenkins-kubernetes-credentials/#hashicorp-vault_2","text":"apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : github-ssh-access namespace : ci spec : refreshInterval : 1m secretStoreRef : name : vault-backend kind : ClusterSecretStore target : name : github-ssh-access template : metadata : labels : \"jenkins.io/credentials-type\" : \"basicSSHUserPrivateKey\" annotations : \"jenkins.io/credentials-description\" : \"github-ssh-access key\" data : username : >- {{ printf \"{{ .username | toString }}\" }} privateKey : >- {{ printf \"{{ .privateKey | toString }}\" }} data : - secretKey : username remoteRef : key : my-kv property : github-ssh-access-username - secretKey : privateKey remoteRef : key : my-kv property : github-ssh-access-private-key","title":"Hashicorp Vault"},{"location":"examples/jenkins-kubernetes-credentials/#aws-secrets-manager_2","text":"--- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : github-ssh-access namespace : ci spec : refreshInterval : 1m secretStoreRef : name : cluster-parameter-store kind : ClusterSecretStore target : name : github-ssh-access template : metadata : labels : \"jenkins.io/credentials-type\" : \"basicSSHUserPrivateKey\" annotations : \"jenkins.io/credentials-description\" : \"github-ssh-access key\" data : - secretKey : username remoteRef : key : /service/github/sshUserPrivateKeyUserName - secretKey : privateKey remoteRef : key : /service/github/sshUserPrivateKey","title":"AWS Secrets Manager"},{"location":"guides/all-keys-one-secret/","text":"All Keys, One Secret To get multiple key-values from an external secret, not having to worry about how many, or what these keys are, we have to use the dataFrom field of the ExternalSecret resource, instead of the data field. We will give an example here with the gcp provider (should work with other providers in the same way). Please follow the authentication and SecretStore steps of the Google Cloud Secrets Manager guide to setup access to your google cloud account first. Then create a secret in Google Cloud Secret Manager that contains a JSON string with multiple key values like this: Let's call this secret all-keys-example-secret on Google Cloud. Creating dataFrom external secret Now, when creating our ExternalSecret resource, instead of using the data field, we use the dataFrom field: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h # rate SecretManager pulls GCPSM secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created creationPolicy : Owner dataFrom : - extract : key : all-keys-example-secret # name of the GCPSM secret To check both values we can run: kubectl get secret secret-to-be-created -n <namespace> -o jsonpath='{.data.username}' | base64 -d kubectl get secret secret-to-be-created -n <namespace> -o jsonpath='{.data.surname}' | base64 -d","title":"All keys, One secret"},{"location":"guides/all-keys-one-secret/#all-keys-one-secret","text":"To get multiple key-values from an external secret, not having to worry about how many, or what these keys are, we have to use the dataFrom field of the ExternalSecret resource, instead of the data field. We will give an example here with the gcp provider (should work with other providers in the same way). Please follow the authentication and SecretStore steps of the Google Cloud Secrets Manager guide to setup access to your google cloud account first. Then create a secret in Google Cloud Secret Manager that contains a JSON string with multiple key values like this: Let's call this secret all-keys-example-secret on Google Cloud.","title":"All Keys, One Secret"},{"location":"guides/all-keys-one-secret/#creating-datafrom-external-secret","text":"Now, when creating our ExternalSecret resource, instead of using the data field, we use the dataFrom field: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h # rate SecretManager pulls GCPSM secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created creationPolicy : Owner dataFrom : - extract : key : all-keys-example-secret # name of the GCPSM secret To check both values we can run: kubectl get secret secret-to-be-created -n <namespace> -o jsonpath='{.data.username}' | base64 -d kubectl get secret secret-to-be-created -n <namespace> -o jsonpath='{.data.surname}' | base64 -d","title":"Creating dataFrom external secret"},{"location":"guides/common-k8s-secret-types/","text":"A few common k8s secret types examples Here we will give some examples of how to work with a few common k8s secret types. We will give this examples here with the gcp provider (should work with other providers in the same way). Please also check the guides on Advanced Templating to understand the details. Please follow the authentication and SecretStore steps of the Google Cloud Secrets Manager guide to setup access to your google cloud account first. Dockerconfigjson example First create a secret in Google Cloud Secrets Manager containing your docker config: Let's call this secret docker-config-example on Google Cloud. Then create a ExternalSecret resource taking advantage of templating to populate the generated secret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : dk-cfg-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : template : type : kubernetes.io/dockerconfigjson data : .dockerconfigjson : \"{{ .mysecret | toString }}\" name : secret-to-be-created creationPolicy : Owner data : - secretKey : mysecret remoteRef : key : docker-config-example For Helm users: since Helm interprets the template above, the ExternalSecret resource can be written this way: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : dk-cfg-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : template : type : kubernetes.io/dockerconfigjson engineVersion : v2 data : .dockerconfigjson : \"{{ `{{ .mysecret }}` }}\" name : secret-to-be-created creationPolicy : Owner data : - secretKey : mysecret remoteRef : key : docker-config-example For more information, please see this issue This will generate a valid dockerconfigjson secret for you to use! You can get the final value with: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data\\.dockerconfigjson}\" | base64 -d TLS Cert example We are assuming here that you already have valid certificates, maybe generated with letsencrypt or any other CA. So to simplify you can use openssl to generate a single secret pkcs12 cert based on your cert.pem and privkey.pen files. openssl pkcs12 -export -out certificate.p12 -inkey privkey.pem -in cert.pem With a certificate.p12 you can upload it to Google Cloud Secrets Manager: And now you can create an ExternalSecret that gets it. You will end up with a k8s secret of type tls with pem values. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template-tls-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : name : secret-to-be-created # this is how the Kind=Secret will look like template : type : kubernetes.io/tls data : tls.crt : \"{{ .mysecret | pkcs12cert | pemCertificate }}\" tls.key : \"{{ .mysecret | pkcs12key | pemPrivateKey }}\" data : # this is a pkcs12 archive that contains # a cert and a private key - secretKey : mysecret remoteRef : key : ssl-certificate-p12-example You can get their values with: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data.tls\\.crt}\" | base64 -d kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data.tls\\.key}\" | base64 -d SSH Auth example Add the ssh privkey to a new Google Cloud Secrets Manager secret: And now you can create an ExternalSecret that gets it. You will end up with a k8s secret of type ssh-auth with the privatekey value. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : ssh-auth-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : name : secret-to-be-created template : type : kubernetes.io/ssh-auth data : ssh-privatekey : \"{{ .mysecret | toString }}\" name : secret-to-be-created creationPolicy : Owner data : - secretKey : mysecret remoteRef : key : ssh-priv-key-example You can get the privkey value with: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data.ssh-privatekey}\" | base64 -d More examples We need more examples here Feel free to contribute with our docs and add more examples here!","title":"Common K8S Secret Types"},{"location":"guides/common-k8s-secret-types/#a-few-common-k8s-secret-types-examples","text":"Here we will give some examples of how to work with a few common k8s secret types. We will give this examples here with the gcp provider (should work with other providers in the same way). Please also check the guides on Advanced Templating to understand the details. Please follow the authentication and SecretStore steps of the Google Cloud Secrets Manager guide to setup access to your google cloud account first.","title":"A few common k8s secret types examples"},{"location":"guides/common-k8s-secret-types/#dockerconfigjson-example","text":"First create a secret in Google Cloud Secrets Manager containing your docker config: Let's call this secret docker-config-example on Google Cloud. Then create a ExternalSecret resource taking advantage of templating to populate the generated secret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : dk-cfg-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : template : type : kubernetes.io/dockerconfigjson data : .dockerconfigjson : \"{{ .mysecret | toString }}\" name : secret-to-be-created creationPolicy : Owner data : - secretKey : mysecret remoteRef : key : docker-config-example For Helm users: since Helm interprets the template above, the ExternalSecret resource can be written this way: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : dk-cfg-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : template : type : kubernetes.io/dockerconfigjson engineVersion : v2 data : .dockerconfigjson : \"{{ `{{ .mysecret }}` }}\" name : secret-to-be-created creationPolicy : Owner data : - secretKey : mysecret remoteRef : key : docker-config-example For more information, please see this issue This will generate a valid dockerconfigjson secret for you to use! You can get the final value with: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data\\.dockerconfigjson}\" | base64 -d","title":"Dockerconfigjson example"},{"location":"guides/common-k8s-secret-types/#tls-cert-example","text":"We are assuming here that you already have valid certificates, maybe generated with letsencrypt or any other CA. So to simplify you can use openssl to generate a single secret pkcs12 cert based on your cert.pem and privkey.pen files. openssl pkcs12 -export -out certificate.p12 -inkey privkey.pem -in cert.pem With a certificate.p12 you can upload it to Google Cloud Secrets Manager: And now you can create an ExternalSecret that gets it. You will end up with a k8s secret of type tls with pem values. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template-tls-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : name : secret-to-be-created # this is how the Kind=Secret will look like template : type : kubernetes.io/tls data : tls.crt : \"{{ .mysecret | pkcs12cert | pemCertificate }}\" tls.key : \"{{ .mysecret | pkcs12key | pemPrivateKey }}\" data : # this is a pkcs12 archive that contains # a cert and a private key - secretKey : mysecret remoteRef : key : ssl-certificate-p12-example You can get their values with: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data.tls\\.crt}\" | base64 -d kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data.tls\\.key}\" | base64 -d","title":"TLS Cert example"},{"location":"guides/common-k8s-secret-types/#ssh-auth-example","text":"Add the ssh privkey to a new Google Cloud Secrets Manager secret: And now you can create an ExternalSecret that gets it. You will end up with a k8s secret of type ssh-auth with the privatekey value. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : ssh-auth-example spec : refreshInterval : 1h secretStoreRef : name : example kind : SecretStore target : name : secret-to-be-created template : type : kubernetes.io/ssh-auth data : ssh-privatekey : \"{{ .mysecret | toString }}\" name : secret-to-be-created creationPolicy : Owner data : - secretKey : mysecret remoteRef : key : ssh-priv-key-example You can get the privkey value with: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = \"{.data.ssh-privatekey}\" | base64 -d","title":"SSH Auth example"},{"location":"guides/common-k8s-secret-types/#more-examples","text":"We need more examples here Feel free to contribute with our docs and add more examples here!","title":"More examples"},{"location":"guides/controller-class/","text":"Controller Classes NOTE: this feature is experimental and not highly tested Controller classes are a property set during the deployment that allows multiple controllers to work in a group of workload. It works by separating which secretStores are going to be attributed to which controller. For the behavior of a single controller, no extra configuration is needed. Setting up Controller Class In order to deploy the controller with a specific class, install the helm charts specifying the controller class, and create a SecretStore with the appropriate spec.controller values: helm install custom-external-secrets external-secrets/external-secrets --set controllerClass=custom apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : controller-custom-example spec : #define the controller label to the matching value of the deployment controller : custom #configure provider the same way provider : vault : server : \"http://vault.default:8200\" path : \"secret\" version : \"v2\" auth : kubernetes : mountPath : \"kubernetes\" role : \"demo-role\" Now, any ExternalSecret bound to this secret store will be evaluated by the operator with the controllerClass custom. Note: Any SecretStore without spec.controller set will be considered as valid by any operator, regardless of their respective controllerClasses.","title":"Controller Classes"},{"location":"guides/controller-class/#controller-classes","text":"NOTE: this feature is experimental and not highly tested Controller classes are a property set during the deployment that allows multiple controllers to work in a group of workload. It works by separating which secretStores are going to be attributed to which controller. For the behavior of a single controller, no extra configuration is needed.","title":"Controller Classes"},{"location":"guides/controller-class/#setting-up-controller-class","text":"In order to deploy the controller with a specific class, install the helm charts specifying the controller class, and create a SecretStore with the appropriate spec.controller values: helm install custom-external-secrets external-secrets/external-secrets --set controllerClass=custom apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : controller-custom-example spec : #define the controller label to the matching value of the deployment controller : custom #configure provider the same way provider : vault : server : \"http://vault.default:8200\" path : \"secret\" version : \"v2\" auth : kubernetes : mountPath : \"kubernetes\" role : \"demo-role\" Now, any ExternalSecret bound to this secret store will be evaluated by the operator with the controllerClass custom. Note: Any SecretStore without spec.controller set will be considered as valid by any operator, regardless of their respective controllerClasses.","title":"Setting up Controller Class"},{"location":"guides/datafrom-rewrite/","text":"Rewriting Keys in DataFrom When calling out an ExternalSecret with dataFrom.extract or dataFrom.find , it is possible that you end up with a kubernetes secret that has conflicts in the key names, or that you simply want to remove a common path from the secret keys. In order to do so, it is possible to define a set of rewrite operations using dataFrom.rewrite . These operations can be stacked, hence allowing complex manipulations of the secret keys. Rewrite operations are all applied before ConversionStrategy is applied. Methods Regexp This method implements rewriting through the use of regular expressions. It needs a source and a target field. The source field is where the definition of the matching regular expression goes, where the target field is where the replacing expression goes. Some considerations about the impelementation of Regexp Rewrite: The input of a subsequent rewrite operation are the outputs of the previous rewrite. If a given set of keys do not match any Rewrite operation, there will be no error. Rather, the original keys will be used. If a source is not a compilable regexp expression, an error will be produced and the external secret goes into a error state. Examples Removing a common path from find operations The following ExternalSecret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : backend target : name : secret-to-be-created dataFrom : - find : path : path/to/my name : regexp : secrets rewrite : - regexp : source : \"path/to/my/secrets/(.*)\" target : \"$1\" Will get all the secrets matching path/to/my/secrets/* and then rewrite them by removing the common path away. In this example, if we had the following secrets available in the provider: path/to/my/secrets/username path/to/my/secrets/password the output kubernetes secret would be: apiVersion : v1 kind : Secret type : Opaque data : username : ... password : ... Avoiding key collisions The following ExternalSecret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : backend target : name : secret-to-be-created dataFrom : - extract : key : my-secrets-dev rewrite : - regexp : source : \"(.*)\" target : \"dev-$1\" - extract : key : my-secrets-prod rewrite : - regexp : source : \"(.*)\" target : \"prod-$1\" Will allow two secrets with the same JSON keys to be imported into a Kubernetes Secret without any conflict. In this example, if we had the following secrets available in the provider: { \"my-secrets-dev\" : { \"password\" : \"bar\" , }, \"my-secrets-prod\" : { \"password\" : \"safebar\" , } } the output kubernetes secret would be: apiVersion : v1 kind : Secret type : Opaque data : dev_password : YmFy #bar prod_password : c2FmZWJhcg== #safebar Remove invalid characters The following ExternalSecret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : backend target : name : secret-to-be-created dataFrom : - extract : key : development rewrite : - regexp : source : \"[^a-zA-Z0-9 -]\" target : \"_\" Will remove invalid characters from the secret key. In this example, if we had the following secrets available in the provider: { \"development\" : { \"foo/bar\" : \"1111\" , \"foo$baz\" : \"2222\" } } the output kubernetes secret would be: apiVersion : v1 kind : Secret type : Opaque data : foo_bar : MTExMQ== #1111 foo_baz : MjIyMg== #2222 Limitations Regexp Rewrite is based on golang regexp , which in turns implements RE2 regexp language. There a a series of known limitations to this implementation, such as: Lack of ability to do lookaheads or lookbehinds; Lack of negation expressions; Lack of support for conditional branches; Lack of support for possessive repetitions. A list of compatibility and known limitations considering other commonly used regexp frameworks (such as PCRE and PERL) are listed here .","title":"Rewriting Keys"},{"location":"guides/datafrom-rewrite/#rewriting-keys-in-datafrom","text":"When calling out an ExternalSecret with dataFrom.extract or dataFrom.find , it is possible that you end up with a kubernetes secret that has conflicts in the key names, or that you simply want to remove a common path from the secret keys. In order to do so, it is possible to define a set of rewrite operations using dataFrom.rewrite . These operations can be stacked, hence allowing complex manipulations of the secret keys. Rewrite operations are all applied before ConversionStrategy is applied.","title":"Rewriting Keys in DataFrom"},{"location":"guides/datafrom-rewrite/#methods","text":"","title":"Methods"},{"location":"guides/datafrom-rewrite/#regexp","text":"This method implements rewriting through the use of regular expressions. It needs a source and a target field. The source field is where the definition of the matching regular expression goes, where the target field is where the replacing expression goes. Some considerations about the impelementation of Regexp Rewrite: The input of a subsequent rewrite operation are the outputs of the previous rewrite. If a given set of keys do not match any Rewrite operation, there will be no error. Rather, the original keys will be used. If a source is not a compilable regexp expression, an error will be produced and the external secret goes into a error state.","title":"Regexp"},{"location":"guides/datafrom-rewrite/#examples","text":"","title":"Examples"},{"location":"guides/datafrom-rewrite/#removing-a-common-path-from-find-operations","text":"The following ExternalSecret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : backend target : name : secret-to-be-created dataFrom : - find : path : path/to/my name : regexp : secrets rewrite : - regexp : source : \"path/to/my/secrets/(.*)\" target : \"$1\" Will get all the secrets matching path/to/my/secrets/* and then rewrite them by removing the common path away. In this example, if we had the following secrets available in the provider: path/to/my/secrets/username path/to/my/secrets/password the output kubernetes secret would be: apiVersion : v1 kind : Secret type : Opaque data : username : ... password : ...","title":"Removing a common path from find operations"},{"location":"guides/datafrom-rewrite/#avoiding-key-collisions","text":"The following ExternalSecret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : backend target : name : secret-to-be-created dataFrom : - extract : key : my-secrets-dev rewrite : - regexp : source : \"(.*)\" target : \"dev-$1\" - extract : key : my-secrets-prod rewrite : - regexp : source : \"(.*)\" target : \"prod-$1\" Will allow two secrets with the same JSON keys to be imported into a Kubernetes Secret without any conflict. In this example, if we had the following secrets available in the provider: { \"my-secrets-dev\" : { \"password\" : \"bar\" , }, \"my-secrets-prod\" : { \"password\" : \"safebar\" , } } the output kubernetes secret would be: apiVersion : v1 kind : Secret type : Opaque data : dev_password : YmFy #bar prod_password : c2FmZWJhcg== #safebar","title":"Avoiding key collisions"},{"location":"guides/datafrom-rewrite/#remove-invalid-characters","text":"The following ExternalSecret: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : backend target : name : secret-to-be-created dataFrom : - extract : key : development rewrite : - regexp : source : \"[^a-zA-Z0-9 -]\" target : \"_\" Will remove invalid characters from the secret key. In this example, if we had the following secrets available in the provider: { \"development\" : { \"foo/bar\" : \"1111\" , \"foo$baz\" : \"2222\" } } the output kubernetes secret would be: apiVersion : v1 kind : Secret type : Opaque data : foo_bar : MTExMQ== #1111 foo_baz : MjIyMg== #2222","title":"Remove invalid characters"},{"location":"guides/datafrom-rewrite/#limitations","text":"Regexp Rewrite is based on golang regexp , which in turns implements RE2 regexp language. There a a series of known limitations to this implementation, such as: Lack of ability to do lookaheads or lookbehinds; Lack of negation expressions; Lack of support for conditional branches; Lack of support for possessive repetitions. A list of compatibility and known limitations considering other commonly used regexp frameworks (such as PCRE and PERL) are listed here .","title":"Limitations"},{"location":"guides/decoding-strategy/","text":"Decoding Strategies The External Secrets Operator has the feature to allow multiple decoding strategies during an object generation. The decodingStrategy field allows the user to set the following Decoding Strategies based on their needs. decodingStrategy can be placed under spec.data.remoteRef , spec.dataFrom.extract or spec.dataFrom.find . It will configure the decoding strategy for that specific operation, leaving others with the default behavior if not set. None (default) ESO will not try to decode the secret value. Base64 ESO will try to decode the secret value using base64 method. If the decoding fails, an error is produced. Base64URL ESO will try to decode the secret value using base64url method. If the decoding fails, an error is produced. Auto ESO will try to decode using Base64/Base64URL strategies. If the decoding fails, ESO will apply decoding strategy None. No error is produced to the user. Examples Setting Decoding strategy Auto in a DataFrom.Extract Given that we have the given secret information: { \"name\": \"Gustavo\", \"surname\": \"Fring\", \"address\":\"aGFwcHkgc3RyZWV0\", } if we apply the following dataFrom: spec: dataFrom: - extract: key: my-secret decodingStrategy: Auto It will render the following Kubernetes Secret: data: name: R3VzdGF2bw== #Gustavo surname: RnJpbmc= #Fring address: aGFwcHkgc3RyZWV0 #happy street Limitations At this time, decoding Strategy Auto is only trying to check if the original input is valid to perform Base64 operations. This means that some non-encoded secret values might end up being decoded, producing gibberish. This is the case for numbered values like 123456 or some specially crafted string values such as happy/street . Note If you are using decodeStrategy: Auto and start to see ESO pulling completely wrong secret values into your kubernetes secret, consider changing it to None to investigate it.","title":"Decoding Strategies"},{"location":"guides/decoding-strategy/#decoding-strategies","text":"The External Secrets Operator has the feature to allow multiple decoding strategies during an object generation. The decodingStrategy field allows the user to set the following Decoding Strategies based on their needs. decodingStrategy can be placed under spec.data.remoteRef , spec.dataFrom.extract or spec.dataFrom.find . It will configure the decoding strategy for that specific operation, leaving others with the default behavior if not set.","title":"Decoding Strategies"},{"location":"guides/decoding-strategy/#none-default","text":"ESO will not try to decode the secret value.","title":"None (default)"},{"location":"guides/decoding-strategy/#base64","text":"ESO will try to decode the secret value using base64 method. If the decoding fails, an error is produced.","title":"Base64"},{"location":"guides/decoding-strategy/#base64url","text":"ESO will try to decode the secret value using base64url method. If the decoding fails, an error is produced.","title":"Base64URL"},{"location":"guides/decoding-strategy/#auto","text":"ESO will try to decode using Base64/Base64URL strategies. If the decoding fails, ESO will apply decoding strategy None. No error is produced to the user.","title":"Auto"},{"location":"guides/decoding-strategy/#examples","text":"","title":"Examples"},{"location":"guides/decoding-strategy/#setting-decoding-strategy-auto-in-a-datafromextract","text":"Given that we have the given secret information: { \"name\": \"Gustavo\", \"surname\": \"Fring\", \"address\":\"aGFwcHkgc3RyZWV0\", } if we apply the following dataFrom: spec: dataFrom: - extract: key: my-secret decodingStrategy: Auto It will render the following Kubernetes Secret: data: name: R3VzdGF2bw== #Gustavo surname: RnJpbmc= #Fring address: aGFwcHkgc3RyZWV0 #happy street","title":"Setting Decoding strategy Auto in a DataFrom.Extract"},{"location":"guides/decoding-strategy/#limitations","text":"At this time, decoding Strategy Auto is only trying to check if the original input is valid to perform Base64 operations. This means that some non-encoded secret values might end up being decoded, producing gibberish. This is the case for numbered values like 123456 or some specially crafted string values such as happy/street . Note If you are using decodeStrategy: Auto and start to see ESO pulling completely wrong secret values into your kubernetes secret, consider changing it to None to investigate it.","title":"Limitations"},{"location":"guides/getallsecrets/","text":"Fetching information from multiple secrets In some use cases, it might be impractical to bundle all sensitive information into a single secret, or even it is not possible to fully know a given secret name. In such cases, it is possible that an user might need to sync multiple secrets from an external provider into a single Kubernetes Secret. This is possible to be done in external-secrets with the dataFrom.find option. Note The secret's contents as defined in the provider are going to be stored in the kubernetes secret as a single key. Currently, it possible to apply a decoding Strategy during a find operation, but only at the secret level (e.g. if a secret is a JSON with some B64 encoded data within, decodingStrategy: Auto would not decode it) Fetching secrets matching a given name pattern To fetch multiple secrets matching a name pattern from a common SecretStore you can apply the following manifest: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : find-by-tags spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created dataFrom : - find : name : regexp : \"key\" Suppose we contain secrets /path/key1 , key2/path , and path/to/keyring with their respective values. The above YAML will produce the following kubernetes Secret: _path_key1 : Cg== key2_path : Cg== path_to_keyring : Cg== Fetching secrets matching a set of metadata tags To fetch multiple secrets matching a name pattern from a common SecretStore you can apply the following manifest: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : find-by-tags spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created dataFrom : - find : tags : environment : \"prod\" application : \"app-name\" This will match any secrets containing all of the metadata labels in the tags parameter. At least one tag must be provided in order to allow finding secrets by metadata tags. Searching only in a given path Some providers support filtering out a find operation only to a given path, instead of the root path. In order to use this feature, you can pass find.path to filter out these secrets into only this path, instead of the root path. Avoiding name conflicts By default, kubernetes Secrets accepts only a given range of characters. Find operations will automatically replace any not allowed character with a _ . So if we have a given secret a_c and a/c would lead to a naming conflict. If you happen to have a case where a conflict is happening, you can use the rewrite block to apply a regexp on one of the find operations (for more information please refer to Rewriting Keys from DataFrom ). You can also set dataFrom.find.conversionStrategy: Unicode to reduce the collistion probability. When using Unicode , any invalid character will be replaced by its unicode, in the form of _UXXXX_ . In this case, the available kubernetes keys would be a_c and a_U2215_c , hence avoiding most of possible conflicts. PRs welcome Some providers might not have the implementation needed for fetching multiple secrets. If that's your case, please feel free to contribute!","title":"Getting Multiple Secrets"},{"location":"guides/getallsecrets/#fetching-information-from-multiple-secrets","text":"In some use cases, it might be impractical to bundle all sensitive information into a single secret, or even it is not possible to fully know a given secret name. In such cases, it is possible that an user might need to sync multiple secrets from an external provider into a single Kubernetes Secret. This is possible to be done in external-secrets with the dataFrom.find option. Note The secret's contents as defined in the provider are going to be stored in the kubernetes secret as a single key. Currently, it possible to apply a decoding Strategy during a find operation, but only at the secret level (e.g. if a secret is a JSON with some B64 encoded data within, decodingStrategy: Auto would not decode it)","title":"Fetching information from multiple secrets"},{"location":"guides/getallsecrets/#fetching-secrets-matching-a-given-name-pattern","text":"To fetch multiple secrets matching a name pattern from a common SecretStore you can apply the following manifest: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : find-by-tags spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created dataFrom : - find : name : regexp : \"key\" Suppose we contain secrets /path/key1 , key2/path , and path/to/keyring with their respective values. The above YAML will produce the following kubernetes Secret: _path_key1 : Cg== key2_path : Cg== path_to_keyring : Cg==","title":"Fetching secrets matching a given name pattern"},{"location":"guides/getallsecrets/#fetching-secrets-matching-a-set-of-metadata-tags","text":"To fetch multiple secrets matching a name pattern from a common SecretStore you can apply the following manifest: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : find-by-tags spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created dataFrom : - find : tags : environment : \"prod\" application : \"app-name\" This will match any secrets containing all of the metadata labels in the tags parameter. At least one tag must be provided in order to allow finding secrets by metadata tags.","title":"Fetching secrets matching a set of metadata tags"},{"location":"guides/getallsecrets/#searching-only-in-a-given-path","text":"Some providers support filtering out a find operation only to a given path, instead of the root path. In order to use this feature, you can pass find.path to filter out these secrets into only this path, instead of the root path.","title":"Searching only in a given path"},{"location":"guides/getallsecrets/#avoiding-name-conflicts","text":"By default, kubernetes Secrets accepts only a given range of characters. Find operations will automatically replace any not allowed character with a _ . So if we have a given secret a_c and a/c would lead to a naming conflict. If you happen to have a case where a conflict is happening, you can use the rewrite block to apply a regexp on one of the find operations (for more information please refer to Rewriting Keys from DataFrom ). You can also set dataFrom.find.conversionStrategy: Unicode to reduce the collistion probability. When using Unicode , any invalid character will be replaced by its unicode, in the form of _UXXXX_ . In this case, the available kubernetes keys would be a_c and a_U2215_c , hence avoiding most of possible conflicts. PRs welcome Some providers might not have the implementation needed for fetching multiple secrets. If that's your case, please feel free to contribute!","title":"Avoiding name conflicts"},{"location":"guides/getting-started/","text":"Getting started External-secrets runs within your Kubernetes cluster as a deployment resource. It utilizes CustomResourceDefinitions to configure access to secret providers through SecretStore resources and manages Kubernetes secret resources with ExternalSecret resources. Note: The minimum supported version of Kubernetes is 1.16.0 . Users still running Kubernetes v1.15 or below should upgrade to a supported version before installing external-secrets. Installing with Helm To automatically install and manage the CRDs as part of your Helm release, you must add the --set installCRDs=true flag to your Helm installation command. Uncomment the relevant line in the next steps to enable this. Option 1: Install from chart repository helm repo add external-secrets https://charts.external-secrets.io helm install external-secrets \\ external-secrets/external-secrets \\ -n external-secrets \\ --create-namespace \\ # --set installCRDs=true Option 2: Install chart from local build Build and install the Helm chart locally after cloning the repository. make helm.build helm install external-secrets \\ ./bin/chart/external-secrets.tgz \\ -n external-secrets \\ --create-namespace \\ # --set installCRDs=true Create a secret containing your AWS credentials echo -n 'KEYID' > ./access-key echo -n 'SECRETKEY' > ./secret-access-key kubectl create secret generic awssm-secret --from-file = ./access-key --from-file = ./secret-access-key Create your first SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : us-east-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key Create your first ExternalSecret apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property dataFrom : - extract : key : remote-key-in-the-provider kubectl describe externalsecret example # [...] Name: example Status: Conditions: Last Transition Time: 2021 -02-24T16:45:23Z Message: Secret was synced Reason: SecretSynced Status: True Type: Ready Refresh Time: 2021 -02-24T16:45:24Z Events: <none> For more advanced examples, please read the other guides . Installing with OLM External-secrets can be managed by Operator Lifecycle Manager (OLM) via an installer operator. It is made available through OperatorHub.io , this installation method is suited best for OpenShift. See installation instructions on the external-secrets-operator package. Uninstalling Before continuing, ensure that all external-secret resources that have been created by users have been deleted. You can check for any existing resources with the following command: kubectl get SecretStores,ClusterSecretStores,ExternalSecrets --all-namespaces Once all these resources have been deleted you are ready to uninstall external-secrets. Uninstalling with Helm Uninstall the helm release using the delete command. helm delete external-secrets --namespace external-secrets","title":"Getting started"},{"location":"guides/getting-started/#getting-started","text":"External-secrets runs within your Kubernetes cluster as a deployment resource. It utilizes CustomResourceDefinitions to configure access to secret providers through SecretStore resources and manages Kubernetes secret resources with ExternalSecret resources. Note: The minimum supported version of Kubernetes is 1.16.0 . Users still running Kubernetes v1.15 or below should upgrade to a supported version before installing external-secrets.","title":"Getting started"},{"location":"guides/getting-started/#installing-with-helm","text":"To automatically install and manage the CRDs as part of your Helm release, you must add the --set installCRDs=true flag to your Helm installation command. Uncomment the relevant line in the next steps to enable this.","title":"Installing with Helm"},{"location":"guides/getting-started/#option-1-install-from-chart-repository","text":"helm repo add external-secrets https://charts.external-secrets.io helm install external-secrets \\ external-secrets/external-secrets \\ -n external-secrets \\ --create-namespace \\ # --set installCRDs=true","title":"Option 1: Install from chart repository"},{"location":"guides/getting-started/#option-2-install-chart-from-local-build","text":"Build and install the Helm chart locally after cloning the repository. make helm.build helm install external-secrets \\ ./bin/chart/external-secrets.tgz \\ -n external-secrets \\ --create-namespace \\ # --set installCRDs=true","title":"Option 2: Install chart from local build"},{"location":"guides/getting-started/#create-a-secret-containing-your-aws-credentials","text":"echo -n 'KEYID' > ./access-key echo -n 'SECRETKEY' > ./secret-access-key kubectl create secret generic awssm-secret --from-file = ./access-key --from-file = ./secret-access-key","title":"Create a secret containing your AWS credentials"},{"location":"guides/getting-started/#create-your-first-secretstore","text":"apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : us-east-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key","title":"Create your first SecretStore"},{"location":"guides/getting-started/#create-your-first-externalsecret","text":"apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : provider-key version : provider-key-version property : provider-key-property dataFrom : - extract : key : remote-key-in-the-provider kubectl describe externalsecret example # [...] Name: example Status: Conditions: Last Transition Time: 2021 -02-24T16:45:23Z Message: Secret was synced Reason: SecretSynced Status: True Type: Ready Refresh Time: 2021 -02-24T16:45:24Z Events: <none> For more advanced examples, please read the other guides .","title":"Create your first ExternalSecret"},{"location":"guides/getting-started/#installing-with-olm","text":"External-secrets can be managed by Operator Lifecycle Manager (OLM) via an installer operator. It is made available through OperatorHub.io , this installation method is suited best for OpenShift. See installation instructions on the external-secrets-operator package.","title":"Installing with OLM"},{"location":"guides/getting-started/#uninstalling","text":"Before continuing, ensure that all external-secret resources that have been created by users have been deleted. You can check for any existing resources with the following command: kubectl get SecretStores,ClusterSecretStores,ExternalSecrets --all-namespaces Once all these resources have been deleted you are ready to uninstall external-secrets.","title":"Uninstalling"},{"location":"guides/getting-started/#uninstalling-with-helm","text":"Uninstall the helm release using the delete command. helm delete external-secrets --namespace external-secrets","title":"Uninstalling with Helm"},{"location":"guides/introduction/","text":"Guides The following guides demonstrate use-cases and provide examples of how to use the API. Please pick one of the following guides: Getting started Advanced Templating Multi-Tenancy Design Considerations","title":"Introduction"},{"location":"guides/introduction/#guides","text":"The following guides demonstrate use-cases and provide examples of how to use the API. Please pick one of the following guides: Getting started Advanced Templating Multi-Tenancy Design Considerations","title":"Guides"},{"location":"guides/metrics/","text":"Metrics The External Secrets Operator exposes its Prometheus metrics in the /metrics path. To enable it, set the serviceMonitor.enabled Helm flag to true . In addition you can also set webhook.serviceMonitor.enabled=true and certController.serviceMonitor.enabled=true to create ServiceMonitor resources for the other components. If you are using a different monitoring tool that also needs a /metrics endpoint, you can set the metrics.service.enabled Helm flag to true . In addition you can also set webhook.metrics.service.enabled and certController.metrics.service.enabled to scrape the other components. The Operator has the metrics inherited from Kubebuilder plus some custom metrics with the externalsecret prefix. External Secret Metrics Name Type Description externalsecret_sync_calls_total Counter Total number of the External Secret sync calls externalsecret_sync_calls_error Counter Total number of the External Secret sync errors externalsecret_status_condition Gauge The status condition of a specific External Secret","title":"Metrics"},{"location":"guides/metrics/#metrics","text":"The External Secrets Operator exposes its Prometheus metrics in the /metrics path. To enable it, set the serviceMonitor.enabled Helm flag to true . In addition you can also set webhook.serviceMonitor.enabled=true and certController.serviceMonitor.enabled=true to create ServiceMonitor resources for the other components. If you are using a different monitoring tool that also needs a /metrics endpoint, you can set the metrics.service.enabled Helm flag to true . In addition you can also set webhook.metrics.service.enabled and certController.metrics.service.enabled to scrape the other components. The Operator has the metrics inherited from Kubebuilder plus some custom metrics with the externalsecret prefix.","title":"Metrics"},{"location":"guides/metrics/#external-secret-metrics","text":"Name Type Description externalsecret_sync_calls_total Counter Total number of the External Secret sync calls externalsecret_sync_calls_error Counter Total number of the External Secret sync errors externalsecret_status_condition Gauge The status condition of a specific External Secret","title":"External Secret Metrics"},{"location":"guides/multi-tenancy/","text":"External Secrets Operator provides different modes of operation to fulfill ogranizational needs. This guide outlines the flexibility of ESO and should give you a first impression of how you can employ this operator in your organization. For a multi-tenant deployment you should first examine your organizational structure: what roles (i.e. Application Developers , Cluster Admins , ...) do you have in your organization, what responsibilities do they have and how does that map to Kubernetes RBAC roles. Further, you should examine how your external API provider manages access control for your secrets. Can you limit access by secret names (e.g. db/dev/* )? Or only on a bucket level? Please keep in mind that not all external APIs provide fine-grained access management for secrets. Note: The following examples should not be considered as best practice but rather as a example to show how to combine different mechanics and techniques for tenant isolation. Shared ClusterSecretStore A Cluster Administrator deploys a ClusterSecretStore (CSS) and manages access to the external API. The CSS is shared by all tenants within the cluster. Application Developers do reference it in a ExternalSecret but can not create a ClusterSecretStores or SecretStores on their own. Now all application developers have access to all the secrets. You probably want to limit access to certain keys or prefixes that should be used. ESO does not provide a mechanic to limit access to certain keys per namespace. More advanced validation should be done with an Admission Webhook, e.g. with Kyverno or Open Policy Agent ). This setup suites well if you have one central bucket that contains all of your secrets and your Cluster Administrators should manage access to it. This setup is very simple but does not scale very well. Managed SecretStore per Namespace Cluster Administrators manage one or multiple SecretStores per Namespace. Each SecretStore uses it's own role that limits access to a small set of keys. The peculiarity of this is approach is, that access is actually managed by the external API which provides the roles. The Cluster Administrator does just the wiring. This approach may be desirable if you have an external entity - let's call it Secret Administrator - that manages access and lifecycle of the secrets. ESO as a Service Every namespace is self-contained. Application developers manage SecretStore , ExternalSecret and secret infrastructure on their own. Cluster Administrators just provide the External Secrets Operator as a service. This makes sense if application developers should be completely autonomous while a central team provides common services.","title":"Multi Tenancy"},{"location":"guides/multi-tenancy/#shared-clustersecretstore","text":"A Cluster Administrator deploys a ClusterSecretStore (CSS) and manages access to the external API. The CSS is shared by all tenants within the cluster. Application Developers do reference it in a ExternalSecret but can not create a ClusterSecretStores or SecretStores on their own. Now all application developers have access to all the secrets. You probably want to limit access to certain keys or prefixes that should be used. ESO does not provide a mechanic to limit access to certain keys per namespace. More advanced validation should be done with an Admission Webhook, e.g. with Kyverno or Open Policy Agent ). This setup suites well if you have one central bucket that contains all of your secrets and your Cluster Administrators should manage access to it. This setup is very simple but does not scale very well.","title":"Shared ClusterSecretStore"},{"location":"guides/multi-tenancy/#managed-secretstore-per-namespace","text":"Cluster Administrators manage one or multiple SecretStores per Namespace. Each SecretStore uses it's own role that limits access to a small set of keys. The peculiarity of this is approach is, that access is actually managed by the external API which provides the roles. The Cluster Administrator does just the wiring. This approach may be desirable if you have an external entity - let's call it Secret Administrator - that manages access and lifecycle of the secrets.","title":"Managed SecretStore per Namespace"},{"location":"guides/multi-tenancy/#eso-as-a-service","text":"Every namespace is self-contained. Application developers manage SecretStore , ExternalSecret and secret infrastructure on their own. Cluster Administrators just provide the External Secrets Operator as a service. This makes sense if application developers should be completely autonomous while a central team provides common services.","title":"ESO as a Service"},{"location":"guides/ownership-deletion-policy/","text":"Lifecycle The External Secrets Operator manages the lifecycle of secrets in Kubernetes. With creationPolicy and deletionPolicy you get fine-grained control of its lifecycle. Creation/Deletion Policy Combinations Some combinations of creationPolicy/deletionPolicy are not allowed as they would delete existing secrets: - deletionPolicy=Delete & creationPolicy=Merge - deletionPolicy=Delete & creationPolicy=None - deletionPolicy=Merge & creationPolicy=None Creation Policy The field spec.creationPolicy defines how the operator creates the a secret. Owner (default) The External Secret Operator creates secret and sets the ownerReference field on the Secret. This secret is subject to garbage collection if the initial ExternalSecret is absent. If a secret with the same name already exists that is not owned by the controller it will result in a conflict. The operator will just error out, not claiming the ownership. Orphan The operator creates ths secret but does not set the ownerReference on the Secret. That means the Secret will not be subject to garbage collection. If a secret with the same name already exists it will be updated. Merge The operator does not create a secret. Instead, it expects the secret to already exist. Values from the secret provider will be merged into the existing secret. Note: the controller takes ownership of a field even if it is owned by a different entity. Multiple ExternalSecrets can use creationPolicy=Merge with a single secret as long as the fields don't collide - otherwise you end up in an oscillating state. None The operator does not create or update the secret, this is basically a no-op. Deletion Policy DeletionPolicy defines what should happen if a given secret gets deleted from the provider . DeletionPolicy is only supported on the following providers. Please feel free to contribute more: * AWS Secrets Manager * AWS Parameter Store Retain (default) Retain will retain the secret if all provider secrets have been deleted. If a provider secret does not exist the ExternalSecret gets into the SecretSyncedError status. Delete Delete deletes the secret if all provider secrets are deleted. If a secret gets deleted on the provider side and is not accessible anymore this is not considered an error and the ExternalSecret does not go into SecretSyncedError status. This is also true for new ExternalSecrets mapping to non-existing secrets in the provider. Merge Merge removes keys in the secret, but not the secret itself. If a secret gets deleted on the provider side and is not accessible anymore this is not considered an error and the ExternalSecret does not go into SecretSyncedError status.","title":"Lifecycle: ownership & deletion"},{"location":"guides/ownership-deletion-policy/#lifecycle","text":"The External Secrets Operator manages the lifecycle of secrets in Kubernetes. With creationPolicy and deletionPolicy you get fine-grained control of its lifecycle. Creation/Deletion Policy Combinations Some combinations of creationPolicy/deletionPolicy are not allowed as they would delete existing secrets: - deletionPolicy=Delete & creationPolicy=Merge - deletionPolicy=Delete & creationPolicy=None - deletionPolicy=Merge & creationPolicy=None","title":"Lifecycle"},{"location":"guides/ownership-deletion-policy/#creation-policy","text":"The field spec.creationPolicy defines how the operator creates the a secret.","title":"Creation Policy"},{"location":"guides/ownership-deletion-policy/#owner-default","text":"The External Secret Operator creates secret and sets the ownerReference field on the Secret. This secret is subject to garbage collection if the initial ExternalSecret is absent. If a secret with the same name already exists that is not owned by the controller it will result in a conflict. The operator will just error out, not claiming the ownership.","title":"Owner (default)"},{"location":"guides/ownership-deletion-policy/#orphan","text":"The operator creates ths secret but does not set the ownerReference on the Secret. That means the Secret will not be subject to garbage collection. If a secret with the same name already exists it will be updated.","title":"Orphan"},{"location":"guides/ownership-deletion-policy/#merge","text":"The operator does not create a secret. Instead, it expects the secret to already exist. Values from the secret provider will be merged into the existing secret. Note: the controller takes ownership of a field even if it is owned by a different entity. Multiple ExternalSecrets can use creationPolicy=Merge with a single secret as long as the fields don't collide - otherwise you end up in an oscillating state.","title":"Merge"},{"location":"guides/ownership-deletion-policy/#none","text":"The operator does not create or update the secret, this is basically a no-op.","title":"None"},{"location":"guides/ownership-deletion-policy/#deletion-policy","text":"DeletionPolicy defines what should happen if a given secret gets deleted from the provider . DeletionPolicy is only supported on the following providers. Please feel free to contribute more: * AWS Secrets Manager * AWS Parameter Store","title":"Deletion Policy"},{"location":"guides/ownership-deletion-policy/#retain-default","text":"Retain will retain the secret if all provider secrets have been deleted. If a provider secret does not exist the ExternalSecret gets into the SecretSyncedError status.","title":"Retain (default)"},{"location":"guides/ownership-deletion-policy/#delete","text":"Delete deletes the secret if all provider secrets are deleted. If a secret gets deleted on the provider side and is not accessible anymore this is not considered an error and the ExternalSecret does not go into SecretSyncedError status. This is also true for new ExternalSecrets mapping to non-existing secrets in the provider.","title":"Delete"},{"location":"guides/ownership-deletion-policy/#merge_1","text":"Merge removes keys in the secret, but not the secret itself. If a secret gets deleted on the provider side and is not accessible anymore this is not considered an error and the ExternalSecret does not go into SecretSyncedError status.","title":"Merge"},{"location":"guides/templating-v1/","text":"Advanced Templating v1 Warning Templating Engine v1 is deprecated and will be removed in the future. Please migrate to engine v2 and take a look at our upgrade guide for changes. With External Secrets Operator you can transform the data from the external secret provider before it is stored as Kind=Secret . You can do this with the Spec.Target.Template . Each data value is interpreted as a golang template . Examples You can use templates to inject your secrets into a configuration file that you mount into your pod: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created # v2 is the default engineVersion in external-secrets.io/v1beta1 # v1 is the default engineVersion in external-secrets.io/v1alpha1 (deprecated) engineVersion : v1 # this is how the Kind=Secret will look like template : type : kubernetes.io/tls data : # multiline string config : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password | toString }}\" # <-- convert []byte to string user: \"{{ .user | toString }}\" # <-- convert []byte to string data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password You can also use pre-defined functions to extract data from your secrets. Here: extract key/cert from a pkcs12 archive and store it as PEM. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created # this is how the Kind=Secret will look like template : type : kubernetes.io/tls data : tls.crt : \"{{ .mysecret | pkcs12cert | pemCertificate }}\" tls.key : \"{{ .mysecret | pkcs12key | pemPrivateKey }}\" data : # this is a pkcs12 archive that contains # a cert and a private key - secretKey : mysecret remoteRef : key : example TemplateFrom You do not have to define your templates inline in an ExternalSecret but you can pull ConfigMaps or other Secrets that contain a template. Consider the following example: # define your template in a config map apiVersion : v1 kind : ConfigMap metadata : name : grafana-config-tpl data : config.yaml : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password | toString }}\" # <-- convert []byte to string user: \"{{ .user | toString }}\" # <-- convert []byte to string --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-template-example spec : # ... target : name : secret-to-be-created template : templateFrom : - configMap : # name of the configmap to pull in name : grafana-config-tpl # here you define the keys that should be used as template items : - key : config.yaml data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password Helper functions We provide a bunch of convenience functions that help you transform your secrets. A secret value is a []byte . Function Description Input Output pkcs12key extracts the private key from a pkcs12 archive []byte []byte pkcs12keyPass extracts the private key from a pkcs12 archive using the provided password password string , data []byte []byte pkcs12cert extracts the certificate from a pkcs12 archive []byte []byte pkcs12certPass extracts the certificate from a pkcs12 archive using the provided password password string , data []byte []byte pemPrivateKey PEM encodes the provided bytes as private key []byte string pemCertificate PEM encodes the provided bytes as certificate []byte string jwkPublicKeyPem takes an json-serialized JWK as []byte and returns an PEM block of type PUBLIC KEY that contains the public key ( see here ) for details []byte string jwkPrivateKeyPem takes an json-serialized JWK as []byte and returns an PEM block of type PRIVATE KEY that contains the private key in PKCS #8 format ( see here ) for details []byte string base64decode decodes the provided bytes as base64 []byte []byte base64encode encodes the provided bytes as base64 []byte []byte fromJSON parses the bytes as JSON so you can access individual properties []byte interface{} toJSON encodes the provided object as json string interface{} string toString converts bytes to string []byte string toBytes converts string to bytes string []byte upper converts all characters to their upper case string string lower converts all character to their lower case string string","title":"v1"},{"location":"guides/templating-v1/#advanced-templating-v1","text":"Warning Templating Engine v1 is deprecated and will be removed in the future. Please migrate to engine v2 and take a look at our upgrade guide for changes. With External Secrets Operator you can transform the data from the external secret provider before it is stored as Kind=Secret . You can do this with the Spec.Target.Template . Each data value is interpreted as a golang template .","title":"Advanced Templating v1"},{"location":"guides/templating-v1/#examples","text":"You can use templates to inject your secrets into a configuration file that you mount into your pod: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created # v2 is the default engineVersion in external-secrets.io/v1beta1 # v1 is the default engineVersion in external-secrets.io/v1alpha1 (deprecated) engineVersion : v1 # this is how the Kind=Secret will look like template : type : kubernetes.io/tls data : # multiline string config : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password | toString }}\" # <-- convert []byte to string user: \"{{ .user | toString }}\" # <-- convert []byte to string data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password You can also use pre-defined functions to extract data from your secrets. Here: extract key/cert from a pkcs12 archive and store it as PEM. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created # this is how the Kind=Secret will look like template : type : kubernetes.io/tls data : tls.crt : \"{{ .mysecret | pkcs12cert | pemCertificate }}\" tls.key : \"{{ .mysecret | pkcs12key | pemPrivateKey }}\" data : # this is a pkcs12 archive that contains # a cert and a private key - secretKey : mysecret remoteRef : key : example","title":"Examples"},{"location":"guides/templating-v1/#templatefrom","text":"You do not have to define your templates inline in an ExternalSecret but you can pull ConfigMaps or other Secrets that contain a template. Consider the following example: # define your template in a config map apiVersion : v1 kind : ConfigMap metadata : name : grafana-config-tpl data : config.yaml : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password | toString }}\" # <-- convert []byte to string user: \"{{ .user | toString }}\" # <-- convert []byte to string --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-template-example spec : # ... target : name : secret-to-be-created template : templateFrom : - configMap : # name of the configmap to pull in name : grafana-config-tpl # here you define the keys that should be used as template items : - key : config.yaml data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password","title":"TemplateFrom"},{"location":"guides/templating-v1/#helper-functions","text":"We provide a bunch of convenience functions that help you transform your secrets. A secret value is a []byte . Function Description Input Output pkcs12key extracts the private key from a pkcs12 archive []byte []byte pkcs12keyPass extracts the private key from a pkcs12 archive using the provided password password string , data []byte []byte pkcs12cert extracts the certificate from a pkcs12 archive []byte []byte pkcs12certPass extracts the certificate from a pkcs12 archive using the provided password password string , data []byte []byte pemPrivateKey PEM encodes the provided bytes as private key []byte string pemCertificate PEM encodes the provided bytes as certificate []byte string jwkPublicKeyPem takes an json-serialized JWK as []byte and returns an PEM block of type PUBLIC KEY that contains the public key ( see here ) for details []byte string jwkPrivateKeyPem takes an json-serialized JWK as []byte and returns an PEM block of type PRIVATE KEY that contains the private key in PKCS #8 format ( see here ) for details []byte string base64decode decodes the provided bytes as base64 []byte []byte base64encode encodes the provided bytes as base64 []byte []byte fromJSON parses the bytes as JSON so you can access individual properties []byte interface{} toJSON encodes the provided object as json string interface{} string toString converts bytes to string []byte string toBytes converts string to bytes string []byte upper converts all characters to their upper case string string lower converts all character to their lower case string string","title":"Helper functions"},{"location":"guides/templating/","text":"Advanced Templating v2 With External Secrets Operator you can transform the data from the external secret provider before it is stored as Kind=Secret . You can do this with the Spec.Target.Template . Each data value is interpreted as a golang template . Examples You can use templates to inject your secrets into a configuration file that you mount into your pod: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : # ... target : name : secret-to-be-created # this is how the Kind=Secret will look like template : type : kubernetes.io/tls engineVersion : v2 data : # multiline string config : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password }}\" user: \"{{ .user }}\" # using replace function to rewrite secret connection : '{{ .dburl | replace \"postgres://\" \"postgresql://\" }}' data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password - secretKey : dburl remoteRef : key : /database/url TemplateFrom You do not have to define your templates inline in an ExternalSecret but you can pull ConfigMaps or other Secrets that contain a template. Consider the following example: # define your template in a config map apiVersion : v1 kind : ConfigMap metadata : name : grafana-config-tpl data : config.yaml : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password }}\" user: \"{{ .user }}\" --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-template-example spec : # ... target : name : secret-to-be-created template : engineVersion : v2 templateFrom : - configMap : # name of the configmap to pull in name : grafana-config-tpl # here you define the keys that should be used as template items : - key : config.yaml data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password Extract Keys and Certificates from PKCS#12 Archive You can use pre-defined functions to extract data from your secrets. Here: extract keys and certificates from a PKCS#12 archive and store it as PEM. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : # ... target : template : type : kubernetes.io/tls engineVersion : v2 data : tls.crt : \"{{ .mysecret | pkcs12cert }}\" tls.key : \"{{ .mysecret | pkcs12key }}\" # if needed unlock the pkcs12 with the password tls.crt : \"{{ .mysecret | pkcs12certPass \" my-password\" }}\" Extract from JWK You can extract the public or private key parts of a JWK and use them as PKCS#8 private key or PEM-encoded PKIX public key. A JWK looks similar to this: { \"kty\" : \"RSA\" , \"kid\" : \"cc34c0a0-bd5a-4a3c-a50d-a2a7db7643df\" , \"use\" : \"sig\" , \"n\" : \"pjdss...\" , \"e\" : \"AQAB\" // ... } And what you want may be a PEM-encoded public or private key portion of it. Take a look at this example on how to transform it into the desired format: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : # ... target : template : engineVersion : v2 data : # .myjwk is a json-encoded JWK string. # # this template will produce for jwk_pub a PEM encoded public key: # -----BEGIN PUBLIC KEY----- # MIIBI... # ... # ...AQAB # -----END PUBLIC KEY----- jwk_pub : \"{{ .myjwk | jwkPublicKeyPem }}\" # private key is a pem-encoded PKCS#8 private key jwk_priv : \"{{ .myjwk | jwkPrivateKeyPem }}\" Filter PEM blocks Consider you have a secret that contains both a certificate and a private key encoded in PEM format and it is your goal to use only the certificate from that secret. -----BEGIN PRIVATE KEY----- MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCvxGZOW4IXvGlh . . . m8JCpbJXDfSSVxKHgK1Siw4K6pnTsIA2e/Z+Ha2fvtocERjq7VQMAJFaIZSTKo9Q JwwY+vj0yxWjyzHUzZB33tg= -----END PRIVATE KEY----- -----BEGIN CERTIFICATE----- MIIDMDCCAhigAwIBAgIQabPaXuZCQaCg+eQAVptGGDANBgkqhkiG9w0BAQsFADAV . . . NtFUGA95RGN9s+pl6XY0YARPHf5O76ErC1OZtDTR5RdyQfcM+94gYZsexsXl0aQO 9YD3Wg== -----END CERTIFICATE----- You can achieve that by using the filterPEM function to extract a specific type of PEM block from that secret. If multiple blocks of that type (here: CERTIFICATE ) exist then all of them are returned in the order they are specified. Helper functions Info Note: we removed env and expandenv from sprig functions for security reasons. We provide a couple of convenience functions that help you transform your secrets. This is useful when dealing with PKCS#12 archives or JSON Web Keys (JWK). In addition to that you can use over 200+ sprig functions . If you feel a function is missing or might be valuable feel free to open an issue and submit a pull request . Function Description pkcs12key Extracts all private keys from a PKCS#12 archive and encodes them in PKCS#8 PEM format. pkcs12keyPass Same as pkcs12key . Uses the provided password to decrypt the PKCS#12 archive. pkcs12cert Extracts all certificates from a PKCS#12 archive and orders them if possible. If disjunct or multiple leaf certs are provided they are returned as-is. Sort order: leaf / intermediate(s) / root . pkcs12certPass Same as pkcs12cert . Uses the provided password to decrypt the PKCS#12 archive. filterPEM Filters PEM blocks with a specific type from a list of PEM blocks. jwkPublicKeyPem Takes an json-serialized JWK and returns an PEM block of type PUBLIC KEY that contains the public key. See here for details. jwkPrivateKeyPem Takes an json-serialized JWK as string and returns an PEM block of type PRIVATE KEY that contains the private key in PKCS #8 format. See here for details. toYaml Takes an interface, marshals it to yaml. It returns a string, even on marshal error (empty string). fromYaml Function converts a YAML document into a map[string]interface{}. Migrating from v1 If you are still using v1alpha1 , You have to opt-in to use the new engine version by specifying template.engineVersion=v2 : apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret metadata : name : secret spec : # ... target : template : engineVersion : v2 # ... The biggest change was that basically all function parameter types were changed from accepting/returning []byte to string . This is relevant for you because now you don't need to specify toString all the time at the end of a template pipeline. apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret # ... spec : target : template : engineVersion : v2 data : # this used to be {{ .foobar | toString }} egg : \"new: {{ .foobar }}\" Functions removed/replaced base64encode was renamed to b64enc . base64decode was renamed to b64dec . Any errors that occurr during decoding are silenced. fromJSON was renamed to fromJson . Any errors that occurr during unmarshalling are silenced. toJSON was renamed to toJson . Any errors that occurr during marshalling are silenced. pkcs12key and pkcs12keyPass encode the PKCS#8 key directly into PEM format. There is no need to call pemPrivateKey anymore. Also, these functions do extract all private keys from the PKCS#12 archive not just the first one. pkcs12cert and pkcs12certPass encode the certs directly into PEM format. There is no need to call pemCertificate anymore. These functions now extract all certificates from the PKCS#12 archive not just the first one. toString implementation was replaced by the sprig implementation and should be api-compatible. toBytes was removed. pemPrivateKey was removed. It's now implemented within the pkcs12* functions. pemCertificate was removed. It's now implemented within the pkcs12* functions.","title":"v2"},{"location":"guides/templating/#advanced-templating-v2","text":"With External Secrets Operator you can transform the data from the external secret provider before it is stored as Kind=Secret . You can do this with the Spec.Target.Template . Each data value is interpreted as a golang template .","title":"Advanced Templating v2"},{"location":"guides/templating/#examples","text":"You can use templates to inject your secrets into a configuration file that you mount into your pod: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : # ... target : name : secret-to-be-created # this is how the Kind=Secret will look like template : type : kubernetes.io/tls engineVersion : v2 data : # multiline string config : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password }}\" user: \"{{ .user }}\" # using replace function to rewrite secret connection : '{{ .dburl | replace \"postgres://\" \"postgresql://\" }}' data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password - secretKey : dburl remoteRef : key : /database/url","title":"Examples"},{"location":"guides/templating/#templatefrom","text":"You do not have to define your templates inline in an ExternalSecret but you can pull ConfigMaps or other Secrets that contain a template. Consider the following example: # define your template in a config map apiVersion : v1 kind : ConfigMap metadata : name : grafana-config-tpl data : config.yaml : | datasources: - name: Graphite type: graphite access: proxy url: http://localhost:8080 password: \"{{ .password }}\" user: \"{{ .user }}\" --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-template-example spec : # ... target : name : secret-to-be-created template : engineVersion : v2 templateFrom : - configMap : # name of the configmap to pull in name : grafana-config-tpl # here you define the keys that should be used as template items : - key : config.yaml data : - secretKey : user remoteRef : key : /grafana/user - secretKey : password remoteRef : key : /grafana/password","title":"TemplateFrom"},{"location":"guides/templating/#extract-keys-and-certificates-from-pkcs12-archive","text":"You can use pre-defined functions to extract data from your secrets. Here: extract keys and certificates from a PKCS#12 archive and store it as PEM. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : # ... target : template : type : kubernetes.io/tls engineVersion : v2 data : tls.crt : \"{{ .mysecret | pkcs12cert }}\" tls.key : \"{{ .mysecret | pkcs12key }}\" # if needed unlock the pkcs12 with the password tls.crt : \"{{ .mysecret | pkcs12certPass \" my-password\" }}\"","title":"Extract Keys and Certificates from PKCS#12 Archive"},{"location":"guides/templating/#extract-from-jwk","text":"You can extract the public or private key parts of a JWK and use them as PKCS#8 private key or PEM-encoded PKIX public key. A JWK looks similar to this: { \"kty\" : \"RSA\" , \"kid\" : \"cc34c0a0-bd5a-4a3c-a50d-a2a7db7643df\" , \"use\" : \"sig\" , \"n\" : \"pjdss...\" , \"e\" : \"AQAB\" // ... } And what you want may be a PEM-encoded public or private key portion of it. Take a look at this example on how to transform it into the desired format: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : template spec : # ... target : template : engineVersion : v2 data : # .myjwk is a json-encoded JWK string. # # this template will produce for jwk_pub a PEM encoded public key: # -----BEGIN PUBLIC KEY----- # MIIBI... # ... # ...AQAB # -----END PUBLIC KEY----- jwk_pub : \"{{ .myjwk | jwkPublicKeyPem }}\" # private key is a pem-encoded PKCS#8 private key jwk_priv : \"{{ .myjwk | jwkPrivateKeyPem }}\"","title":"Extract from JWK"},{"location":"guides/templating/#filter-pem-blocks","text":"Consider you have a secret that contains both a certificate and a private key encoded in PEM format and it is your goal to use only the certificate from that secret. -----BEGIN PRIVATE KEY----- MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCvxGZOW4IXvGlh . . . m8JCpbJXDfSSVxKHgK1Siw4K6pnTsIA2e/Z+Ha2fvtocERjq7VQMAJFaIZSTKo9Q JwwY+vj0yxWjyzHUzZB33tg= -----END PRIVATE KEY----- -----BEGIN CERTIFICATE----- MIIDMDCCAhigAwIBAgIQabPaXuZCQaCg+eQAVptGGDANBgkqhkiG9w0BAQsFADAV . . . NtFUGA95RGN9s+pl6XY0YARPHf5O76ErC1OZtDTR5RdyQfcM+94gYZsexsXl0aQO 9YD3Wg== -----END CERTIFICATE----- You can achieve that by using the filterPEM function to extract a specific type of PEM block from that secret. If multiple blocks of that type (here: CERTIFICATE ) exist then all of them are returned in the order they are specified.","title":"Filter PEM blocks"},{"location":"guides/templating/#helper-functions","text":"Info Note: we removed env and expandenv from sprig functions for security reasons. We provide a couple of convenience functions that help you transform your secrets. This is useful when dealing with PKCS#12 archives or JSON Web Keys (JWK). In addition to that you can use over 200+ sprig functions . If you feel a function is missing or might be valuable feel free to open an issue and submit a pull request . Function Description pkcs12key Extracts all private keys from a PKCS#12 archive and encodes them in PKCS#8 PEM format. pkcs12keyPass Same as pkcs12key . Uses the provided password to decrypt the PKCS#12 archive. pkcs12cert Extracts all certificates from a PKCS#12 archive and orders them if possible. If disjunct or multiple leaf certs are provided they are returned as-is. Sort order: leaf / intermediate(s) / root . pkcs12certPass Same as pkcs12cert . Uses the provided password to decrypt the PKCS#12 archive. filterPEM Filters PEM blocks with a specific type from a list of PEM blocks. jwkPublicKeyPem Takes an json-serialized JWK and returns an PEM block of type PUBLIC KEY that contains the public key. See here for details. jwkPrivateKeyPem Takes an json-serialized JWK as string and returns an PEM block of type PRIVATE KEY that contains the private key in PKCS #8 format. See here for details. toYaml Takes an interface, marshals it to yaml. It returns a string, even on marshal error (empty string). fromYaml Function converts a YAML document into a map[string]interface{}.","title":"Helper functions"},{"location":"guides/templating/#migrating-from-v1","text":"If you are still using v1alpha1 , You have to opt-in to use the new engine version by specifying template.engineVersion=v2 : apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret metadata : name : secret spec : # ... target : template : engineVersion : v2 # ... The biggest change was that basically all function parameter types were changed from accepting/returning []byte to string . This is relevant for you because now you don't need to specify toString all the time at the end of a template pipeline. apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret # ... spec : target : template : engineVersion : v2 data : # this used to be {{ .foobar | toString }} egg : \"new: {{ .foobar }}\"","title":"Migrating from v1"},{"location":"guides/templating/#functions-removedreplaced","text":"base64encode was renamed to b64enc . base64decode was renamed to b64dec . Any errors that occurr during decoding are silenced. fromJSON was renamed to fromJson . Any errors that occurr during unmarshalling are silenced. toJSON was renamed to toJson . Any errors that occurr during marshalling are silenced. pkcs12key and pkcs12keyPass encode the PKCS#8 key directly into PEM format. There is no need to call pemPrivateKey anymore. Also, these functions do extract all private keys from the PKCS#12 archive not just the first one. pkcs12cert and pkcs12certPass encode the certs directly into PEM format. There is no need to call pemCertificate anymore. These functions now extract all certificates from the PKCS#12 archive not just the first one. toString implementation was replaced by the sprig implementation and should be api-compatible. toBytes was removed. pemPrivateKey was removed. It's now implemented within the pkcs12* functions. pemCertificate was removed. It's now implemented within the pkcs12* functions.","title":"Functions removed/replaced"},{"location":"guides/using-latest-image/","text":"You can test a feature that was not yet released using the following methods, use them at your own discretion: Helm Create a values.yaml file with the following content: replicaCount : 1 image : repository : ghcr.io/external-secrets/external-secrets pullPolicy : IfNotPresent # -- The image tag to use. The default is the chart appVersion. tag : \"main\" # -- If set, install and upgrade CRDs through helm chart. installCRDs : false Install the crds make crds.install Install the external-secrets Helm chart indicating the values file created before: helm install external-secrets external-secrets/external-secrets -f values.yaml Manual Build the Docker image docker build -f Dockerfile.standalone -t my-org/external-secrets:latest . Apply the bundle.yaml kubectl apply -f deploy/crds/bundle.yaml Modify your configs to use the image kind : Deployment metadata : name : external-secrets|external-secrets-webhook|external-secrets-cert-controller ... image : my-org/external-secrets:latest","title":"Using Latest Image"},{"location":"guides/using-latest-image/#helm","text":"Create a values.yaml file with the following content: replicaCount : 1 image : repository : ghcr.io/external-secrets/external-secrets pullPolicy : IfNotPresent # -- The image tag to use. The default is the chart appVersion. tag : \"main\" # -- If set, install and upgrade CRDs through helm chart. installCRDs : false Install the crds make crds.install Install the external-secrets Helm chart indicating the values file created before: helm install external-secrets external-secrets/external-secrets -f values.yaml","title":"Helm"},{"location":"guides/using-latest-image/#manual","text":"Build the Docker image docker build -f Dockerfile.standalone -t my-org/external-secrets:latest . Apply the bundle.yaml kubectl apply -f deploy/crds/bundle.yaml Modify your configs to use the image kind : Deployment metadata : name : external-secrets|external-secrets-webhook|external-secrets-cert-controller ... image : my-org/external-secrets:latest","title":"Manual"},{"location":"guides/v1beta1/","text":"Upgrading CRD versions From version v0.5.0, v1alpha1 version is deprecated, and v1beta1 is in place. This guide will cover the main differences between the two versions, and a procedure on how to safely upgrade it. Differences between versions Versions v1alpha1 and v1beta1 are fully-compatible for SecretStores and ClusterSecretStores. For ExternalSecrets, there is a difference on the dataFrom method. While in v1alpha1, we could define a dataFrom with the following format: spec: dataFrom: - key: my-key - key: my-other-key In v1beta1 is possible to use two methods. One of them is Extract and has the exact same behavior as dataFrom in v1alpha1. The other is Find , which allows finding multiple external secrets and map them into a single Kubernetes secret. Here is an example of Find : spec: dataFrom: - find: name: #matches any secret name ending in foo-bar regexp: .*foo-bar$ - find: tags: #matches any secrets with the following metadata. env: dev app: web Upgrading If you already have an installation of ESO using v1alpha1 , we recommend you to upgrade to v1beta1 . If you do not use dataFrom in your ExternalSecrets, or if you deploy the CRDs using the official Helm charts, the upgrade can be done with no risk of losing data. If you are installing CRDs manually, you will need to deploy the bundle CRD file available at deploys/crds/bundle.yaml . This bundle file contains v1beta1 definition and a conversion webhook configuration. This configuration will ensure that new requests to handle any CRD object will only be valid after the upgrade is successfully complete - so there are no risks of losing data due to an incomplete upgrade. Once the new CRDs are applied, you can proceed to upgrade the controller version. Once the upgrade is finished, at each reconcile, any ExternalSecret , SecretStore , and ClusterSecretStore stored in v1alpha1 will be automatically converted to v1beta1 .","title":"Upgrading to v1beta1"},{"location":"guides/v1beta1/#upgrading-crd-versions","text":"From version v0.5.0, v1alpha1 version is deprecated, and v1beta1 is in place. This guide will cover the main differences between the two versions, and a procedure on how to safely upgrade it.","title":"Upgrading CRD versions"},{"location":"guides/v1beta1/#differences-between-versions","text":"Versions v1alpha1 and v1beta1 are fully-compatible for SecretStores and ClusterSecretStores. For ExternalSecrets, there is a difference on the dataFrom method. While in v1alpha1, we could define a dataFrom with the following format: spec: dataFrom: - key: my-key - key: my-other-key In v1beta1 is possible to use two methods. One of them is Extract and has the exact same behavior as dataFrom in v1alpha1. The other is Find , which allows finding multiple external secrets and map them into a single Kubernetes secret. Here is an example of Find : spec: dataFrom: - find: name: #matches any secret name ending in foo-bar regexp: .*foo-bar$ - find: tags: #matches any secrets with the following metadata. env: dev app: web","title":"Differences between versions"},{"location":"guides/v1beta1/#upgrading","text":"If you already have an installation of ESO using v1alpha1 , we recommend you to upgrade to v1beta1 . If you do not use dataFrom in your ExternalSecrets, or if you deploy the CRDs using the official Helm charts, the upgrade can be done with no risk of losing data. If you are installing CRDs manually, you will need to deploy the bundle CRD file available at deploys/crds/bundle.yaml . This bundle file contains v1beta1 definition and a conversion webhook configuration. This configuration will ensure that new requests to handle any CRD object will only be valid after the upgrade is successfully complete - so there are no risks of losing data due to an incomplete upgrade. Once the new CRDs are applied, you can proceed to upgrade the controller version. Once the upgrade is finished, at each reconcile, any ExternalSecret , SecretStore , and ClusterSecretStore stored in v1alpha1 will be automatically converted to v1beta1 .","title":"Upgrading"},{"location":"provider/1password-automation/","text":"1Password Secrets Automation External Secrets Operator integrates with 1Password Secrets Automation for secret management. Important note about this documentation The 1Password API calls the entries in vaults 'Items'. These docs use the same term. Behavior How an Item is equated to an ExternalSecret: remoteRef.key is equated to an Item's Title remoteRef.property is equated to: An Item's field's Label (Password type) An Item's file's Name (Document type) If empty, defaults to the first file name, or the field labeled password remoteRef.version is currently not supported. One Item in a vault can equate to one Kubernetes Secret to keep things easy to comprehend. Support for 1Password secret types of Password and Document . The Password type can get data from multiple fields in the Item. The Document type can get data from files. See creating 1Password Items compatible with ExternalSecrets . Ordered vaults Specify an ordered list of vaults in a SecretStore and the value will be sourced from the first vault with a matching Item. If no matching Item is found, an error is returned. This supports having a default or shared set of values that can also be overriden for specific environments. dataFrom : find.path is equated to Item Title. find.name.regexp is equated to field Labels. find.tags are not supported at this time. Prerequisites 1Password requires running a 1Password Connect Server to which the API requests will be made. External Secrets does not run this server. See Deploy a Connect Server . One Connect Server is needed per 1Password Automation Environment. Many Vaults can be added to an Automation Environment, and Tokens can be generated in that Environment with access to any set or subset of those Vaults. 1Password Connect Server version 1.5.6 or higher. Setup Authentication Authentication requires a 1password-credentials.json file provided to the Connect Server, and a related 'Access Token' for the client in this provider to authenticate to that Connect Server. Both of these are generated by 1Password. Setup an Automation Environment at 1Password.com , or via the op CLI . Note: don't be confused by the op connect server create syntax. This will create an Automation Environment in 1Password, and corresponding credentials for a Connect Server, nothing more. This will result in a 1password-credentials.json file to provide to a Connect Server Deployment, and an Access Token to provide as a Secret referenced by a SecretStore or ClusterSecretStore . Create a Kubernetes secret with the Access Token --- apiVersion : v1 kind : Secret metadata : name : onepassword-connect-token-staging type : Opaque stringData : token : my-token Reference the secret in a SecretStore or ClusterSecretStore --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : staging spec : provider : onepassword : connectHost : https://onepassword-connect-staging vaults : staging : 1 # look in this vault first shared : 2 # next look in here. error if not found auth : secretRef : connectTokenSecretRef : name : onepassword-connect-token-staging key : token Create a Kubernetes secret with the Connect Server credentials --- apiVersion : v1 kind : Secret metadata : name : connect-server-credentials type : Opaque stringData : # NOTE: This secret value must be base64 encoded after it becomes the OP_SESSION env var in the Connect Server Deployment, that means double base64 encoded here. (Or single w/ stringData.) 1password-credentials.json : |- eyJ2ZXJpZmllciI6eyJzYWx0IjoiZXhhbXBsZSIsImxvY2FsSGFzaCI6ImV4YW1wbGUifSwiZW5jQ3JlZGVudGlhbHMiOnsia2lkIjoiZXhhbXBsZSIsImVuYyI6ImV4YW1wbGUiLCJjdHkiOiJleGFtcGxlIiwiaXYiOiJleGFtcGxlIiwiZGF0YSI6ImV4YW1wbGUifSwidmVyc2lvbiI6IjIiLCJkZXZpY2VVdWlkIjoiZXhhbXBsZSIsInVuaXF1ZUtleSI6eyJhbGciOiJleGFtcGxlIiwiZXh0Ijp0cnVlLCJrIjoiZXhhbXBsZSIsImtleV9vcHMiOlsiZW5jcnlwdCIsImRlY3J5cHQiXSwia3R5Ijoib2N0Iiwia2lkIjoiZXhhbXBsZSJ9fQ== Reference the secret in a Connect Server Deployment --- apiVersion : apps/v1 kind : Deployment metadata : name : onepassword-connect-staging spec : template : spec : containers : - name : connect-api image : 1password/connect-api:1.5.0 env : - name : OP_SESSION valueFrom : secretKeyRef : name : connect-server-credentials key : 1password-credentials.json ... - name : connect-sync image : 1password/connect-sync:1.5.0 env : - name : OP_SESSION valueFrom : secretKeyRef : name : connect-server-credentials key : 1password-credentials.json ... ... Deploy a Connect Server Follow the remaining instructions in the Quick Start guide . Deploy at minimum a Deployment and Service for a Connect Server, to go along with the Secret for the Server created in the Setup Authentication section . The Service's name will be referenced in SecretStores/ClusterSecretStores. Keep in mind the likely need for additional Connect Servers for other Automation Environments when naming objects. For example dev, staging, prod, etc. Unencrypted secret values are passed over the connection between the Operator and the Connect Server. Encrypting the connection is recommended. Creating Compatible 1Password Items Also see examples below for matching SecretStore and ExternalSecret specs. Manually (Password type) Click the plus button to create a new Password type Item. Change the title to what you want remoteRef.key to be. Set what you want remoteRef.property to be in the field sections where is says 'label', and values where it says 'new field'. Click the 'Save' button. Manually (Document type) Click the plus button to create a new Document type Item. Choose the file to upload and upload it. Change the title to match remoteRef.key Click the 'Add New File' button to add more files. Click the 'Save' button. Scripting (Password type with op CLI ) Create file.json with the following contents, swapping in your keys and values. Note: section.name 's and section.title 's values are ignored by the Operator, but cannot be empty for the op CLI { \"sections\" : [ { \"fields\" : [ { \"k\" : \"concealed\" , \"n\" : \"MY_ENV_VAR1\" , \"t\" : \"MY_ENV_VAR1\" , \"v\" : \"value1\" }, { \"k\" : \"concealed\" , \"n\" : \"MY_ENV_VAR2\" , \"t\" : \"MY_ENV_VAR2\" , \"v\" : \"value2\" } ], \"name\" : \"EXTERNAL-SECRETS\" , \"title\" : \"EXTERNAL-SECRETS\" } ] } Run op create item password --template file.json --vault my-vault --title my-item Scripting (Document type) Unfortunately the op CLI doesn't seem to support uploading multiple files to the same Item, and the current Go lib has a bug . op can be used to create a Document type Item with one file in it, but for now it's necessary to add multiple files to the same Document via the GUI. In-built field labeled password on Password type Items TL;DR if you need a field labeled password , use the in-built one rather than the one in a fields Section. 1Password automatically adds a field labeled password on every Password type Item, whether it's created through a GUI or the API or op CLI. There's no problem with using this field just like any other field, just make sure you don't end up with two fields with the same label . (For example, by automating the op CLI to create Items.) The in-built password field is not otherwise special for the purposes of ExternalSecrets. It can be ignored when not in use. Examples Examples of using the my-env-config and my-cert Items seen above . Note: with this configuration a 1Password Item titled my-env-config is correlated to a ExternalSecret named my-env-config that results in a Kubernetes secret named my-env-config , all with matching names for the key/value pairs. This is a way to increase comprehensibility. --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : staging spec : provider : onepassword : connectHost : https://onepassword-connect-staging vaults : staging : 1 # look in this vault first shared : 2 # next look in here. error if not found auth : secretRef : connectTokenSecretRef : name : onepassword-connect-token-staging key : token --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-env-config spec : secretStoreRef : kind : SecretStore name : staging target : creationPolicy : Owner data : - secretKey : MY_ENV_VAR1 remoteRef : key : my-env-config property : MY_ENV_VAR1 - secretKey : MY_ENV_VAR2 remoteRef : key : my-env-config property : MY_ENV_VAR2 # OR dataFrom : - extract : key : my-env-config property : MY_ENV_VAR1 # optional field Label to match exactly # OR - find : path : my-env-config # optional Item Title to match exactly name : regexp : \"^MY_ENV_VAR.*\" --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-cert spec : secretStoreRef : kind : SecretStore name : staging target : creationPolicy : Owner data : - secretKey : cert.crt remoteRef : key : my-cert property : cert.crt - secretKey : cert.key remoteRef : key : my-cert property : cert.key # OR dataFrom : - extract : key : my-cert property : cert.key # optional field Label to match exactly # OR - find : path : my-cert # optional Item Title to match exactly name : regexp : \"^cert.*\" Additional Notes General It's intuative to use Document type Items for Kubernetes secrets mounted as files, and Password type Items for ones that will be mounted as environment variables, but either can be used for either. It comes down to what's more convenient. Why no version history 1Password only supports version history on their in-built password field. Therefore, implementing version history in this provider would require one Item in 1Password per remoteRef in an ExternalSecret. Additionally remoteRef.property would be pointless/unusable. For example, a Kubernetes secret with 15 keys (say, used in envFrom ,) would require 15 Items in the 1Password vault, instead of 15 Fields in 1 Item. This would quickly get untenable for more than a few secrets, because: All Items would have to have unique names which means secretKey couldn't match the Item name the remoteRef is targeting. Maintenance, particularly clean up of no longer used secrets, would be significantly more work. A vault would often become a huge list of unorganized entries as opposed to a much smaller list organized by Kubernetes Secret. To support new and old versions of a secret value at the same time, create a new Item in 1Password with the new value, and point some ExternalSecrets at a time to the new Item. Keeping misconfiguration from working One instance of the ExternalSecrets Operator can work with many Connect Server instances, but it may not be the best approach. With one Operator instance per Connect Server instance, namespaces and RBAC can be used to improve security posture, and perhaps just as importantly, it's harder to misconfigure something and have it work (supply env A's secret values to env B for example.) You can run as many 1Password Connect Servers as you need security boundaries to help protect against accidental misconfiguration. Patching ExternalSecrets with Kustomize An overlay can provide a SecretStore specific to that overlay, and then use JSON6902 to patch all the ExternalSecrets coming from base to point to that SecretStore. Here's an example overlays/staging/kustomization.yaml : --- apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - ../../base/something-with-external-secrets - secretStore.staging.yaml patchesJson6902 : - target : kind : ExternalSecret name : \".*\" patch : |- - op: replace path: /spec/secretStoreRef/name value: staging","title":"Secrets Automation"},{"location":"provider/1password-automation/#1password-secrets-automation","text":"External Secrets Operator integrates with 1Password Secrets Automation for secret management.","title":"1Password Secrets Automation"},{"location":"provider/1password-automation/#important-note-about-this-documentation","text":"The 1Password API calls the entries in vaults 'Items'. These docs use the same term.","title":"Important note about this documentation"},{"location":"provider/1password-automation/#behavior","text":"How an Item is equated to an ExternalSecret: remoteRef.key is equated to an Item's Title remoteRef.property is equated to: An Item's field's Label (Password type) An Item's file's Name (Document type) If empty, defaults to the first file name, or the field labeled password remoteRef.version is currently not supported. One Item in a vault can equate to one Kubernetes Secret to keep things easy to comprehend. Support for 1Password secret types of Password and Document . The Password type can get data from multiple fields in the Item. The Document type can get data from files. See creating 1Password Items compatible with ExternalSecrets . Ordered vaults Specify an ordered list of vaults in a SecretStore and the value will be sourced from the first vault with a matching Item. If no matching Item is found, an error is returned. This supports having a default or shared set of values that can also be overriden for specific environments. dataFrom : find.path is equated to Item Title. find.name.regexp is equated to field Labels. find.tags are not supported at this time.","title":"Behavior"},{"location":"provider/1password-automation/#prerequisites","text":"1Password requires running a 1Password Connect Server to which the API requests will be made. External Secrets does not run this server. See Deploy a Connect Server . One Connect Server is needed per 1Password Automation Environment. Many Vaults can be added to an Automation Environment, and Tokens can be generated in that Environment with access to any set or subset of those Vaults. 1Password Connect Server version 1.5.6 or higher.","title":"Prerequisites"},{"location":"provider/1password-automation/#setup-authentication","text":"Authentication requires a 1password-credentials.json file provided to the Connect Server, and a related 'Access Token' for the client in this provider to authenticate to that Connect Server. Both of these are generated by 1Password. Setup an Automation Environment at 1Password.com , or via the op CLI . Note: don't be confused by the op connect server create syntax. This will create an Automation Environment in 1Password, and corresponding credentials for a Connect Server, nothing more. This will result in a 1password-credentials.json file to provide to a Connect Server Deployment, and an Access Token to provide as a Secret referenced by a SecretStore or ClusterSecretStore . Create a Kubernetes secret with the Access Token --- apiVersion : v1 kind : Secret metadata : name : onepassword-connect-token-staging type : Opaque stringData : token : my-token Reference the secret in a SecretStore or ClusterSecretStore --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : staging spec : provider : onepassword : connectHost : https://onepassword-connect-staging vaults : staging : 1 # look in this vault first shared : 2 # next look in here. error if not found auth : secretRef : connectTokenSecretRef : name : onepassword-connect-token-staging key : token Create a Kubernetes secret with the Connect Server credentials --- apiVersion : v1 kind : Secret metadata : name : connect-server-credentials type : Opaque stringData : # NOTE: This secret value must be base64 encoded after it becomes the OP_SESSION env var in the Connect Server Deployment, that means double base64 encoded here. (Or single w/ stringData.) 1password-credentials.json : |- eyJ2ZXJpZmllciI6eyJzYWx0IjoiZXhhbXBsZSIsImxvY2FsSGFzaCI6ImV4YW1wbGUifSwiZW5jQ3JlZGVudGlhbHMiOnsia2lkIjoiZXhhbXBsZSIsImVuYyI6ImV4YW1wbGUiLCJjdHkiOiJleGFtcGxlIiwiaXYiOiJleGFtcGxlIiwiZGF0YSI6ImV4YW1wbGUifSwidmVyc2lvbiI6IjIiLCJkZXZpY2VVdWlkIjoiZXhhbXBsZSIsInVuaXF1ZUtleSI6eyJhbGciOiJleGFtcGxlIiwiZXh0Ijp0cnVlLCJrIjoiZXhhbXBsZSIsImtleV9vcHMiOlsiZW5jcnlwdCIsImRlY3J5cHQiXSwia3R5Ijoib2N0Iiwia2lkIjoiZXhhbXBsZSJ9fQ== Reference the secret in a Connect Server Deployment --- apiVersion : apps/v1 kind : Deployment metadata : name : onepassword-connect-staging spec : template : spec : containers : - name : connect-api image : 1password/connect-api:1.5.0 env : - name : OP_SESSION valueFrom : secretKeyRef : name : connect-server-credentials key : 1password-credentials.json ... - name : connect-sync image : 1password/connect-sync:1.5.0 env : - name : OP_SESSION valueFrom : secretKeyRef : name : connect-server-credentials key : 1password-credentials.json ... ...","title":"Setup Authentication"},{"location":"provider/1password-automation/#deploy-a-connect-server","text":"Follow the remaining instructions in the Quick Start guide . Deploy at minimum a Deployment and Service for a Connect Server, to go along with the Secret for the Server created in the Setup Authentication section . The Service's name will be referenced in SecretStores/ClusterSecretStores. Keep in mind the likely need for additional Connect Servers for other Automation Environments when naming objects. For example dev, staging, prod, etc. Unencrypted secret values are passed over the connection between the Operator and the Connect Server. Encrypting the connection is recommended.","title":"Deploy a Connect Server"},{"location":"provider/1password-automation/#creating-compatible-1password-items","text":"Also see examples below for matching SecretStore and ExternalSecret specs.","title":"Creating Compatible 1Password Items"},{"location":"provider/1password-automation/#manually-password-type","text":"Click the plus button to create a new Password type Item. Change the title to what you want remoteRef.key to be. Set what you want remoteRef.property to be in the field sections where is says 'label', and values where it says 'new field'. Click the 'Save' button.","title":"Manually (Password type)"},{"location":"provider/1password-automation/#manually-document-type","text":"Click the plus button to create a new Document type Item. Choose the file to upload and upload it. Change the title to match remoteRef.key Click the 'Add New File' button to add more files. Click the 'Save' button.","title":"Manually (Document type)"},{"location":"provider/1password-automation/#scripting-password-type-with-op-cli","text":"Create file.json with the following contents, swapping in your keys and values. Note: section.name 's and section.title 's values are ignored by the Operator, but cannot be empty for the op CLI { \"sections\" : [ { \"fields\" : [ { \"k\" : \"concealed\" , \"n\" : \"MY_ENV_VAR1\" , \"t\" : \"MY_ENV_VAR1\" , \"v\" : \"value1\" }, { \"k\" : \"concealed\" , \"n\" : \"MY_ENV_VAR2\" , \"t\" : \"MY_ENV_VAR2\" , \"v\" : \"value2\" } ], \"name\" : \"EXTERNAL-SECRETS\" , \"title\" : \"EXTERNAL-SECRETS\" } ] } Run op create item password --template file.json --vault my-vault --title my-item","title":"Scripting (Password type with op CLI)"},{"location":"provider/1password-automation/#scripting-document-type","text":"Unfortunately the op CLI doesn't seem to support uploading multiple files to the same Item, and the current Go lib has a bug . op can be used to create a Document type Item with one file in it, but for now it's necessary to add multiple files to the same Document via the GUI.","title":"Scripting (Document type)"},{"location":"provider/1password-automation/#in-built-field-labeled-password-on-password-type-items","text":"TL;DR if you need a field labeled password , use the in-built one rather than the one in a fields Section. 1Password automatically adds a field labeled password on every Password type Item, whether it's created through a GUI or the API or op CLI. There's no problem with using this field just like any other field, just make sure you don't end up with two fields with the same label . (For example, by automating the op CLI to create Items.) The in-built password field is not otherwise special for the purposes of ExternalSecrets. It can be ignored when not in use.","title":"In-built field labeled password on Password type Items"},{"location":"provider/1password-automation/#examples","text":"Examples of using the my-env-config and my-cert Items seen above . Note: with this configuration a 1Password Item titled my-env-config is correlated to a ExternalSecret named my-env-config that results in a Kubernetes secret named my-env-config , all with matching names for the key/value pairs. This is a way to increase comprehensibility. --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : staging spec : provider : onepassword : connectHost : https://onepassword-connect-staging vaults : staging : 1 # look in this vault first shared : 2 # next look in here. error if not found auth : secretRef : connectTokenSecretRef : name : onepassword-connect-token-staging key : token --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-env-config spec : secretStoreRef : kind : SecretStore name : staging target : creationPolicy : Owner data : - secretKey : MY_ENV_VAR1 remoteRef : key : my-env-config property : MY_ENV_VAR1 - secretKey : MY_ENV_VAR2 remoteRef : key : my-env-config property : MY_ENV_VAR2 # OR dataFrom : - extract : key : my-env-config property : MY_ENV_VAR1 # optional field Label to match exactly # OR - find : path : my-env-config # optional Item Title to match exactly name : regexp : \"^MY_ENV_VAR.*\" --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : my-cert spec : secretStoreRef : kind : SecretStore name : staging target : creationPolicy : Owner data : - secretKey : cert.crt remoteRef : key : my-cert property : cert.crt - secretKey : cert.key remoteRef : key : my-cert property : cert.key # OR dataFrom : - extract : key : my-cert property : cert.key # optional field Label to match exactly # OR - find : path : my-cert # optional Item Title to match exactly name : regexp : \"^cert.*\"","title":"Examples"},{"location":"provider/1password-automation/#additional-notes","text":"","title":"Additional Notes"},{"location":"provider/1password-automation/#general","text":"It's intuative to use Document type Items for Kubernetes secrets mounted as files, and Password type Items for ones that will be mounted as environment variables, but either can be used for either. It comes down to what's more convenient.","title":"General"},{"location":"provider/1password-automation/#why-no-version-history","text":"1Password only supports version history on their in-built password field. Therefore, implementing version history in this provider would require one Item in 1Password per remoteRef in an ExternalSecret. Additionally remoteRef.property would be pointless/unusable. For example, a Kubernetes secret with 15 keys (say, used in envFrom ,) would require 15 Items in the 1Password vault, instead of 15 Fields in 1 Item. This would quickly get untenable for more than a few secrets, because: All Items would have to have unique names which means secretKey couldn't match the Item name the remoteRef is targeting. Maintenance, particularly clean up of no longer used secrets, would be significantly more work. A vault would often become a huge list of unorganized entries as opposed to a much smaller list organized by Kubernetes Secret. To support new and old versions of a secret value at the same time, create a new Item in 1Password with the new value, and point some ExternalSecrets at a time to the new Item.","title":"Why no version history"},{"location":"provider/1password-automation/#keeping-misconfiguration-from-working","text":"One instance of the ExternalSecrets Operator can work with many Connect Server instances, but it may not be the best approach. With one Operator instance per Connect Server instance, namespaces and RBAC can be used to improve security posture, and perhaps just as importantly, it's harder to misconfigure something and have it work (supply env A's secret values to env B for example.) You can run as many 1Password Connect Servers as you need security boundaries to help protect against accidental misconfiguration.","title":"Keeping misconfiguration from working"},{"location":"provider/1password-automation/#patching-externalsecrets-with-kustomize","text":"An overlay can provide a SecretStore specific to that overlay, and then use JSON6902 to patch all the ExternalSecrets coming from base to point to that SecretStore. Here's an example overlays/staging/kustomization.yaml : --- apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - ../../base/something-with-external-secrets - secretStore.staging.yaml patchesJson6902 : - target : kind : ExternalSecret name : \".*\" patch : |- - op: replace path: /spec/secretStoreRef/name value: staging","title":"Patching ExternalSecrets with Kustomize"},{"location":"provider/akeyless/","text":"Akeyless Vault External Secrets Operator integrates with Akeyless API . Authentication The API requires an access-id, access-type and access-Type-param. The supported auth-methods and their params are: accessType accessTypeParam api_key The access key. k8s The k8s configuration name aws_iam - gcp The gcp audience azure_ad azure object id (optional) form more information about Akeyless Authentication Methods Akeless credentials secret Create a secret containing your credentials: apiVersion : v1 kind : Secret metadata : name : akeylss-secret-creds type : Opaque stringData : accessId : \"p-XXXX\" accessType : # k8s/aws_iam/gcp/azure_ad/api_key accessTypeParam : # can be one of the following: k8s-conf-name/gcp-audience/azure-obj-id/access-key Update secret store Be sure the akeyless provider is listed in the Kind=SecretStore and the akeylessGWApiURL is set (def: \"https://api.akeless.io\". apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : akeyless-secret-store spec : provider : akeyless : # URL of your akeyless API akeylessGWApiURL : \"https://api.akeyless.io\" authSecretRef : secretRef : accessID : name : akeylss-secret-creds key : accessId accessType : name : akeylss-secret-creds key : accessType accessTypeParam : name : akeylss-secret-creds key : accessTypeParam NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for accessID , accessType and accessTypeParam with the namespaces where the secrets reside. Creating external secret To get a secret from Akeyless and secret it on the Kubernetes cluster, a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : akeyless-external-secret-example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : akeyless-secret-store # Must match SecretStore on the cluster target : name : akeyless-secret-to-create # Name for the secret to be created on the cluster creationPolicy : Owner data : - secretKey : secretKey # Key given to the secret to be created on the cluster remoteRef : key : secret-name # Full path of the secret on Akeyless Using DataFrom DataFrom can be used to get a secret as a JSON string and attempt to parse it. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : akeyless-external-secret-example-json spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : akeyless-secret-store # Must match SecretStore on the cluster target : name : akeyless-secret-to-create-json # Name for the secret to be created on the cluster creationPolicy : Owner # for json formatted secrets: each key in the json will be used as the secret key in the SECRET k8s target object dataFrom : - extract : key : secret-name # Full path of the secret on Akeyless Getting the Kubernetes secret The operator will fetch the secret and inject it as a Kind=Secret . kubectl get secret akeyless-secret-to-create -o jsonpath='{.data.secretKey}' | base64 -d kubectl get secret akeyless-secret-to-create-json -o jsonpath='{.data}'","title":"Akeyless"},{"location":"provider/akeyless/#akeyless-vault","text":"External Secrets Operator integrates with Akeyless API .","title":"Akeyless Vault"},{"location":"provider/akeyless/#authentication","text":"The API requires an access-id, access-type and access-Type-param. The supported auth-methods and their params are: accessType accessTypeParam api_key The access key. k8s The k8s configuration name aws_iam - gcp The gcp audience azure_ad azure object id (optional) form more information about Akeyless Authentication Methods","title":"Authentication"},{"location":"provider/akeyless/#akeless-credentials-secret","text":"Create a secret containing your credentials: apiVersion : v1 kind : Secret metadata : name : akeylss-secret-creds type : Opaque stringData : accessId : \"p-XXXX\" accessType : # k8s/aws_iam/gcp/azure_ad/api_key accessTypeParam : # can be one of the following: k8s-conf-name/gcp-audience/azure-obj-id/access-key","title":"Akeless credentials secret"},{"location":"provider/akeyless/#update-secret-store","text":"Be sure the akeyless provider is listed in the Kind=SecretStore and the akeylessGWApiURL is set (def: \"https://api.akeless.io\". apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : akeyless-secret-store spec : provider : akeyless : # URL of your akeyless API akeylessGWApiURL : \"https://api.akeyless.io\" authSecretRef : secretRef : accessID : name : akeylss-secret-creds key : accessId accessType : name : akeylss-secret-creds key : accessType accessTypeParam : name : akeylss-secret-creds key : accessTypeParam NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for accessID , accessType and accessTypeParam with the namespaces where the secrets reside.","title":"Update secret store"},{"location":"provider/akeyless/#creating-external-secret","text":"To get a secret from Akeyless and secret it on the Kubernetes cluster, a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : akeyless-external-secret-example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : akeyless-secret-store # Must match SecretStore on the cluster target : name : akeyless-secret-to-create # Name for the secret to be created on the cluster creationPolicy : Owner data : - secretKey : secretKey # Key given to the secret to be created on the cluster remoteRef : key : secret-name # Full path of the secret on Akeyless","title":"Creating external secret"},{"location":"provider/akeyless/#using-datafrom","text":"DataFrom can be used to get a secret as a JSON string and attempt to parse it. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : akeyless-external-secret-example-json spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : akeyless-secret-store # Must match SecretStore on the cluster target : name : akeyless-secret-to-create-json # Name for the secret to be created on the cluster creationPolicy : Owner # for json formatted secrets: each key in the json will be used as the secret key in the SECRET k8s target object dataFrom : - extract : key : secret-name # Full path of the secret on Akeyless","title":"Using DataFrom"},{"location":"provider/akeyless/#getting-the-kubernetes-secret","text":"The operator will fetch the secret and inject it as a Kind=Secret . kubectl get secret akeyless-secret-to-create -o jsonpath='{.data.secretKey}' | base64 -d kubectl get secret akeyless-secret-to-create-json -o jsonpath='{.data}'","title":"Getting the Kubernetes secret"},{"location":"provider/aws-parameter-store/","text":"Parameter Store A ParameterStore points to AWS SSM Parameter Store in a certain account within a defined region. You should define Roles that define fine-grained access to individual secrets and pass them to ESO using spec.provider.aws.role . This way users of the SecretStore can only access the secrets necessary. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : ParameterStore # define a specific role to limit access # to certain secrets role : iam-role region : eu-central-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef and secretAccessKeySecretRef with the namespaces where the secrets reside. API Pricing & Throttling The SSM Parameter Store API is charged by throughput and is available in different tiers, see pricing . Please estimate your costs before using ESO. Cost depends on the RefreshInterval of your ExternalSecrets. IAM Policy Create a IAM Policy to pin down access to secrets matching dev-* , for further information see AWS Documentation : { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"ssm:GetParameter*\" ], \"Resource\" : \"arn:aws:ssm:us-east-2:123456789012:parameter/dev-*\" } ] } JSON Secret Values You can store JSON objects in a parameter. You can access nested values or arrays using gjson syntax : Consider the following JSON object that is stored in the Parameter Store key my-json-secret : { \"name\" : { \"first\" : \"Tom\" , \"last\" : \"Anderson\" }, \"friends\" : [ { \"first\" : \"Dale\" , \"last\" : \"Murphy\" }, { \"first\" : \"Roger\" , \"last\" : \"Craig\" }, { \"first\" : \"Jane\" , \"last\" : \"Murphy\" } ] } This is an example on how you would look up nested keys in the above json object: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : # [omitted for brevity] data : - secretKey : firstname remoteRef : key : my-json-secret property : name.first # Tom - secretKey : first_friend remoteRef : key : my-json-secret property : friends.1.first # Roger AWS Authentication Controller's Pod Identity Note: If you are using Parameter Store replace service: SecretsManager with service: ParameterStore in all examples below. This is basicially a zero-configuration authentication method that inherits the credentials from the runtime environment using the aws sdk default credential chain . You can attach a role to the pod using IRSA , kiam or kube2iam . When no other authentication method is configured in the Kind=Secretstore this role is used to make all API calls against AWS Secrets Manager or SSM Parameter Store. Based on the Pod's identity you can do a sts:assumeRole before fetching the secrets to limit access to certain keys in your provider. This is optional. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: do a sts:assumeRole before fetching secrets role : team-b Access Key ID & Secret Access Key You can store Access Key ID & Secret Access Key in a Kind=Secret and reference it from a SecretStore. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: assume role before fetching secrets role : team-b auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef , secretAccessKeySecretRef with the namespaces where the secrets reside. EKS Service Account credentials This feature lets you use short-lived service account tokens to authenticate with AWS. You must have Service Account Volume Projection enabled - it is by default on EKS. See EKS guide on how to set up IAM roles for service accounts. The big advantage of this approach is that ESO runs without any credentials. apiVersion : v1 kind : ServiceAccount metadata : annotations : eks.amazonaws.com/role-arn : arn:aws:iam::123456789012:role/team-a name : my-serviceaccount namespace : default Reference the service account from above in the Secret Store: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : eu-central-1 auth : jwt : serviceAccountRef : name : my-serviceaccount NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for serviceAccountRef with the namespace where the service account resides. Custom Endpoints You can define custom AWS endpoints if you want to use regional, vpc or custom endpoints. See List of endpoints for Secrets Manager , Secure Systems Manager and Security Token Service . Use the following environment variables to point the controller to your custom endpoints. Note: All resources managed by this controller are affected. ENV VAR DESCRIPTION AWS_SECRETSMANAGER_ENDPOINT Endpoint for the Secrets Manager Service. The controller uses this endpoint to fetch secrets from AWS Secrets Manager. AWS_SSM_ENDPOINT Endpoint for the AWS Secure Systems Manager. The controller uses this endpoint to fetch secrets from SSM Parameter Store. AWS_STS_ENDPOINT Endpoint for the Security Token Service. The controller uses this endpoint when creating a session and when doing assumeRole or assumeRoleWithWebIdentity calls.","title":"Parameter Store"},{"location":"provider/aws-parameter-store/#parameter-store","text":"A ParameterStore points to AWS SSM Parameter Store in a certain account within a defined region. You should define Roles that define fine-grained access to individual secrets and pass them to ESO using spec.provider.aws.role . This way users of the SecretStore can only access the secrets necessary. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : ParameterStore # define a specific role to limit access # to certain secrets role : iam-role region : eu-central-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef and secretAccessKeySecretRef with the namespaces where the secrets reside. API Pricing & Throttling The SSM Parameter Store API is charged by throughput and is available in different tiers, see pricing . Please estimate your costs before using ESO. Cost depends on the RefreshInterval of your ExternalSecrets.","title":"Parameter Store"},{"location":"provider/aws-parameter-store/#iam-policy","text":"Create a IAM Policy to pin down access to secrets matching dev-* , for further information see AWS Documentation : { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"ssm:GetParameter*\" ], \"Resource\" : \"arn:aws:ssm:us-east-2:123456789012:parameter/dev-*\" } ] }","title":"IAM Policy"},{"location":"provider/aws-parameter-store/#json-secret-values","text":"You can store JSON objects in a parameter. You can access nested values or arrays using gjson syntax : Consider the following JSON object that is stored in the Parameter Store key my-json-secret : { \"name\" : { \"first\" : \"Tom\" , \"last\" : \"Anderson\" }, \"friends\" : [ { \"first\" : \"Dale\" , \"last\" : \"Murphy\" }, { \"first\" : \"Roger\" , \"last\" : \"Craig\" }, { \"first\" : \"Jane\" , \"last\" : \"Murphy\" } ] } This is an example on how you would look up nested keys in the above json object: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : # [omitted for brevity] data : - secretKey : firstname remoteRef : key : my-json-secret property : name.first # Tom - secretKey : first_friend remoteRef : key : my-json-secret property : friends.1.first # Roger","title":"JSON Secret Values"},{"location":"provider/aws-parameter-store/#aws-authentication","text":"","title":"AWS Authentication"},{"location":"provider/aws-parameter-store/#controllers-pod-identity","text":"Note: If you are using Parameter Store replace service: SecretsManager with service: ParameterStore in all examples below. This is basicially a zero-configuration authentication method that inherits the credentials from the runtime environment using the aws sdk default credential chain . You can attach a role to the pod using IRSA , kiam or kube2iam . When no other authentication method is configured in the Kind=Secretstore this role is used to make all API calls against AWS Secrets Manager or SSM Parameter Store. Based on the Pod's identity you can do a sts:assumeRole before fetching the secrets to limit access to certain keys in your provider. This is optional. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: do a sts:assumeRole before fetching secrets role : team-b","title":"Controller's Pod Identity"},{"location":"provider/aws-parameter-store/#access-key-id-secret-access-key","text":"You can store Access Key ID & Secret Access Key in a Kind=Secret and reference it from a SecretStore. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: assume role before fetching secrets role : team-b auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef , secretAccessKeySecretRef with the namespaces where the secrets reside.","title":"Access Key ID &amp; Secret Access Key"},{"location":"provider/aws-parameter-store/#eks-service-account-credentials","text":"This feature lets you use short-lived service account tokens to authenticate with AWS. You must have Service Account Volume Projection enabled - it is by default on EKS. See EKS guide on how to set up IAM roles for service accounts. The big advantage of this approach is that ESO runs without any credentials. apiVersion : v1 kind : ServiceAccount metadata : annotations : eks.amazonaws.com/role-arn : arn:aws:iam::123456789012:role/team-a name : my-serviceaccount namespace : default Reference the service account from above in the Secret Store: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : eu-central-1 auth : jwt : serviceAccountRef : name : my-serviceaccount NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for serviceAccountRef with the namespace where the service account resides.","title":"EKS Service Account credentials"},{"location":"provider/aws-parameter-store/#custom-endpoints","text":"You can define custom AWS endpoints if you want to use regional, vpc or custom endpoints. See List of endpoints for Secrets Manager , Secure Systems Manager and Security Token Service . Use the following environment variables to point the controller to your custom endpoints. Note: All resources managed by this controller are affected. ENV VAR DESCRIPTION AWS_SECRETSMANAGER_ENDPOINT Endpoint for the Secrets Manager Service. The controller uses this endpoint to fetch secrets from AWS Secrets Manager. AWS_SSM_ENDPOINT Endpoint for the AWS Secure Systems Manager. The controller uses this endpoint to fetch secrets from SSM Parameter Store. AWS_STS_ENDPOINT Endpoint for the Security Token Service. The controller uses this endpoint when creating a session and when doing assumeRole or assumeRoleWithWebIdentity calls.","title":"Custom Endpoints"},{"location":"provider/aws-secrets-manager/","text":"Secrets Manager A SecretStore points to AWS Secrets Manager in a certain account within a defined region. You should define Roles that define fine-grained access to individual secrets and pass them to ESO using spec.provider.aws.role . This way users of the SecretStore can only access the secrets necessary. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager # define a specific role to limit access # to certain secrets. # role is a optional field that # can be omitted for test purposes role : iam-role region : eu-central-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef and secretAccessKeySecretRef with the namespaces where the secrets reside. IAM Policy Create a IAM Policy to pin down access to secrets matching dev-* . { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"secretsmanager:GetResourcePolicy\" , \"secretsmanager:GetSecretValue\" , \"secretsmanager:DescribeSecret\" , \"secretsmanager:ListSecretVersionIds\" ], \"Resource\" : [ \"arn:aws:secretsmanager:us-west-2:111122223333:secret:dev-*\" ] } ] } JSON Secret Values SecretsManager supports simple key/value pairs that are stored as json. If you use the API you can store more complex JSON objects. You can access nested values or arrays using gjson syntax : Consider the following JSON object that is stored in the SecretsManager key my-json-secret : { \"name\" : { \"first\" : \"Tom\" , \"last\" : \"Anderson\" }, \"friends\" : [ { \"first\" : \"Dale\" , \"last\" : \"Murphy\" }, { \"first\" : \"Roger\" , \"last\" : \"Craig\" }, { \"first\" : \"Jane\" , \"last\" : \"Murphy\" } ] } This is an example on how you would look up nested keys in the above json object: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1m secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : firstname remoteRef : key : my-json-secret property : name.first # Tom - secretKey : first_friend remoteRef : key : my-json-secret property : friends.1.first # Roger Secret Versions SecretsManager creates a new version of a secret every time it is updated. The secret version can be reference in two ways, the VersionStage and the VersionId . The VersionId is a unique uuid which is generated every time the secret changes. This id is immutable and will always refer to the same secret data. The VersionStage is an alias to a VersionId , and can refer to different secret data as the secret is updated. By default, SecretsManager will add the version stages AWSCURRENT and AWSPREVIOUS to every secret, but other stages can be created via the update-secret-version-stage api. The version field on the remoteRef of the ExternalSecret will normally consider the version to be a VersionStage , but if the field is prefixed with uuid/ , then the version will be considered a VersionId . So in this example, the operator will request the secret with VersionStage as AWSPREVIOUS : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : \"example/secret\" version : \"AWSPREVIOUS\" While in this example, the operator will request the secret with VersionId as abcd-1234 apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : \"example/secret\" version : \"uuid/abcd-1234\" AWS Authentication Controller's Pod Identity Note: If you are using Parameter Store replace service: SecretsManager with service: ParameterStore in all examples below. This is basicially a zero-configuration authentication method that inherits the credentials from the runtime environment using the aws sdk default credential chain . You can attach a role to the pod using IRSA , kiam or kube2iam . When no other authentication method is configured in the Kind=Secretstore this role is used to make all API calls against AWS Secrets Manager or SSM Parameter Store. Based on the Pod's identity you can do a sts:assumeRole before fetching the secrets to limit access to certain keys in your provider. This is optional. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: do a sts:assumeRole before fetching secrets role : team-b Access Key ID & Secret Access Key You can store Access Key ID & Secret Access Key in a Kind=Secret and reference it from a SecretStore. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: assume role before fetching secrets role : team-b auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef , secretAccessKeySecretRef with the namespaces where the secrets reside. EKS Service Account credentials This feature lets you use short-lived service account tokens to authenticate with AWS. You must have Service Account Volume Projection enabled - it is by default on EKS. See EKS guide on how to set up IAM roles for service accounts. The big advantage of this approach is that ESO runs without any credentials. apiVersion : v1 kind : ServiceAccount metadata : annotations : eks.amazonaws.com/role-arn : arn:aws:iam::123456789012:role/team-a name : my-serviceaccount namespace : default Reference the service account from above in the Secret Store: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : eu-central-1 auth : jwt : serviceAccountRef : name : my-serviceaccount NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for serviceAccountRef with the namespace where the service account resides. Custom Endpoints You can define custom AWS endpoints if you want to use regional, vpc or custom endpoints. See List of endpoints for Secrets Manager , Secure Systems Manager and Security Token Service . Use the following environment variables to point the controller to your custom endpoints. Note: All resources managed by this controller are affected. ENV VAR DESCRIPTION AWS_SECRETSMANAGER_ENDPOINT Endpoint for the Secrets Manager Service. The controller uses this endpoint to fetch secrets from AWS Secrets Manager. AWS_SSM_ENDPOINT Endpoint for the AWS Secure Systems Manager. The controller uses this endpoint to fetch secrets from SSM Parameter Store. AWS_STS_ENDPOINT Endpoint for the Security Token Service. The controller uses this endpoint when creating a session and when doing assumeRole or assumeRoleWithWebIdentity calls.","title":"Secrets Manager"},{"location":"provider/aws-secrets-manager/#secrets-manager","text":"A SecretStore points to AWS Secrets Manager in a certain account within a defined region. You should define Roles that define fine-grained access to individual secrets and pass them to ESO using spec.provider.aws.role . This way users of the SecretStore can only access the secrets necessary. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager # define a specific role to limit access # to certain secrets. # role is a optional field that # can be omitted for test purposes role : iam-role region : eu-central-1 auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef and secretAccessKeySecretRef with the namespaces where the secrets reside.","title":"Secrets Manager"},{"location":"provider/aws-secrets-manager/#iam-policy","text":"Create a IAM Policy to pin down access to secrets matching dev-* . { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"secretsmanager:GetResourcePolicy\" , \"secretsmanager:GetSecretValue\" , \"secretsmanager:DescribeSecret\" , \"secretsmanager:ListSecretVersionIds\" ], \"Resource\" : [ \"arn:aws:secretsmanager:us-west-2:111122223333:secret:dev-*\" ] } ] }","title":"IAM Policy"},{"location":"provider/aws-secrets-manager/#json-secret-values","text":"SecretsManager supports simple key/value pairs that are stored as json. If you use the API you can store more complex JSON objects. You can access nested values or arrays using gjson syntax : Consider the following JSON object that is stored in the SecretsManager key my-json-secret : { \"name\" : { \"first\" : \"Tom\" , \"last\" : \"Anderson\" }, \"friends\" : [ { \"first\" : \"Dale\" , \"last\" : \"Murphy\" }, { \"first\" : \"Roger\" , \"last\" : \"Craig\" }, { \"first\" : \"Jane\" , \"last\" : \"Murphy\" } ] } This is an example on how you would look up nested keys in the above json object: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1m secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : firstname remoteRef : key : my-json-secret property : name.first # Tom - secretKey : first_friend remoteRef : key : my-json-secret property : friends.1.first # Roger","title":"JSON Secret Values"},{"location":"provider/aws-secrets-manager/#secret-versions","text":"SecretsManager creates a new version of a secret every time it is updated. The secret version can be reference in two ways, the VersionStage and the VersionId . The VersionId is a unique uuid which is generated every time the secret changes. This id is immutable and will always refer to the same secret data. The VersionStage is an alias to a VersionId , and can refer to different secret data as the secret is updated. By default, SecretsManager will add the version stages AWSCURRENT and AWSPREVIOUS to every secret, but other stages can be created via the update-secret-version-stage api. The version field on the remoteRef of the ExternalSecret will normally consider the version to be a VersionStage , but if the field is prefixed with uuid/ , then the version will be considered a VersionId . So in this example, the operator will request the secret with VersionStage as AWSPREVIOUS : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : \"example/secret\" version : \"AWSPREVIOUS\" While in this example, the operator will request the secret with VersionId as abcd-1234 apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : secret-key-to-be-managed remoteRef : key : \"example/secret\" version : \"uuid/abcd-1234\"","title":"Secret Versions"},{"location":"provider/aws-secrets-manager/#aws-authentication","text":"","title":"AWS Authentication"},{"location":"provider/aws-secrets-manager/#controllers-pod-identity","text":"Note: If you are using Parameter Store replace service: SecretsManager with service: ParameterStore in all examples below. This is basicially a zero-configuration authentication method that inherits the credentials from the runtime environment using the aws sdk default credential chain . You can attach a role to the pod using IRSA , kiam or kube2iam . When no other authentication method is configured in the Kind=Secretstore this role is used to make all API calls against AWS Secrets Manager or SSM Parameter Store. Based on the Pod's identity you can do a sts:assumeRole before fetching the secrets to limit access to certain keys in your provider. This is optional. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: do a sts:assumeRole before fetching secrets role : team-b","title":"Controller's Pod Identity"},{"location":"provider/aws-secrets-manager/#access-key-id-secret-access-key","text":"You can store Access Key ID & Secret Access Key in a Kind=Secret and reference it from a SecretStore. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: assume role before fetching secrets role : team-b auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef , secretAccessKeySecretRef with the namespaces where the secrets reside.","title":"Access Key ID &amp; Secret Access Key"},{"location":"provider/aws-secrets-manager/#eks-service-account-credentials","text":"This feature lets you use short-lived service account tokens to authenticate with AWS. You must have Service Account Volume Projection enabled - it is by default on EKS. See EKS guide on how to set up IAM roles for service accounts. The big advantage of this approach is that ESO runs without any credentials. apiVersion : v1 kind : ServiceAccount metadata : annotations : eks.amazonaws.com/role-arn : arn:aws:iam::123456789012:role/team-a name : my-serviceaccount namespace : default Reference the service account from above in the Secret Store: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : eu-central-1 auth : jwt : serviceAccountRef : name : my-serviceaccount NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for serviceAccountRef with the namespace where the service account resides.","title":"EKS Service Account credentials"},{"location":"provider/aws-secrets-manager/#custom-endpoints","text":"You can define custom AWS endpoints if you want to use regional, vpc or custom endpoints. See List of endpoints for Secrets Manager , Secure Systems Manager and Security Token Service . Use the following environment variables to point the controller to your custom endpoints. Note: All resources managed by this controller are affected. ENV VAR DESCRIPTION AWS_SECRETSMANAGER_ENDPOINT Endpoint for the Secrets Manager Service. The controller uses this endpoint to fetch secrets from AWS Secrets Manager. AWS_SSM_ENDPOINT Endpoint for the AWS Secure Systems Manager. The controller uses this endpoint to fetch secrets from SSM Parameter Store. AWS_STS_ENDPOINT Endpoint for the Security Token Service. The controller uses this endpoint when creating a session and when doing assumeRole or assumeRoleWithWebIdentity calls.","title":"Custom Endpoints"},{"location":"provider/azure-key-vault/","text":"Azure Key vault External Secrets Operator integrates with Azure Key vault for secrets, certificates and Keys management. Authentication We support Service Principals, Managed Identity and Workload Identity authentication. To use Managed Identity authentication, you should use aad-pod-identity to assign the identity to external-secrets operator. To add the selector to external-secrets operator, use podLabels in your values.yaml in case of Helm installation of external-secrets. We support connecting to different cloud flavours azure supports: PublicCloud , USGovernmentCloud , ChinaCloud and GermanCloud . You have to specify the environmentType and point to the correct cloud flavour. This defaults to PublicCloud . apiVersion: external-secrets.io/v1beta1 kind: SecretStore metadata: name: azure-backend spec: provider: azurekv: # PublicCloud, USGovernmentCloud, ChinaCloud, GermanCloud environmentType: PublicCloud # default Minimum required permissions are Get over secret and certificate permissions. This can be done by adding a Key Vault access policy: KUBELET_IDENTITY_OBJECT_ID = $( az aks show --resource-group <AKS_CLUSTER_RG_NAME> --name <AKS_CLUSTER_NAME> --query 'identityProfile.kubeletidentity.objectId' -o tsv ) az keyvault set-policy --name kv-name-with-certs --object-id \" $KUBELET_IDENTITY_OBJECT_ID \" --certificate-permissions get --secret-permissions get Service Principal key authentication A service Principal client and Secret is created and the JSON keyfile is stored in a Kind=Secret . The ClientID and ClientSecret should be configured for the secret. This service principal should have proper access rights to the keyvault to be managed by the operator Managed Identity authentication A Managed Identity should be created in Azure, and that Identity should have proper rights to the keyvault to be managed by the operator. If there are multiple Managed Identitites for different keyvaults, the operator should have been assigned all identities via aad-pod-identity , then the SecretStore configuration should include the Id of the idenetity to be used via the identityId field. apiVersion : v1 kind : Secret metadata : name : azure-secret-sp type : Opaque data : ClientID : bXktc2VydmljZS1wcmluY2lwbGUtY2xpZW50LWlkCg== #service-principal-ID ClientSecret : bXktc2VydmljZS1wcmluY2lwbGUtY2xpZW50LXNlY3JldAo= #service-principal-secret Workload Identity You can use Azure AD Workload Identity Federation to access Azure managed services like Key Vault without needing to manage secrets . You need to configure a trust relationship between your Kubernetes Cluster and Azure AD. This can be done in various ways, for instance using terraform , the Azure Portal or the az cli. We found the azwi cli very helpful. The Azure Workload Identity Quick Start Guide is also good place to get started. This is basically a two step process: Create a Kubernetes Service Account ( guide ) azwi serviceaccount create phase sa \\ --aad-application-name \" ${ APPLICATION_NAME } \" \\ --service-account-namespace \" ${ SERVICE_ACCOUNT_NAMESPACE } \" \\ --service-account-name \" ${ SERVICE_ACCOUNT_NAME } \" 2. Configure the trust relationship between Azure AD and Kubernetes ( guide ) azwi serviceaccount create phase federated-identity \\ --aad-application-name \" ${ APPLICATION_NAME } \" \\ --service-account-namespace \" ${ SERVICE_ACCOUNT_NAMESPACE } \" \\ --service-account-name \" ${ SERVICE_ACCOUNT_NAME } \" \\ --service-account-issuer-url \" ${ SERVICE_ACCOUNT_ISSUER } \" With these prerequisites met you can configure ESO to use that Service Account. You have two options: Mounted Service Account You run the controller and mount that particular service account into the pod. That grants everyone who is able to create a secret store or reference a correctly configured one the ability to read secrets. This approach is usually not recommended . But may make sense when you want to share an identity with multiple namespaces. Also see our Multi-Tenancy Guide for design considerations. apiVersion : v1 kind : ServiceAccount metadata : # this service account was created by azwi name : workload-identity-sa annotations : azure.workload.identity/client-id : 7d8cdf74-xxxx-xxxx-xxxx-274d963d358b azure.workload.identity/tenant-id : 5a02a20e-xxxx-xxxx-xxxx-0ad5b634c5d8 --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : azurekv : authType : WorkloadIdentity vaultUrl : \"https://xx-xxxx-xx.vault.azure.net\" # note: no serviceAccountRef was provided Referenced Service Account You run the controller without service account (effectively without azure permissions). Now you have to configure the SecretStore and set the serviceAccountRef and point to the service account you have just created. This is usually the recommended approach . It makes sense for everyone who wants to run the controller withour Azure permissions and delegate authentication via service accounts in particular namespaces. Also see our [Multi-Tenancy Guide] for design considerations. apiVersion : v1 kind : ServiceAccount metadata : # this service account was created by azwi name : workload-identity-sa annotations : azure.workload.identity/client-id : 7d8cdf74-xxxx-xxxx-xxxx-274d963d358b azure.workload.identity/tenant-id : 5a02a20e-xxxx-xxxx-xxxx-0ad5b634c5d8 --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : azurekv : authType : WorkloadIdentity vaultUrl : \"https://xx-xxxx-xx.vault.azure.net\" serviceAccountRef : name : workload-identity-sa Update secret store Be sure the azurekv provider is listed in the Kind=SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : # provider type: azure keyvault azurekv : # azure tenant ID, see: https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-how-to-find-tenant tenantId : \"d3bc2180-xxxx-xxxx-xxxx-154105743342\" # URL of your vault instance, see: https://docs.microsoft.com/en-us/azure/key-vault/general/about-keys-secrets-certificates vaultUrl : \"https://my-keyvault-name.vault.azure.net\" authSecretRef : # points to the secret that contains # the azure service principal credentials clientId : name : azure-secret-sp key : ClientID clientSecret : name : azure-secret-sp key : ClientSecret NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in clientId and clientSecret with the namespaces where the secrets reside. Or in case of Managed Idenetity authentication: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : # provider type: azure keyvault azurekv : authType : ManagedIdentity # Optionally set the Id of the Managed Identity, if multiple identities are assigned to external-secrets operator identityId : \"<MI_clientId>\" # URL of your vault instance, see: https://docs.microsoft.com/en-us/azure/key-vault/general/about-keys-secrets-certificates vaultUrl : \"https://my-keyvault-name.vault.azure.net\" Object Types Azure KeyVault manages different object types , we support keys , secrets and certificates . Simply prefix the key with key , secret or cert to retrieve the desired type (defaults to secret). Object Type Return Value secret the raw secret value. key A JWK which contains the public key. Azure KeyVault does not export the private key. You may want to use template functions to transform this JWK into PEM encoded PKIX ASN.1 DER format. certificate The raw CER contents of the x509 certificate. You may want to use template functions to transform this into your desired encoding Creating external secret To create a kubernetes secret from the Azure Key vault secret a Kind=ExternalSecret is needed. You can manage keys/secrets/certificates saved inside the keyvault , by setting a \"/\" prefixed type in the secret name, the default type is a secret . Other supported values are cert and key . apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example-external-secret spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : example-secret-store target : name : secret-to-be-created creationPolicy : Owner data : # name of the SECRET in the Azure KV (no prefix is by default a SECRET) - secretKey : dev-secret-test remoteRef : key : dev-secret-test # explicit type and name of secret in the Azure KV - secretKey : dev-another-secret-test remoteRef : key : secret/dev-secret-test # metadataPolicy to fetch all the tags in JSON format - secretKey : dev-secret-test remoteRef : key : dev-secret-test metadataPolicy : Fetch # metadataPolicy to fetch a specific tag which name must be in property - secretKey : dev-secret-test remoteRef : key : dev-secret-test metadataPolicy : Fetch property : tagname # type/name of certificate in the Azure KV # raw value will be returned, use templating features for data processing - secretKey : dev-cert-test remoteRef : key : cert/dev-cert-test # type/name of the public key in the Azure KV # the key is returned PEM encoded - secretKey : dev-key-test remoteRef : key : key/dev-key-test The operator will fetch the Azure Key vault secret and inject it as a Kind=Secret . Then the Kubernetes secret can be fetched by issuing: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = '{.data.dev-secret-test}' | base64 -d To select all secrets inside the key vault or all tags inside a secret, you can use the dataFrom directive: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h # rate SecretManager pulls Azure Key Vault secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created creationPolicy : Owner dataFrom : - find : name : regexp : \"^example\" - find : tags : author : seb environment : dev # secret value is in JSON format and we unmarshall it into multiple key/values in k8s secret - extract : key : test # get all tags and the tags in JSON format will be unmarshall - extract : key : test metadataPolicy : Fetch To get a PKCS#12 certificate from Azure Key Vault and inject it as a Kind=Secret of type kubernetes.io/tls : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : mycert spec : refreshInterval : 24h secretStoreRef : kind : ClusterSecretStore name : kv-mycert target : template : type : kubernetes.io/tls engineVersion : v2 data : tls.crt : \"{{ .mycert | b64dec | pkcs12cert }}\" tls.key : \"{{ .mycert | b64dec | pkcs12key }}\" data : - secretKey : mycert remoteRef : # Azure Key Vault certificates must be fetched as secret/cert-name key : secret/mycert","title":"Key Vault"},{"location":"provider/azure-key-vault/#azure-key-vault","text":"External Secrets Operator integrates with Azure Key vault for secrets, certificates and Keys management.","title":"Azure Key vault"},{"location":"provider/azure-key-vault/#authentication","text":"We support Service Principals, Managed Identity and Workload Identity authentication. To use Managed Identity authentication, you should use aad-pod-identity to assign the identity to external-secrets operator. To add the selector to external-secrets operator, use podLabels in your values.yaml in case of Helm installation of external-secrets. We support connecting to different cloud flavours azure supports: PublicCloud , USGovernmentCloud , ChinaCloud and GermanCloud . You have to specify the environmentType and point to the correct cloud flavour. This defaults to PublicCloud . apiVersion: external-secrets.io/v1beta1 kind: SecretStore metadata: name: azure-backend spec: provider: azurekv: # PublicCloud, USGovernmentCloud, ChinaCloud, GermanCloud environmentType: PublicCloud # default Minimum required permissions are Get over secret and certificate permissions. This can be done by adding a Key Vault access policy: KUBELET_IDENTITY_OBJECT_ID = $( az aks show --resource-group <AKS_CLUSTER_RG_NAME> --name <AKS_CLUSTER_NAME> --query 'identityProfile.kubeletidentity.objectId' -o tsv ) az keyvault set-policy --name kv-name-with-certs --object-id \" $KUBELET_IDENTITY_OBJECT_ID \" --certificate-permissions get --secret-permissions get","title":"Authentication"},{"location":"provider/azure-key-vault/#service-principal-key-authentication","text":"A service Principal client and Secret is created and the JSON keyfile is stored in a Kind=Secret . The ClientID and ClientSecret should be configured for the secret. This service principal should have proper access rights to the keyvault to be managed by the operator","title":"Service Principal key authentication"},{"location":"provider/azure-key-vault/#managed-identity-authentication","text":"A Managed Identity should be created in Azure, and that Identity should have proper rights to the keyvault to be managed by the operator. If there are multiple Managed Identitites for different keyvaults, the operator should have been assigned all identities via aad-pod-identity , then the SecretStore configuration should include the Id of the idenetity to be used via the identityId field. apiVersion : v1 kind : Secret metadata : name : azure-secret-sp type : Opaque data : ClientID : bXktc2VydmljZS1wcmluY2lwbGUtY2xpZW50LWlkCg== #service-principal-ID ClientSecret : bXktc2VydmljZS1wcmluY2lwbGUtY2xpZW50LXNlY3JldAo= #service-principal-secret","title":"Managed Identity authentication"},{"location":"provider/azure-key-vault/#workload-identity","text":"You can use Azure AD Workload Identity Federation to access Azure managed services like Key Vault without needing to manage secrets . You need to configure a trust relationship between your Kubernetes Cluster and Azure AD. This can be done in various ways, for instance using terraform , the Azure Portal or the az cli. We found the azwi cli very helpful. The Azure Workload Identity Quick Start Guide is also good place to get started. This is basically a two step process: Create a Kubernetes Service Account ( guide ) azwi serviceaccount create phase sa \\ --aad-application-name \" ${ APPLICATION_NAME } \" \\ --service-account-namespace \" ${ SERVICE_ACCOUNT_NAMESPACE } \" \\ --service-account-name \" ${ SERVICE_ACCOUNT_NAME } \" 2. Configure the trust relationship between Azure AD and Kubernetes ( guide ) azwi serviceaccount create phase federated-identity \\ --aad-application-name \" ${ APPLICATION_NAME } \" \\ --service-account-namespace \" ${ SERVICE_ACCOUNT_NAMESPACE } \" \\ --service-account-name \" ${ SERVICE_ACCOUNT_NAME } \" \\ --service-account-issuer-url \" ${ SERVICE_ACCOUNT_ISSUER } \" With these prerequisites met you can configure ESO to use that Service Account. You have two options:","title":"Workload Identity"},{"location":"provider/azure-key-vault/#mounted-service-account","text":"You run the controller and mount that particular service account into the pod. That grants everyone who is able to create a secret store or reference a correctly configured one the ability to read secrets. This approach is usually not recommended . But may make sense when you want to share an identity with multiple namespaces. Also see our Multi-Tenancy Guide for design considerations. apiVersion : v1 kind : ServiceAccount metadata : # this service account was created by azwi name : workload-identity-sa annotations : azure.workload.identity/client-id : 7d8cdf74-xxxx-xxxx-xxxx-274d963d358b azure.workload.identity/tenant-id : 5a02a20e-xxxx-xxxx-xxxx-0ad5b634c5d8 --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : azurekv : authType : WorkloadIdentity vaultUrl : \"https://xx-xxxx-xx.vault.azure.net\" # note: no serviceAccountRef was provided","title":"Mounted Service Account"},{"location":"provider/azure-key-vault/#referenced-service-account","text":"You run the controller without service account (effectively without azure permissions). Now you have to configure the SecretStore and set the serviceAccountRef and point to the service account you have just created. This is usually the recommended approach . It makes sense for everyone who wants to run the controller withour Azure permissions and delegate authentication via service accounts in particular namespaces. Also see our [Multi-Tenancy Guide] for design considerations. apiVersion : v1 kind : ServiceAccount metadata : # this service account was created by azwi name : workload-identity-sa annotations : azure.workload.identity/client-id : 7d8cdf74-xxxx-xxxx-xxxx-274d963d358b azure.workload.identity/tenant-id : 5a02a20e-xxxx-xxxx-xxxx-0ad5b634c5d8 --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : azurekv : authType : WorkloadIdentity vaultUrl : \"https://xx-xxxx-xx.vault.azure.net\" serviceAccountRef : name : workload-identity-sa","title":"Referenced Service Account"},{"location":"provider/azure-key-vault/#update-secret-store","text":"Be sure the azurekv provider is listed in the Kind=SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : # provider type: azure keyvault azurekv : # azure tenant ID, see: https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-how-to-find-tenant tenantId : \"d3bc2180-xxxx-xxxx-xxxx-154105743342\" # URL of your vault instance, see: https://docs.microsoft.com/en-us/azure/key-vault/general/about-keys-secrets-certificates vaultUrl : \"https://my-keyvault-name.vault.azure.net\" authSecretRef : # points to the secret that contains # the azure service principal credentials clientId : name : azure-secret-sp key : ClientID clientSecret : name : azure-secret-sp key : ClientSecret NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in clientId and clientSecret with the namespaces where the secrets reside. Or in case of Managed Idenetity authentication: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-secret-store spec : provider : # provider type: azure keyvault azurekv : authType : ManagedIdentity # Optionally set the Id of the Managed Identity, if multiple identities are assigned to external-secrets operator identityId : \"<MI_clientId>\" # URL of your vault instance, see: https://docs.microsoft.com/en-us/azure/key-vault/general/about-keys-secrets-certificates vaultUrl : \"https://my-keyvault-name.vault.azure.net\"","title":"Update secret store"},{"location":"provider/azure-key-vault/#object-types","text":"Azure KeyVault manages different object types , we support keys , secrets and certificates . Simply prefix the key with key , secret or cert to retrieve the desired type (defaults to secret). Object Type Return Value secret the raw secret value. key A JWK which contains the public key. Azure KeyVault does not export the private key. You may want to use template functions to transform this JWK into PEM encoded PKIX ASN.1 DER format. certificate The raw CER contents of the x509 certificate. You may want to use template functions to transform this into your desired encoding","title":"Object Types"},{"location":"provider/azure-key-vault/#creating-external-secret","text":"To create a kubernetes secret from the Azure Key vault secret a Kind=ExternalSecret is needed. You can manage keys/secrets/certificates saved inside the keyvault , by setting a \"/\" prefixed type in the secret name, the default type is a secret . Other supported values are cert and key . apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example-external-secret spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : example-secret-store target : name : secret-to-be-created creationPolicy : Owner data : # name of the SECRET in the Azure KV (no prefix is by default a SECRET) - secretKey : dev-secret-test remoteRef : key : dev-secret-test # explicit type and name of secret in the Azure KV - secretKey : dev-another-secret-test remoteRef : key : secret/dev-secret-test # metadataPolicy to fetch all the tags in JSON format - secretKey : dev-secret-test remoteRef : key : dev-secret-test metadataPolicy : Fetch # metadataPolicy to fetch a specific tag which name must be in property - secretKey : dev-secret-test remoteRef : key : dev-secret-test metadataPolicy : Fetch property : tagname # type/name of certificate in the Azure KV # raw value will be returned, use templating features for data processing - secretKey : dev-cert-test remoteRef : key : cert/dev-cert-test # type/name of the public key in the Azure KV # the key is returned PEM encoded - secretKey : dev-key-test remoteRef : key : key/dev-key-test The operator will fetch the Azure Key vault secret and inject it as a Kind=Secret . Then the Kubernetes secret can be fetched by issuing: kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath = '{.data.dev-secret-test}' | base64 -d To select all secrets inside the key vault or all tags inside a secret, you can use the dataFrom directive: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h # rate SecretManager pulls Azure Key Vault secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created creationPolicy : Owner dataFrom : - find : name : regexp : \"^example\" - find : tags : author : seb environment : dev # secret value is in JSON format and we unmarshall it into multiple key/values in k8s secret - extract : key : test # get all tags and the tags in JSON format will be unmarshall - extract : key : test metadataPolicy : Fetch To get a PKCS#12 certificate from Azure Key Vault and inject it as a Kind=Secret of type kubernetes.io/tls : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : mycert spec : refreshInterval : 24h secretStoreRef : kind : ClusterSecretStore name : kv-mycert target : template : type : kubernetes.io/tls engineVersion : v2 data : tls.crt : \"{{ .mycert | b64dec | pkcs12cert }}\" tls.key : \"{{ .mycert | b64dec | pkcs12key }}\" data : - secretKey : mycert remoteRef : # Azure Key Vault certificates must be fetched as secret/cert-name key : secret/mycert","title":"Creating external secret"},{"location":"provider/fake/","text":"We provide a fake implementation to help with testing. This provider returns static key/value pairs and nothing else. To use the fake provider simply create a SecretStore or ClusterSecretStore and configure it like in the following example: Note The provider returns static data configured in value or valueMap . You can define a version , too. If set the remoteRef from an ExternalSecret must match otherwise no value is returned. apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : fake spec : provider : fake : data : - key : \"/foo/bar\" value : \"HELLO1\" version : \"v1\" - key : \"/foo/bar\" value : \"HELLO2\" version : \"v2\" - key : \"/foo/baz\" valueMap : foo : example other : thing Please note that value is intended for exclusive use with data and valueMap for dataFrom . Here is an example ExternalSecret that displays this behavior: Warning This provider supports specifying different data[].version configurations. However, data[].property is ignored. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : name : fake kind : ClusterSecretStore target : name : secret-to-be-created data : - secretKey : foo_bar remoteRef : key : /foo/bar version : v1 dataFrom : - extract : key : /foo/baz This results in the following secret: apiVersion : v1 kind : Secret metadata : name : secret-to-be-created namespace : default data : foo_bar : SEVMTE8x # HELLO1 (via data) foo : ZXhhbXBsZQ== # example (via dataFrom) other : dGhpbmc= # thing (via dataFrom)","title":"Fake"},{"location":"provider/gitlab-project-variables/","text":"Gitlab Project Variables External Secrets Operator integrates with Gitlab API to sync Gitlab project variables to secrets held on the Kubernetes cluster. Authentication The API requires an access token and project ID. To create a new access token, go to your user settings and select 'access tokens'. Give your token a name, expiration date, and select the permissions required (Note 'api' is required). Click 'Create personal access token', and your token will be generated and displayed on screen. Copy or save this token since you can't access it again. Access Token secret Create a secret containing your access token: apiVersion : v1 kind : Secret metadata : name : gitlab-secret labels : type : gitlab type : Opaque stringData : token : \"**access token goes here**\" Update secret store Be sure the gitlab provider is listed in the Kind=SecretStore and the ProjectID is set. If you are not using https://gitlab.com , you must set the url field as well. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : gitlab-secret-store spec : provider : # provider type: gitlab gitlab : # url: https://gitlab.mydomain.com/ auth : SecretRef : accessToken : name : gitlab-secret key : token projectID : \"**project ID goes here**\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessToken with the namespace where the secret resides. Your project ID can be found on your project's page. Creating external secret To sync a Gitlab variable to a secret on the Kubernetes cluster, a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : gitlab-external-secret-example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : gitlab-secret-store # Must match SecretStore on the cluster target : name : gitlab-secret-to-create # Name for the secret to be created on the cluster creationPolicy : Owner data : - secretKey : secretKey # Key given to the secret to be created on the cluster remoteRef : key : myGitlabVariable # Key of the variable on Gitlab Using DataFrom DataFrom can be used to get a variable as a JSON string and attempt to parse it. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : gitlab-external-secret-example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : gitlab-secret-store # Must match SecretStore on the cluster target : name : gitlab-secret-to-create # Name for the secret to be created on the cluster creationPolicy : Owner # each secret name in the KV will be used as the secret key in the SECRET k8s target object dataFrom : - extract : key : \"myJsonVariable\" # Key of the variable on Gitlab Getting the Kubernetes secret The operator will fetch the project variable and inject it as a Kind=Secret . kubectl get secret gitlab-secret-to-create -o jsonpath='{.data.secretKey}' | base64 -d","title":"Gitlab Project Variables"},{"location":"provider/gitlab-project-variables/#gitlab-project-variables","text":"External Secrets Operator integrates with Gitlab API to sync Gitlab project variables to secrets held on the Kubernetes cluster.","title":"Gitlab Project Variables"},{"location":"provider/gitlab-project-variables/#authentication","text":"The API requires an access token and project ID. To create a new access token, go to your user settings and select 'access tokens'. Give your token a name, expiration date, and select the permissions required (Note 'api' is required). Click 'Create personal access token', and your token will be generated and displayed on screen. Copy or save this token since you can't access it again.","title":"Authentication"},{"location":"provider/gitlab-project-variables/#access-token-secret","text":"Create a secret containing your access token: apiVersion : v1 kind : Secret metadata : name : gitlab-secret labels : type : gitlab type : Opaque stringData : token : \"**access token goes here**\"","title":"Access Token secret"},{"location":"provider/gitlab-project-variables/#update-secret-store","text":"Be sure the gitlab provider is listed in the Kind=SecretStore and the ProjectID is set. If you are not using https://gitlab.com , you must set the url field as well. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : gitlab-secret-store spec : provider : # provider type: gitlab gitlab : # url: https://gitlab.mydomain.com/ auth : SecretRef : accessToken : name : gitlab-secret key : token projectID : \"**project ID goes here**\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessToken with the namespace where the secret resides. Your project ID can be found on your project's page.","title":"Update secret store"},{"location":"provider/gitlab-project-variables/#creating-external-secret","text":"To sync a Gitlab variable to a secret on the Kubernetes cluster, a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : gitlab-external-secret-example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : gitlab-secret-store # Must match SecretStore on the cluster target : name : gitlab-secret-to-create # Name for the secret to be created on the cluster creationPolicy : Owner data : - secretKey : secretKey # Key given to the secret to be created on the cluster remoteRef : key : myGitlabVariable # Key of the variable on Gitlab","title":"Creating external secret"},{"location":"provider/gitlab-project-variables/#using-datafrom","text":"DataFrom can be used to get a variable as a JSON string and attempt to parse it. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : gitlab-external-secret-example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : gitlab-secret-store # Must match SecretStore on the cluster target : name : gitlab-secret-to-create # Name for the secret to be created on the cluster creationPolicy : Owner # each secret name in the KV will be used as the secret key in the SECRET k8s target object dataFrom : - extract : key : \"myJsonVariable\" # Key of the variable on Gitlab","title":"Using DataFrom"},{"location":"provider/gitlab-project-variables/#getting-the-kubernetes-secret","text":"The operator will fetch the project variable and inject it as a Kind=Secret . kubectl get secret gitlab-secret-to-create -o jsonpath='{.data.secretKey}' | base64 -d","title":"Getting the Kubernetes secret"},{"location":"provider/google-secrets-manager/","text":"Google Cloud Secret Manager External Secrets Operator integrates with GCP Secret Manager for secret management. Authentication Workload Identity Your Google Kubernetes Engine (GKE) applications can consume GCP services like Secrets Manager without using static, long-lived authentication tokens. This is our recommended approach of handling credentials in GCP. ESO offers two options for integrating with GKE workload identity: pod-based workload identity and using service accounts directly . Before using either way you need to create a service account - this is covered below. Creating Workload Identity Service Accounts You can find the documentation for Workload Identity here . We will walk you through how to navigate it here. Search the document for this editable values and change them to your values: Note: If you have installed ESO, a serviceaccount has already been created. You can either patch the existing external-secrets SA or create a new one that fits your needs. CLUSTER_NAME : The name of your cluster PROJECT_ID : Your project ID (not your Project number nor your Project name) K8S_NAMESPACE : For us following these steps here it will be es , but this will be the namespace where you deployed the external-secrets operator KSA_NAME : external-secrets (if you are not creating a new one to attach to the deployment) GSA_NAME : external-secrets for simplicity, or something else if you have to follow different naming convetions for cloud resources ROLE_NAME : should be roles/secretmanager.secretAccessor - so you make the pod only be able to access secrets on Secret Manager Using Service Accounts directly Let's assume you have created a service account correctly and attached a appropriate workload identity. It should roughly look like this: apiVersion : v1 kind : ServiceAccount metadata : name : external-secrets namespace : es annotations : iam.gke.io/gcp-service-account : example-team-a@my-project.iam.gserviceaccount.com You can reference this particular ServiceAccount in a SecretStore or ClusterSecretStore . It's important that you also set the projectID , clusterLocation and clusterName . The Namespace on the serviceAccountRef is ignored when using a SecretStore resource. This is needed to isolate the namespaces properly. apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : example spec : provider : gcpsm : projectID : my-project auth : workloadIdentity : # name of the cluster region clusterLocation : europe-central2 # name of the GKE cluster clusterName : example-workload-identity # projectID of the cluster (if omitted defaults to spec.provider.gcpsm.projectID) clusterProjectID : my-cluster-project # reference the sa from above serviceAccountRef : name : team-a namespace : team-a You need to give the Google service account the roles/iam.serviceAccountTokenCreator role so it can generate a service account token for you (not necessary in the Pod-based Workload Identity bellow) Using Pod-based Workload Identity You can attach a Workload Identity directly to the ESO pod. ESO then has access to all the APIs defined in the attached service account policy. You attach the workload identity by (1) creating a service account with a attached workload identity (described above) and (2) using this particular service account in the pod's serviceAccountName field. For this example we will assume that you installed ESO using helm and that you named the chart installation external-secrets and the namespace where it lives es like: helm install external-secrets external-secrets/external-secrets --namespace es Then most of the resources would have this name, the important one here being the k8s service account attached to the external-secrets operator deployment: # ... containers : - image : ghcr.io/external-secrets/external-secrets:vVERSION name : external-secrets ports : - containerPort : 8080 protocol : TCP restartPolicy : Always schedulerName : default-scheduler serviceAccount : external-secrets serviceAccountName : external-secrets # <--- here The pod now has the identity. Now you need to configure the SecretStore . You just need to set the projectID , all other fields can be omitted. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : gcpsm : projectID : pid GCP Service Account authentication You can use GCP Service Account to authenticate with GCP. These are static, long-lived credentials. A GCP Service Account is a JSON file that needs to be stored in a Kind=Secret . ESO will use that Secret to authenticate with GCP. See here how you manage GCP Service Accounts . apiVersion : v1 kind : Secret metadata : name : gcpsm-secret labels : type : gcpsm type : Opaque stringData : secret-access-credentials : |- { \"type\": \"service_account\", \"project_id\": \"external-secrets-operator\", \"private_key_id\": \"\", \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nA key\\n-----END PRIVATE KEY-----\\n\", \"client_email\": \"test-service-account@external-secrets-operator.iam.gserviceaccount.com\", \"client_id\": \"client ID\", \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\", \"token_uri\": \"https://oauth2.googleapis.com/token\", \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\", \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/test-service-account%40external-secrets-operator.iam.gserviceaccount.com\" } Update secret store Be sure the gcpsm provider is listed in the Kind=SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : gcpsm : # gcpsm provider auth : secretRef : secretAccessKeySecretRef : name : gcpsm-secret # secret name containing SA key key : secret-access-credentials # key name containing SA key projectID : myproject # name of Google Cloud project NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for SecretAccessKeyRef with the namespace of the secret that we just created. Creating external secret To create a kubernetes secret from the GCP Secret Manager secret a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h # rate SecretManager pulls GCPSM secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created creationPolicy : Owner data : - secretKey : dev-secret-test # name of the GCPSM secret key remoteRef : key : dev-secret-test The operator will fetch the GCP Secret Manager secret and inject it as a Kind=Secret kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath='{.data.dev-secret-test}' | base64 -d","title":"Secret Manager"},{"location":"provider/google-secrets-manager/#google-cloud-secret-manager","text":"External Secrets Operator integrates with GCP Secret Manager for secret management.","title":"Google Cloud Secret Manager"},{"location":"provider/google-secrets-manager/#authentication","text":"","title":"Authentication"},{"location":"provider/google-secrets-manager/#workload-identity","text":"Your Google Kubernetes Engine (GKE) applications can consume GCP services like Secrets Manager without using static, long-lived authentication tokens. This is our recommended approach of handling credentials in GCP. ESO offers two options for integrating with GKE workload identity: pod-based workload identity and using service accounts directly . Before using either way you need to create a service account - this is covered below.","title":"Workload Identity"},{"location":"provider/google-secrets-manager/#creating-workload-identity-service-accounts","text":"You can find the documentation for Workload Identity here . We will walk you through how to navigate it here. Search the document for this editable values and change them to your values: Note: If you have installed ESO, a serviceaccount has already been created. You can either patch the existing external-secrets SA or create a new one that fits your needs. CLUSTER_NAME : The name of your cluster PROJECT_ID : Your project ID (not your Project number nor your Project name) K8S_NAMESPACE : For us following these steps here it will be es , but this will be the namespace where you deployed the external-secrets operator KSA_NAME : external-secrets (if you are not creating a new one to attach to the deployment) GSA_NAME : external-secrets for simplicity, or something else if you have to follow different naming convetions for cloud resources ROLE_NAME : should be roles/secretmanager.secretAccessor - so you make the pod only be able to access secrets on Secret Manager","title":"Creating Workload Identity Service Accounts"},{"location":"provider/google-secrets-manager/#using-service-accounts-directly","text":"Let's assume you have created a service account correctly and attached a appropriate workload identity. It should roughly look like this: apiVersion : v1 kind : ServiceAccount metadata : name : external-secrets namespace : es annotations : iam.gke.io/gcp-service-account : example-team-a@my-project.iam.gserviceaccount.com You can reference this particular ServiceAccount in a SecretStore or ClusterSecretStore . It's important that you also set the projectID , clusterLocation and clusterName . The Namespace on the serviceAccountRef is ignored when using a SecretStore resource. This is needed to isolate the namespaces properly. apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : example spec : provider : gcpsm : projectID : my-project auth : workloadIdentity : # name of the cluster region clusterLocation : europe-central2 # name of the GKE cluster clusterName : example-workload-identity # projectID of the cluster (if omitted defaults to spec.provider.gcpsm.projectID) clusterProjectID : my-cluster-project # reference the sa from above serviceAccountRef : name : team-a namespace : team-a You need to give the Google service account the roles/iam.serviceAccountTokenCreator role so it can generate a service account token for you (not necessary in the Pod-based Workload Identity bellow)","title":"Using Service Accounts directly"},{"location":"provider/google-secrets-manager/#using-pod-based-workload-identity","text":"You can attach a Workload Identity directly to the ESO pod. ESO then has access to all the APIs defined in the attached service account policy. You attach the workload identity by (1) creating a service account with a attached workload identity (described above) and (2) using this particular service account in the pod's serviceAccountName field. For this example we will assume that you installed ESO using helm and that you named the chart installation external-secrets and the namespace where it lives es like: helm install external-secrets external-secrets/external-secrets --namespace es Then most of the resources would have this name, the important one here being the k8s service account attached to the external-secrets operator deployment: # ... containers : - image : ghcr.io/external-secrets/external-secrets:vVERSION name : external-secrets ports : - containerPort : 8080 protocol : TCP restartPolicy : Always schedulerName : default-scheduler serviceAccount : external-secrets serviceAccountName : external-secrets # <--- here The pod now has the identity. Now you need to configure the SecretStore . You just need to set the projectID , all other fields can be omitted. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : gcpsm : projectID : pid","title":"Using Pod-based Workload Identity"},{"location":"provider/google-secrets-manager/#gcp-service-account-authentication","text":"You can use GCP Service Account to authenticate with GCP. These are static, long-lived credentials. A GCP Service Account is a JSON file that needs to be stored in a Kind=Secret . ESO will use that Secret to authenticate with GCP. See here how you manage GCP Service Accounts . apiVersion : v1 kind : Secret metadata : name : gcpsm-secret labels : type : gcpsm type : Opaque stringData : secret-access-credentials : |- { \"type\": \"service_account\", \"project_id\": \"external-secrets-operator\", \"private_key_id\": \"\", \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nA key\\n-----END PRIVATE KEY-----\\n\", \"client_email\": \"test-service-account@external-secrets-operator.iam.gserviceaccount.com\", \"client_id\": \"client ID\", \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\", \"token_uri\": \"https://oauth2.googleapis.com/token\", \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\", \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/test-service-account%40external-secrets-operator.iam.gserviceaccount.com\" }","title":"GCP Service Account authentication"},{"location":"provider/google-secrets-manager/#update-secret-store","text":"Be sure the gcpsm provider is listed in the Kind=SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : gcpsm : # gcpsm provider auth : secretRef : secretAccessKeySecretRef : name : gcpsm-secret # secret name containing SA key key : secret-access-credentials # key name containing SA key projectID : myproject # name of Google Cloud project NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for SecretAccessKeyRef with the namespace of the secret that we just created.","title":"Update secret store"},{"location":"provider/google-secrets-manager/#creating-external-secret","text":"To create a kubernetes secret from the GCP Secret Manager secret a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h # rate SecretManager pulls GCPSM secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created creationPolicy : Owner data : - secretKey : dev-secret-test # name of the GCPSM secret key remoteRef : key : dev-secret-test The operator will fetch the GCP Secret Manager secret and inject it as a Kind=Secret kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath='{.data.dev-secret-test}' | base64 -d","title":"Creating external secret"},{"location":"provider/hashicorp-vault/","text":"Hashicorp Vault External Secrets Operator integrates with HashiCorp Vault for secret management. Vault itself implements lots of different secret engines, as of now we only support the KV Secrets Engine . Example First, create a SecretStore with a vault backend. For the sake of simplicity we'll use a static token root : apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend spec : provider : vault : server : \"http://my.vault.server:8200\" path : \"secret\" version : \"v2\" auth : # points to a secret that contains a vault token # https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"vault-token\" key : \"token\" --- apiVersion : v1 kind : Secret metadata : name : vault-token data : token : cm9vdA== # \"root\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for tokenSecretRef with the namespace of the secret that we just created. Then create a simple k/v pair at path secret/foo : vault kv put secret/foo my-value=s3cr3t Now create a ExternalSecret that uses the above SecretStore: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : refreshInterval : \"15s\" secretStoreRef : name : vault-backend kind : SecretStore target : name : example-sync data : - secretKey : foobar remoteRef : key : secret/foo property : my-value --- # will create a secret with: kind : Secret metadata : name : example-sync data : foobar : czNjcjN0 Fetching Raw Values You can fetch all key/value pairs for a given path If you leave the remoteRef.property empty. This returns the json-encoded secret value for that path. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... data : - secretKey : foobar remoteRef : key : /dev/package.json Nested Values Vault supports nested key/value pairs. You can specify a gjson expression at remoteRef.property to get a nested value. Given the following secret - assume its path is /dev/config : { \"foo\" : { \"nested\" : { \"bar\" : \"mysecret\" } } } You can set the remoteRef.property to point to the nested key using a gjson expression. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... data : - secretKey : foobar remoteRef : key : /dev/config property : foo.nested.bar --- # creates a secret with: # foobar=mysecret If you would set the remoteRef.property to just foo then you would get the json-encoded value of that property: {\"nested\":{\"bar\":\"mysecret\"}} . Multiple nested Values You can extract multiple keys from a nested secret using dataFrom . Given the following secret - assume its path is /dev/config : { \"foo\" : { \"nested\" : { \"bar\" : \"mysecret\" , \"baz\" : \"bang\" } } } You can set the remoteRef.property to point to the nested key using a gjson expression. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... dataFrom : - extract : key : /dev/config property : foo.nested That results in a secret with these values: bar=mysecret baz=bang Getting multiple secrets You can extract multiple secrets from Hashicorp vault by using dataFrom.Find Currently, dataFrom.Find allows users to fetch secret names that match a given regexp pattern, or fetch secrets whose custom_metadata tags match a predefined set. Warning The way hashicorp Vault currently allows LIST operations is through the existence of a secret metadata. If you delete the secret, you will also need to delete the secret's metadata or this will currently make Find operations fail. Given the following secret - assume its path is /dev/config : { \"foo\" : { \"nested\" : { \"bar\" : \"mysecret\" , \"baz\" : \"bang\" } } } Also consider the following secret has the following custom_metadata : { \"environment\" : \"dev\" , \"component\" : \"app-1\" } It is possible to find this secret by all the following possibilities: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... dataFrom : - find : #will return every secret with 'dev' in it (including paths) name : regexp : dev - find : #will return every secret matching environment:dev tags from dev/ folder and beyond tags : environment : dev will generate a secret with: { \"dev_config\" : \"{\\\"foo\\\":{\\\"nested\\\":{\\\"bar\\\":\\\"mysecret\\\",\\\"baz\\\":\\\"bang\\\"}}}\" } Currently, Find operations are recursive throughout a given vault folder, starting on provider.Path definition. It is recommended to narrow down the scope of search by setting a find.path variable. This is also useful to automatically reduce the resulting secret key names: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... dataFrom : - find : #will return every secret from dev/ folder path : dev name : regexp : \".*\" - find : #will return every secret matching environment:dev tags from dev/ folder path : dev tags : environment : dev Will generate a secret with: { \"config\" : \"{\\\"foo\\\": {\\\"nested\\\": {\\\"bar\\\": \\\"mysecret\\\",\\\"baz\\\": \\\"bang\\\"}}}\" } Authentication We support five different modes for authentication: token-based , appRole , kubernetes-native , ldap and jwt/odic , each one comes with it's own trade-offs. Depending on the authentication method you need to adapt your environment. Token-based authentication A static token is stored in a Kind=Secret and is used to authenticate with vault. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # points to a secret that contains a vault token # https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"my-secret\" key : \"vault-token\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in tokenSecretRef with the namespace where the secret resides. AppRole authentication example AppRole authentication reads the secret id from a Kind=Secret and uses the specified roleId to aquire a temporary token to fetch secrets. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # VaultAppRole authenticates with Vault using the # App Role auth mechanism # https://www.vaultproject.io/docs/auth/approle appRole : # Path where the App Role authentication backend is mounted path : \"approle\" # RoleID configured in the App Role authentication backend roleId : \"db02de05-fa39-4855-059b-67221c5c2f63\" # Reference to a key in a K8 Secret that contains the App Role SecretId secretRef : name : \"my-secret\" key : \"secret-id\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretRef with the namespace where the secret resides. Kubernetes authentication Kubernetes-native authentication has three options of optaining credentials for vault: by using a service account jwt referenced in serviceAccountRef by using the jwt from a Kind=Secret referenced by the secretRef by using transient credentials from the mounted service account token within the external-secrets operator apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # Authenticate against Vault using a Kubernetes ServiceAccount # token stored in a Secret. # https://www.vaultproject.io/docs/auth/kubernetes kubernetes : # Path where the Kubernetes authentication backend is mounted in Vault mountPath : \"kubernetes\" # A required field containing the Vault Role to assume. role : \"demo\" # Optional service account field containing the name # of a kubernetes ServiceAccount serviceAccountRef : name : \"my-sa\" # Optional secret field containing a Kubernetes ServiceAccount JWT # used for authenticating with Vault secretRef : name : \"my-secret\" key : \"vault\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in serviceAccountRef or in secretRef , if used. LDAP authentication LDAP authentication uses username/password pair to get an access token. Username is stored directly in a Kind=SecretStore or Kind=ClusterSecretStore resource, password is stored in a Kind=Secret referenced by the secretRef . apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # VaultLdap authenticates with Vault using the LDAP auth mechanism # https://www.vaultproject.io/docs/auth/ldap ldap : # Path where the LDAP authentication backend is mounted path : \"ldap\" # LDAP username username : \"username\" secretRef : name : \"my-secret\" key : \"ldap-password\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretRef with the namespace where the secret resides. JWT/OIDC authentication JWT/OIDC uses either a JWT token stored in a Kind=Secret and referenced by the secretRef or a temporary Kubernetes service account token retrieved via the TokenRequest API. Optionally a role field can be defined in a Kind=SecretStore or Kind=ClusterSecretStore resource. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # VaultJwt authenticates with Vault using the JWT/OIDC auth mechanism # https://www.vaultproject.io/docs/auth/jwt jwt : # Path where the JWT authentication backend is mounted path : \"jwt\" # JWT role configured in a Vault server, optional. role : \"vault-jwt-role\" # Retrieve JWT token from a Kubernetes secret secretRef : name : \"my-secret\" key : \"jwt-token\" # ... or retrieve a Kubernetes service account token via the `TokenRequest` API kubernetesServiceAccountToken : serviceAccountRef : name : \"my-sa\" # `audiences` defaults to `[\"vault\"]` it not supplied audiences : - vault # `expirationSeconds` defaults to 10 minutes if not supplied expirationSeconds : 600 NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretRef with the namespace where the secret resides. Vault Enterprise Eventual Consistency and Performance Standby Nodes When using Vault Enterprise with performance standby nodes , any follower can handle read requests immediately after the provider has authenticated. Since Vault becomes eventually consistent in this mode, these requests can fail if the login has not yet propagated to each server's local state. Below are two different solutions to this scenario. You'll need to review them and pick the best fit for your environment and Vault configuration. Vault Namespaces Vault namespaces are an enterprise feature that support multi-tenancy. You can specify a vault namespace using the namespace property when you define a SecretStore: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend spec : provider : vault : server : \"http://my.vault.server:8200\" # See https://www.vaultproject.io/docs/enterprise/namespaces namespace : \"ns1\" path : \"secret\" version : \"v2\" auth : # ... Read Your Writes Vault 1.10.0 and later encodes information in the token to detect the case when a server is behind. If a Vault server does not have information about the provided token, Vault returns a 412 error so clients know to retry. A method supported in versions Vault 1.7 and later is to utilize the X-Vault-Index header returned on all write requests (including logins). Passing this header back on subsequent requests instructs the Vault client to retry the request until the server has an index greater than or equal to that returned with the last write. Obviously though, this has a performance hit because the read is blocked until the follower's local state has caught up. Forward Inconsistent Vault also supports proxying inconsistent requests to the current cluster leader for immediate read-after-write consistency. Vault 1.10.0 and later support a replication configuration that detects when forwarding should occur and does it transparently to the client. In Vault 1.7 forwarding can be achieved by setting the X-Vault-Inconsistent header to forward-active-node . By default, this behavior is disabled and must be explicitly enabled in the server's replication configuration .","title":"HashiCorp Vault"},{"location":"provider/hashicorp-vault/#hashicorp-vault","text":"External Secrets Operator integrates with HashiCorp Vault for secret management. Vault itself implements lots of different secret engines, as of now we only support the KV Secrets Engine .","title":"Hashicorp Vault"},{"location":"provider/hashicorp-vault/#example","text":"First, create a SecretStore with a vault backend. For the sake of simplicity we'll use a static token root : apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend spec : provider : vault : server : \"http://my.vault.server:8200\" path : \"secret\" version : \"v2\" auth : # points to a secret that contains a vault token # https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"vault-token\" key : \"token\" --- apiVersion : v1 kind : Secret metadata : name : vault-token data : token : cm9vdA== # \"root\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for tokenSecretRef with the namespace of the secret that we just created. Then create a simple k/v pair at path secret/foo : vault kv put secret/foo my-value=s3cr3t Now create a ExternalSecret that uses the above SecretStore: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : refreshInterval : \"15s\" secretStoreRef : name : vault-backend kind : SecretStore target : name : example-sync data : - secretKey : foobar remoteRef : key : secret/foo property : my-value --- # will create a secret with: kind : Secret metadata : name : example-sync data : foobar : czNjcjN0","title":"Example"},{"location":"provider/hashicorp-vault/#fetching-raw-values","text":"You can fetch all key/value pairs for a given path If you leave the remoteRef.property empty. This returns the json-encoded secret value for that path. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... data : - secretKey : foobar remoteRef : key : /dev/package.json","title":"Fetching Raw Values"},{"location":"provider/hashicorp-vault/#nested-values","text":"Vault supports nested key/value pairs. You can specify a gjson expression at remoteRef.property to get a nested value. Given the following secret - assume its path is /dev/config : { \"foo\" : { \"nested\" : { \"bar\" : \"mysecret\" } } } You can set the remoteRef.property to point to the nested key using a gjson expression. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... data : - secretKey : foobar remoteRef : key : /dev/config property : foo.nested.bar --- # creates a secret with: # foobar=mysecret If you would set the remoteRef.property to just foo then you would get the json-encoded value of that property: {\"nested\":{\"bar\":\"mysecret\"}} .","title":"Nested Values"},{"location":"provider/hashicorp-vault/#multiple-nested-values","text":"You can extract multiple keys from a nested secret using dataFrom . Given the following secret - assume its path is /dev/config : { \"foo\" : { \"nested\" : { \"bar\" : \"mysecret\" , \"baz\" : \"bang\" } } } You can set the remoteRef.property to point to the nested key using a gjson expression. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... dataFrom : - extract : key : /dev/config property : foo.nested That results in a secret with these values: bar=mysecret baz=bang","title":"Multiple nested Values"},{"location":"provider/hashicorp-vault/#getting-multiple-secrets","text":"You can extract multiple secrets from Hashicorp vault by using dataFrom.Find Currently, dataFrom.Find allows users to fetch secret names that match a given regexp pattern, or fetch secrets whose custom_metadata tags match a predefined set. Warning The way hashicorp Vault currently allows LIST operations is through the existence of a secret metadata. If you delete the secret, you will also need to delete the secret's metadata or this will currently make Find operations fail. Given the following secret - assume its path is /dev/config : { \"foo\" : { \"nested\" : { \"bar\" : \"mysecret\" , \"baz\" : \"bang\" } } } Also consider the following secret has the following custom_metadata : { \"environment\" : \"dev\" , \"component\" : \"app-1\" } It is possible to find this secret by all the following possibilities: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... dataFrom : - find : #will return every secret with 'dev' in it (including paths) name : regexp : dev - find : #will return every secret matching environment:dev tags from dev/ folder and beyond tags : environment : dev will generate a secret with: { \"dev_config\" : \"{\\\"foo\\\":{\\\"nested\\\":{\\\"bar\\\":\\\"mysecret\\\",\\\"baz\\\":\\\"bang\\\"}}}\" } Currently, Find operations are recursive throughout a given vault folder, starting on provider.Path definition. It is recommended to narrow down the scope of search by setting a find.path variable. This is also useful to automatically reduce the resulting secret key names: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : vault-example spec : # ... dataFrom : - find : #will return every secret from dev/ folder path : dev name : regexp : \".*\" - find : #will return every secret matching environment:dev tags from dev/ folder path : dev tags : environment : dev Will generate a secret with: { \"config\" : \"{\\\"foo\\\": {\\\"nested\\\": {\\\"bar\\\": \\\"mysecret\\\",\\\"baz\\\": \\\"bang\\\"}}}\" }","title":"Getting multiple secrets"},{"location":"provider/hashicorp-vault/#authentication","text":"We support five different modes for authentication: token-based , appRole , kubernetes-native , ldap and jwt/odic , each one comes with it's own trade-offs. Depending on the authentication method you need to adapt your environment.","title":"Authentication"},{"location":"provider/hashicorp-vault/#token-based-authentication","text":"A static token is stored in a Kind=Secret and is used to authenticate with vault. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # points to a secret that contains a vault token # https://www.vaultproject.io/docs/auth/token tokenSecretRef : name : \"my-secret\" key : \"vault-token\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in tokenSecretRef with the namespace where the secret resides.","title":"Token-based authentication"},{"location":"provider/hashicorp-vault/#approle-authentication-example","text":"AppRole authentication reads the secret id from a Kind=Secret and uses the specified roleId to aquire a temporary token to fetch secrets. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # VaultAppRole authenticates with Vault using the # App Role auth mechanism # https://www.vaultproject.io/docs/auth/approle appRole : # Path where the App Role authentication backend is mounted path : \"approle\" # RoleID configured in the App Role authentication backend roleId : \"db02de05-fa39-4855-059b-67221c5c2f63\" # Reference to a key in a K8 Secret that contains the App Role SecretId secretRef : name : \"my-secret\" key : \"secret-id\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretRef with the namespace where the secret resides.","title":"AppRole authentication example"},{"location":"provider/hashicorp-vault/#kubernetes-authentication","text":"Kubernetes-native authentication has three options of optaining credentials for vault: by using a service account jwt referenced in serviceAccountRef by using the jwt from a Kind=Secret referenced by the secretRef by using transient credentials from the mounted service account token within the external-secrets operator apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # Authenticate against Vault using a Kubernetes ServiceAccount # token stored in a Secret. # https://www.vaultproject.io/docs/auth/kubernetes kubernetes : # Path where the Kubernetes authentication backend is mounted in Vault mountPath : \"kubernetes\" # A required field containing the Vault Role to assume. role : \"demo\" # Optional service account field containing the name # of a kubernetes ServiceAccount serviceAccountRef : name : \"my-sa\" # Optional secret field containing a Kubernetes ServiceAccount JWT # used for authenticating with Vault secretRef : name : \"my-secret\" key : \"vault\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in serviceAccountRef or in secretRef , if used.","title":"Kubernetes authentication"},{"location":"provider/hashicorp-vault/#ldap-authentication","text":"LDAP authentication uses username/password pair to get an access token. Username is stored directly in a Kind=SecretStore or Kind=ClusterSecretStore resource, password is stored in a Kind=Secret referenced by the secretRef . apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # VaultLdap authenticates with Vault using the LDAP auth mechanism # https://www.vaultproject.io/docs/auth/ldap ldap : # Path where the LDAP authentication backend is mounted path : \"ldap\" # LDAP username username : \"username\" secretRef : name : \"my-secret\" key : \"ldap-password\" NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretRef with the namespace where the secret resides.","title":"LDAP authentication"},{"location":"provider/hashicorp-vault/#jwtoidc-authentication","text":"JWT/OIDC uses either a JWT token stored in a Kind=Secret and referenced by the secretRef or a temporary Kubernetes service account token retrieved via the TokenRequest API. Optionally a role field can be defined in a Kind=SecretStore or Kind=ClusterSecretStore resource. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend namespace : example spec : provider : vault : server : \"https://vault.acme.org\" path : \"secret\" version : \"v2\" auth : # VaultJwt authenticates with Vault using the JWT/OIDC auth mechanism # https://www.vaultproject.io/docs/auth/jwt jwt : # Path where the JWT authentication backend is mounted path : \"jwt\" # JWT role configured in a Vault server, optional. role : \"vault-jwt-role\" # Retrieve JWT token from a Kubernetes secret secretRef : name : \"my-secret\" key : \"jwt-token\" # ... or retrieve a Kubernetes service account token via the `TokenRequest` API kubernetesServiceAccountToken : serviceAccountRef : name : \"my-sa\" # `audiences` defaults to `[\"vault\"]` it not supplied audiences : - vault # `expirationSeconds` defaults to 10 minutes if not supplied expirationSeconds : 600 NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretRef with the namespace where the secret resides.","title":"JWT/OIDC authentication"},{"location":"provider/hashicorp-vault/#vault-enterprise","text":"","title":"Vault Enterprise"},{"location":"provider/hashicorp-vault/#eventual-consistency-and-performance-standby-nodes","text":"When using Vault Enterprise with performance standby nodes , any follower can handle read requests immediately after the provider has authenticated. Since Vault becomes eventually consistent in this mode, these requests can fail if the login has not yet propagated to each server's local state. Below are two different solutions to this scenario. You'll need to review them and pick the best fit for your environment and Vault configuration.","title":"Eventual Consistency and Performance Standby Nodes"},{"location":"provider/hashicorp-vault/#vault-namespaces","text":"Vault namespaces are an enterprise feature that support multi-tenancy. You can specify a vault namespace using the namespace property when you define a SecretStore: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : vault-backend spec : provider : vault : server : \"http://my.vault.server:8200\" # See https://www.vaultproject.io/docs/enterprise/namespaces namespace : \"ns1\" path : \"secret\" version : \"v2\" auth : # ...","title":"Vault Namespaces"},{"location":"provider/hashicorp-vault/#read-your-writes","text":"Vault 1.10.0 and later encodes information in the token to detect the case when a server is behind. If a Vault server does not have information about the provided token, Vault returns a 412 error so clients know to retry. A method supported in versions Vault 1.7 and later is to utilize the X-Vault-Index header returned on all write requests (including logins). Passing this header back on subsequent requests instructs the Vault client to retry the request until the server has an index greater than or equal to that returned with the last write. Obviously though, this has a performance hit because the read is blocked until the follower's local state has caught up.","title":"Read Your Writes"},{"location":"provider/hashicorp-vault/#forward-inconsistent","text":"Vault also supports proxying inconsistent requests to the current cluster leader for immediate read-after-write consistency. Vault 1.10.0 and later support a replication configuration that detects when forwarding should occur and does it transparently to the client. In Vault 1.7 forwarding can be achieved by setting the X-Vault-Inconsistent header to forward-active-node . By default, this behavior is disabled and must be explicitly enabled in the server's replication configuration .","title":"Forward Inconsistent"},{"location":"provider/ibm-secrets-manager/","text":"IBM Cloud Secret Manager External Secrets Operator integrates with IBM Secret Manager for secret management. Authentication We support API key and trusted profile container authentication for this provider. API key secret To generate your key (for test purposes we are going to generate from your user), first got to your (Access IAM) page: On the left, click \"IBM Cloud API Keys\": Press \"Create an IBM Cloud API Key\": Pick a name and description for your key: You have created a key. Press the eyeball to show the key. Copy or save it because keys can't be displayed or downloaded twice. Create a secret containing your apiKey: kubectl create secret generic ibm-secret --from-literal = apiKey = 'API_KEY_VALUE' Trusted Profile Container Auth To create the trusted profile, first got to your (Access IAM) page: On the left, click \"Access groups\": Pick a name and description for your group: Click on \"Access Policies\": Click on \"Assign Access\", select \"IAM services\", and pick \"Secrets Manager\" from the pick-list: Scope to \"All resources\" or \"Resources based on selected attributes\", select \"SecretsReader\": Click \"Add\" and \"Assign\" to save the access group. Next, on the left, click \"Trusted profiles\": Press \"Create\": Pick a name and description for your profile: Scope the profile's access. The compute service type will be \"Red Hat OpenShift on IBM Cloud\". Additional restriction can be configured based on cloud or cluster metadata, or if \"Specific resources\" is selected, restriction to a specific cluster. Click \"Add\" next to the previously created access group and then \"Create\", to associate the necessary service permissions. To use the container-based authentication, it is necessary to map the API server serviceAccountToken auth token to the \"external-secrets\" and \"external-secrets-webhook\" deployment descriptors. Example below: ... spec : ... template : ... spec : containers : ... volumeMounts : - mountPath : /var/run/secrets/tokens name : sa-token ... volumes : - name : sa-token projected : defaultMode : 420 sources : - serviceAccountToken : audience : iam expirationSeconds : 3600 path : sa-token ... Update secret store Be sure the ibm provider is listed in the Kind=SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : ibm : serviceUrl : \"https://SECRETS_MANAGER_ID.REGION.secrets-manager.appdomain.cloud\" auth : containerAuth : profile : \"test container auth profile\" tokenLocation : \"/var/run/secrets/tokens/sa-token\" iamEndpoint : \"https://iam.cloud.ibm.com\" secretRef : secretApiKeySecretRef : name : ibm-secret key : apiKey NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretApiKeySecretRef with the namespace where the secret resides. NOTE: Only secretApiKeySecretRef or containerAuth should be specified, depending on authentication me thod being used. To find your serviceURL, under your Secrets Manager resource, go to \"Endpoints\" on the left. Note: Use the url without the /api suffix that is presented in the UI. See here for a list of publicly available endpoints . Secret Types We support the following secret types of IBM Secrets Manager : arbitrary username_password iam_credentials imported_cert public_cert private_cert kv To define the type of secret you would like to sync you need to prefix the secret id with the desired type. If the secret type is not specified it is defaulted to arbitrary : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : ibm-sample spec : # [...] data : - secretKey : test remoteRef : # defaults to type=arbitrary key : xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx - secretKey : usr_pass remoteRef : key : username_password/yyyyyyy-yyyy-yyyy-yyyy-yyyyyyyyyyyy property : username - secretKey : iam_cred remoteRef : key : iam_credentials/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz - secretKey : imp_cert remoteRef : key : imported_cert/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : certificate - secretKey : pub_cert remoteRef : key : public_cert/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : certificate - secretKey : prvt_cert remoteRef : key : private_cert/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : certificate - secretKey : kv_without_key remoteRef : key : kv/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz - secretKey : kv_key remoteRef : key : kv/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : 'keyid' - secretKey : kv_key_with_path remoteRef : key : kv/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : 'key.path' dataFrom : The behavior for the different secret types is as following: arbitrary remoteRef retrieves a string from secrets manager and sets it for specified secretKey dataFrom retrieves a string from secrets manager and tries to parse it as JSON object setting the key:values pairs in resulting Kubernetes secret if successful username_password remoteRef requires a property to be set for either username or password to retrieve respective fields from the secrets manager secret and set in specified secretKey dataFrom retrieves both username and password fields from the secrets manager secret and sets appropriate key:value pairs in the resulting Kubernetes secret iam_credentials remoteRef retrieves an apikey from secrets manager and sets it for specified secretKey dataFrom retrieves an apikey from secrets manager and sets it for the apikey Kubernetes secret key imported_cert, public_cert and private_cert remoteRef requires a property to be set for either certificate , private_key or intermediate to retrieve respective fields from the secrets manager secret and set in specified secretKey dataFrom retrieves all certificate , private_key and intermediate fields from the secrets manager secret and sets appropriate key:value pairs in the resulting Kubernetes secret kv An optional property field can be set to remoteRef to select requested key from the KV secret. If not set, the entire secret will be returned dataFrom retrieves a string from secrets manager and tries to parse it as JSON object setting the key:values pairs in resulting Kubernetes secret if successful { \"key1\" : \"val1\" , \"key2\" : \"val2\" , \"key3\" : { \"keyA\" : \"valA\" , \"keyB\" : \"valB\" }, \"special.key\" : \"special-content\" } data : - secretKey : key3_keyB remoteRef : key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' property : 'key3.keyB' - secretKey : special_key remoteRef : key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' property : 'special.key' - secretKey : key_all remoteRef : key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' dataFrom : - key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' property : 'key3' results in data : # secrets from data key3_keyB : ... #valB special_key : ... #special-content key_all : ... #{\"key1\":\"val1\",\"key2\":\"val2\", ...\"special.key\":\"special-content\"} # secrets from dataFrom keyA : ... #valA keyB : ... #valB Creating external secret To create a kubernetes secret from the IBM Secrets Manager, a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : external-secret-sample spec : refreshInterval : 60m secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : test remoteRef : key : xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx Currently we can only get the secret by its id and not its name, so something like 565287ce-578f-8d96-a746-9409d531fe2a . Getting the Kubernetes secret The operator will fetch the IBM Secret Manager secret and inject it as a Kind=Secret kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath='{.data.test}' | base64 -d","title":"Secrets Manager"},{"location":"provider/ibm-secrets-manager/#ibm-cloud-secret-manager","text":"External Secrets Operator integrates with IBM Secret Manager for secret management.","title":"IBM Cloud Secret Manager"},{"location":"provider/ibm-secrets-manager/#authentication","text":"We support API key and trusted profile container authentication for this provider.","title":"Authentication"},{"location":"provider/ibm-secrets-manager/#api-key-secret","text":"To generate your key (for test purposes we are going to generate from your user), first got to your (Access IAM) page: On the left, click \"IBM Cloud API Keys\": Press \"Create an IBM Cloud API Key\": Pick a name and description for your key: You have created a key. Press the eyeball to show the key. Copy or save it because keys can't be displayed or downloaded twice. Create a secret containing your apiKey: kubectl create secret generic ibm-secret --from-literal = apiKey = 'API_KEY_VALUE'","title":"API key secret"},{"location":"provider/ibm-secrets-manager/#trusted-profile-container-auth","text":"To create the trusted profile, first got to your (Access IAM) page: On the left, click \"Access groups\": Pick a name and description for your group: Click on \"Access Policies\": Click on \"Assign Access\", select \"IAM services\", and pick \"Secrets Manager\" from the pick-list: Scope to \"All resources\" or \"Resources based on selected attributes\", select \"SecretsReader\": Click \"Add\" and \"Assign\" to save the access group. Next, on the left, click \"Trusted profiles\": Press \"Create\": Pick a name and description for your profile: Scope the profile's access. The compute service type will be \"Red Hat OpenShift on IBM Cloud\". Additional restriction can be configured based on cloud or cluster metadata, or if \"Specific resources\" is selected, restriction to a specific cluster. Click \"Add\" next to the previously created access group and then \"Create\", to associate the necessary service permissions. To use the container-based authentication, it is necessary to map the API server serviceAccountToken auth token to the \"external-secrets\" and \"external-secrets-webhook\" deployment descriptors. Example below: ... spec : ... template : ... spec : containers : ... volumeMounts : - mountPath : /var/run/secrets/tokens name : sa-token ... volumes : - name : sa-token projected : defaultMode : 420 sources : - serviceAccountToken : audience : iam expirationSeconds : 3600 path : sa-token ...","title":"Trusted Profile Container Auth"},{"location":"provider/ibm-secrets-manager/#update-secret-store","text":"Be sure the ibm provider is listed in the Kind=SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : ibm : serviceUrl : \"https://SECRETS_MANAGER_ID.REGION.secrets-manager.appdomain.cloud\" auth : containerAuth : profile : \"test container auth profile\" tokenLocation : \"/var/run/secrets/tokens/sa-token\" iamEndpoint : \"https://iam.cloud.ibm.com\" secretRef : secretApiKeySecretRef : name : ibm-secret key : apiKey NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in secretApiKeySecretRef with the namespace where the secret resides. NOTE: Only secretApiKeySecretRef or containerAuth should be specified, depending on authentication me thod being used. To find your serviceURL, under your Secrets Manager resource, go to \"Endpoints\" on the left. Note: Use the url without the /api suffix that is presented in the UI. See here for a list of publicly available endpoints .","title":"Update secret store"},{"location":"provider/ibm-secrets-manager/#secret-types","text":"We support the following secret types of IBM Secrets Manager : arbitrary username_password iam_credentials imported_cert public_cert private_cert kv To define the type of secret you would like to sync you need to prefix the secret id with the desired type. If the secret type is not specified it is defaulted to arbitrary : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : ibm-sample spec : # [...] data : - secretKey : test remoteRef : # defaults to type=arbitrary key : xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx - secretKey : usr_pass remoteRef : key : username_password/yyyyyyy-yyyy-yyyy-yyyy-yyyyyyyyyyyy property : username - secretKey : iam_cred remoteRef : key : iam_credentials/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz - secretKey : imp_cert remoteRef : key : imported_cert/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : certificate - secretKey : pub_cert remoteRef : key : public_cert/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : certificate - secretKey : prvt_cert remoteRef : key : private_cert/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : certificate - secretKey : kv_without_key remoteRef : key : kv/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz - secretKey : kv_key remoteRef : key : kv/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : 'keyid' - secretKey : kv_key_with_path remoteRef : key : kv/zzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz property : 'key.path' dataFrom : The behavior for the different secret types is as following:","title":"Secret Types"},{"location":"provider/ibm-secrets-manager/#arbitrary","text":"remoteRef retrieves a string from secrets manager and sets it for specified secretKey dataFrom retrieves a string from secrets manager and tries to parse it as JSON object setting the key:values pairs in resulting Kubernetes secret if successful","title":"arbitrary"},{"location":"provider/ibm-secrets-manager/#username_password","text":"remoteRef requires a property to be set for either username or password to retrieve respective fields from the secrets manager secret and set in specified secretKey dataFrom retrieves both username and password fields from the secrets manager secret and sets appropriate key:value pairs in the resulting Kubernetes secret","title":"username_password"},{"location":"provider/ibm-secrets-manager/#iam_credentials","text":"remoteRef retrieves an apikey from secrets manager and sets it for specified secretKey dataFrom retrieves an apikey from secrets manager and sets it for the apikey Kubernetes secret key","title":"iam_credentials"},{"location":"provider/ibm-secrets-manager/#imported_cert-public_cert-and-private_cert","text":"remoteRef requires a property to be set for either certificate , private_key or intermediate to retrieve respective fields from the secrets manager secret and set in specified secretKey dataFrom retrieves all certificate , private_key and intermediate fields from the secrets manager secret and sets appropriate key:value pairs in the resulting Kubernetes secret","title":"imported_cert, public_cert and private_cert"},{"location":"provider/ibm-secrets-manager/#kv","text":"An optional property field can be set to remoteRef to select requested key from the KV secret. If not set, the entire secret will be returned dataFrom retrieves a string from secrets manager and tries to parse it as JSON object setting the key:values pairs in resulting Kubernetes secret if successful { \"key1\" : \"val1\" , \"key2\" : \"val2\" , \"key3\" : { \"keyA\" : \"valA\" , \"keyB\" : \"valB\" }, \"special.key\" : \"special-content\" } data : - secretKey : key3_keyB remoteRef : key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' property : 'key3.keyB' - secretKey : special_key remoteRef : key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' property : 'special.key' - secretKey : key_all remoteRef : key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' dataFrom : - key : 'kv/aaaaa-bbbb-cccc-dddd-eeeeee' property : 'key3' results in data : # secrets from data key3_keyB : ... #valB special_key : ... #special-content key_all : ... #{\"key1\":\"val1\",\"key2\":\"val2\", ...\"special.key\":\"special-content\"} # secrets from dataFrom keyA : ... #valA keyB : ... #valB","title":"kv"},{"location":"provider/ibm-secrets-manager/#creating-external-secret","text":"To create a kubernetes secret from the IBM Secrets Manager, a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : external-secret-sample spec : refreshInterval : 60m secretStoreRef : name : secretstore-sample kind : SecretStore target : name : secret-to-be-created creationPolicy : Owner data : - secretKey : test remoteRef : key : xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx Currently we can only get the secret by its id and not its name, so something like 565287ce-578f-8d96-a746-9409d531fe2a .","title":"Creating external secret"},{"location":"provider/ibm-secrets-manager/#getting-the-kubernetes-secret","text":"The operator will fetch the IBM Secret Manager secret and inject it as a Kind=Secret kubectl get secret secret-to-be-created -n <namespace> | -o jsonpath='{.data.test}' | base64 -d","title":"Getting the Kubernetes secret"},{"location":"provider/kubernetes/","text":"External Secrets Operator allows to retrieve secrets from a Kubernetes Cluster - this can be either a remote cluster or the local where the operator runs in. A SecretStore points to a specific namespace in the target Kubernetes Cluster. You are able to retrieve all secrets from that particular namespace given you have the correct set of RBAC permissions. The SecretStore reconciler checks if you have read access for secrets in that namespace using SelfSubjectRulesReview . See below on how to set that up properly. External Secret Spec This provider supports the use of the Property field. With it you point to the key of the remote secret. If you leave it empty it will json encode all key/value pairs. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created data : - secretKey : extra remoteRef : key : secret-example property : extra find by tag & name You can fetch secrets based on labels or names matching a regexp: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : example target : name : secret-to-be-created dataFrom : - find : name : # match secret name with regexp regexp : \"key-.*\" - find : tags : # fetch secrets based on label combination app : \"nginx\" Target API-Server Configuration The servers url can be omitted and defaults to kubernetes.default . You have to provide a CA certificate in order to connect to the API Server securely. For your convenience, each namespace has a ConfigMap kube-root-ca.crt that contains the CA certificate of the internal API Server (see RootCAConfigMap feature gate ). Use that if you want to connect to the same API server. If you want to connect to a remote API Server you need to fetch it and store it inside the cluster as ConfigMap or Secret. You may also define it inline as base64 encoded value using the caBundle property. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : remoteNamespace : default server : url : \"https://myapiserver.tld\" caProvider : type : ConfigMap name : kube-root-ca.crt key : ca.crt Authentication It's possible to authenticate against the Kubernetes API using client certificates, a bearer token or service account. The operator enforces that exactly one authentication method is used. You can not use the service account that is mounted inside the operator, this is by design to avoid reading secrets across namespaces. NOTE: SelfSubjectRulesReview permission is required in order to validation work properly. Please use the following role as reference: apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : namespace : default name : eso-store-role rules : - apiGroups : [ \"\" ] resources : - secrets verbs : - get - list - watch - apiGroups : - authorization.k8s.io resources : - selfsubjectrulesreviews verbs : - create Authenticating with BearerToken Create a Kubernetes secret with a client token. There are many ways to acquire such a token, please refer to the Kubernetes Authentication docs . apiVersion : v1 kind : Secret metadata : name : mydefaulttoken data : token : \"....\" Create a SecretStore: The auth section indicates that the type token will be used for authentication, it includes the path to fetch the token. Set remoteNamespace to the name of the namespace where your target secrets reside. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : server : # ... auth : token : bearerToken : name : mydefaulttoken key : token remoteNamespace : default Authenticating with ServiceAccount Create a Kubernetes Service Account, please refer to the Service Account Tokens Documentation on how they work and how to create them. $ kubectl create serviceaccount my-store This Service Account needs permissions to read Secret and create SelfSubjectRulesReview resources. Please see the above role. $ kubectl create rolebinding my-store --role=eso-store-role --serviceaccount=default:my-store Create a SecretStore: the auth section indicates that the type serviceAccount will be used for authentication. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : server : # ... auth : serviceAccount : name : \"my-store\" remoteNamespace : default Authenticating with Client Certificates Create a Kubernetes secret which contains the client key and certificate. See Generate Certificates Documentations on how to create them. $ kubectl create secret tls tls-secret --cert=path/to/tls.cert --key=path/to/tls.key Reference the tls-secret in the SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : server : # ... auth : cert : clientCert : name : \"tls-secret\" key : \"tls.crt\" clientKey : name : \"tls-secret\" key : \"tls.key\" remoteNamespace : default","title":"Kubernetes"},{"location":"provider/kubernetes/#external-secret-spec","text":"This provider supports the use of the Property field. With it you point to the key of the remote secret. If you leave it empty it will json encode all key/value pairs. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : example # name of the SecretStore (or kind specified) target : name : secret-to-be-created # name of the k8s Secret to be created data : - secretKey : extra remoteRef : key : secret-example property : extra","title":"External Secret Spec"},{"location":"provider/kubernetes/#find-by-tag-name","text":"You can fetch secrets based on labels or names matching a regexp: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 1h secretStoreRef : kind : SecretStore name : example target : name : secret-to-be-created dataFrom : - find : name : # match secret name with regexp regexp : \"key-.*\" - find : tags : # fetch secrets based on label combination app : \"nginx\"","title":"find by tag &amp; name"},{"location":"provider/kubernetes/#target-api-server-configuration","text":"The servers url can be omitted and defaults to kubernetes.default . You have to provide a CA certificate in order to connect to the API Server securely. For your convenience, each namespace has a ConfigMap kube-root-ca.crt that contains the CA certificate of the internal API Server (see RootCAConfigMap feature gate ). Use that if you want to connect to the same API server. If you want to connect to a remote API Server you need to fetch it and store it inside the cluster as ConfigMap or Secret. You may also define it inline as base64 encoded value using the caBundle property. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : remoteNamespace : default server : url : \"https://myapiserver.tld\" caProvider : type : ConfigMap name : kube-root-ca.crt key : ca.crt","title":"Target API-Server Configuration"},{"location":"provider/kubernetes/#authentication","text":"It's possible to authenticate against the Kubernetes API using client certificates, a bearer token or service account. The operator enforces that exactly one authentication method is used. You can not use the service account that is mounted inside the operator, this is by design to avoid reading secrets across namespaces. NOTE: SelfSubjectRulesReview permission is required in order to validation work properly. Please use the following role as reference: apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : namespace : default name : eso-store-role rules : - apiGroups : [ \"\" ] resources : - secrets verbs : - get - list - watch - apiGroups : - authorization.k8s.io resources : - selfsubjectrulesreviews verbs : - create","title":"Authentication"},{"location":"provider/kubernetes/#authenticating-with-bearertoken","text":"Create a Kubernetes secret with a client token. There are many ways to acquire such a token, please refer to the Kubernetes Authentication docs . apiVersion : v1 kind : Secret metadata : name : mydefaulttoken data : token : \"....\" Create a SecretStore: The auth section indicates that the type token will be used for authentication, it includes the path to fetch the token. Set remoteNamespace to the name of the namespace where your target secrets reside. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : server : # ... auth : token : bearerToken : name : mydefaulttoken key : token remoteNamespace : default","title":"Authenticating with BearerToken"},{"location":"provider/kubernetes/#authenticating-with-serviceaccount","text":"Create a Kubernetes Service Account, please refer to the Service Account Tokens Documentation on how they work and how to create them. $ kubectl create serviceaccount my-store This Service Account needs permissions to read Secret and create SelfSubjectRulesReview resources. Please see the above role. $ kubectl create rolebinding my-store --role=eso-store-role --serviceaccount=default:my-store Create a SecretStore: the auth section indicates that the type serviceAccount will be used for authentication. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : server : # ... auth : serviceAccount : name : \"my-store\" remoteNamespace : default","title":"Authenticating with ServiceAccount"},{"location":"provider/kubernetes/#authenticating-with-client-certificates","text":"Create a Kubernetes secret which contains the client key and certificate. See Generate Certificates Documentations on how to create them. $ kubectl create secret tls tls-secret --cert=path/to/tls.cert --key=path/to/tls.key Reference the tls-secret in the SecretStore apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example spec : provider : kubernetes : server : # ... auth : cert : clientCert : name : \"tls-secret\" key : \"tls.crt\" clientKey : name : \"tls-secret\" key : \"tls.key\" remoteNamespace : default","title":"Authenticating with Client Certificates"},{"location":"provider/oracle-vault/","text":"Oracle Vault External Secrets Operator integrates with OCI API to sync secret on the Oracle Vault to secrets held on the Kubernetes cluster. Authentication If auth is not specified, the operator uses the instance principal. For using a specific user credentials, userOCID, tenancyOCID, fingerprint and private key are required. The fingerprint and key file should be supplied in the secret with the rest being provided in the secret store. See url for what region you you are accessing. Select tenancy in the top right to see your user OCID as shown below. Select your user in the top right to see your user OCID as shown below. Service account key authentication Create a secret containing your private key and fingerprint: apiVersion : v1 kind : Secret metadata : name : oracle-secret labels : type : oracle type : Opaque stringData : privateKey : fingerprint : Your fingerprint will be attatched to your API key, once it has been generated. Found on the same page as the user OCID. Once you click \"Add API Key\" you will be shown the following, where you can download the RSA key in the necessary PEM format for API requests. This will automatically generate a fingerprint. Update secret store Be sure the oracle provider is listed in the Kind=SecretStore . apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-instance-principal spec : provider : oracle : vault : # The vault OCID region : # The vault region --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-auth spec : provider : oracle : vault : # The vault OCID region : # The vault region auth : user : # A user OCID tenancy : # A user's tenancy secretRef : privatekey : name : oracle-secret key : privateKey fingerprint : name : oracle-secret key : fingerprint NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in privatekey and fingerprint with the namespaces where the secrets reside. Creating external secret To create a kubernetes secret from the Oracle Cloud Interface secret a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 0.03m secretStoreRef : kind : SecretStore name : example # Must match SecretStore on the cluster target : name : secret-to-be-created # Name for the secret on the cluster creationPolicy : Owner dataFrom : - extract : key : the-secret-name Getting the Kubernetes secret The operator will fetch the project variable and inject it as a Kind=Secret . kubectl get secret oracle-secret-to-create -o jsonpath='{.data.dev-secret-test}' | base64 -d","title":"Oracle Vault"},{"location":"provider/oracle-vault/#oracle-vault","text":"External Secrets Operator integrates with OCI API to sync secret on the Oracle Vault to secrets held on the Kubernetes cluster.","title":"Oracle Vault"},{"location":"provider/oracle-vault/#authentication","text":"If auth is not specified, the operator uses the instance principal. For using a specific user credentials, userOCID, tenancyOCID, fingerprint and private key are required. The fingerprint and key file should be supplied in the secret with the rest being provided in the secret store. See url for what region you you are accessing. Select tenancy in the top right to see your user OCID as shown below. Select your user in the top right to see your user OCID as shown below.","title":"Authentication"},{"location":"provider/oracle-vault/#service-account-key-authentication","text":"Create a secret containing your private key and fingerprint: apiVersion : v1 kind : Secret metadata : name : oracle-secret labels : type : oracle type : Opaque stringData : privateKey : fingerprint : Your fingerprint will be attatched to your API key, once it has been generated. Found on the same page as the user OCID. Once you click \"Add API Key\" you will be shown the following, where you can download the RSA key in the necessary PEM format for API requests. This will automatically generate a fingerprint.","title":"Service account key authentication"},{"location":"provider/oracle-vault/#update-secret-store","text":"Be sure the oracle provider is listed in the Kind=SecretStore . apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-instance-principal spec : provider : oracle : vault : # The vault OCID region : # The vault region --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : example-auth spec : provider : oracle : vault : # The vault OCID region : # The vault region auth : user : # A user OCID tenancy : # A user's tenancy secretRef : privatekey : name : oracle-secret key : privateKey fingerprint : name : oracle-secret key : fingerprint NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in privatekey and fingerprint with the namespaces where the secrets reside.","title":"Update secret store"},{"location":"provider/oracle-vault/#creating-external-secret","text":"To create a kubernetes secret from the Oracle Cloud Interface secret a Kind=ExternalSecret is needed. apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example spec : refreshInterval : 0.03m secretStoreRef : kind : SecretStore name : example # Must match SecretStore on the cluster target : name : secret-to-be-created # Name for the secret on the cluster creationPolicy : Owner dataFrom : - extract : key : the-secret-name","title":"Creating external secret"},{"location":"provider/oracle-vault/#getting-the-kubernetes-secret","text":"The operator will fetch the project variable and inject it as a Kind=Secret . kubectl get secret oracle-secret-to-create -o jsonpath='{.data.dev-secret-test}' | base64 -d","title":"Getting the Kubernetes secret"},{"location":"provider/senhasegura-dsm/","text":"senhasegura DevOps Secrets Management (DSM) External Secrets Operator integrates with senhasegura DevOps Secrets Management (DSM) module to sync application secrets to secrets held on the Kubernetes cluster. Authentication Authentication in senhasegura uses DevOps Secrets Management (DSM) application authorization schema You need to create an Kubernetes Secret with desired auth parameters, for example: Instructions to setup authorizations and secrets in senhasegura DSM can be found at senhasegura docs for DSM and senhasegura YouTube channel --- apiVersion : v1 kind : Secret metadata : name : senhasegura-dsm-auth stringData : CLIENT_SECRET : \"CHANGEME\" Examples To sync secrets between senhasegura and Kubernetes with External Secrets, we need to define an SecretStore or ClusterSecretStore resource with senhasegura provider, setting authentication in DSM module with Secret defined before SecretStore --- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : senhasegura spec : provider : senhasegura : url : \"https://senhasegura.changeme.com\" module : DSM # Select senhasegura DSM module to sync secrets auth : clientId : \"CHANGEME\" clientSecretSecretRef : name : senhasegura-dsm-auth key : CLIENT_SECRET ignoreSslCertificate : false # Optional ClusterSecretStore --- apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : senhasegura spec : provider : senhasegura : url : \"https://senhasegura.changeme.com\" module : DSM # Select senhasegura DSM module to sync secrets auth : clientId : \"CHANGEME\" clientSecretSecretRef : name : senhasegura-dsm-auth key : CLIENT_SECRET namespace : senhasegura # Namespace of Secret \"senhasegura-dsm-auth\" ignoreSslCertificate : false # Optional Syncing secrets In examples below, consider that three secrets (api-settings, db-settings and hsm-settings) are defined in senhasegura DSM Secret Identifier: api-settings Secret data: URL = https://example.com/api/example TOKEN = example-token-value Secret Identifier: db-settings Secret data: DB_HOST = 'db.example' DB_PORT = '5432' DB_USERNAME = 'example' DB_PASSWORD = 'example' Secret Identifier: hsm-settings Secret data: HSM_ADDRESS = 'hsm.example' HSM_PORT = '9223' Sync DSM secrets using Secret Identifiers You can fetch all key/value pairs for a given secret identifier If you leave the remoteRef.property empty. This returns the json-encoded secret value for that path. If you only need a specific key, you can select it using remoteRef.property as the key name. In this method, you can overwrites data name in Kubernetes Secret object (e.g API_SETTINGS and API_SETTINGS_TOKEN) --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example-secret spec : refreshInterval : \"30s\" secretStoreRef : name : senhasegura kind : SecretStore target : name : example-secret data : # Define API_SETTINGS Kubernetes Secret key, with json-encoded values from senhasegura secret with identifier \"api-settings\" - secretKey : API_SETTINGS remoteRef : key : api-settings # Secret Identifier in senhasegura # Define API_SETTINGS_TOKEN Kubernetes Secret key, with single secret key (TOKEN) from senhasegura as string - secretKey : API_SETTINGS_TOKEN remoteRef : key : api-settings # Secret Identifier in senhasegura property : TOKEN # Optional, Key name within secret Kubernetes Secret will be create with follow .data.X API_SETTINGS = '[{\"TOKEN\":\"example-token-value\",\"URL\":\"https://example.com/api/example\"}]' API_SETTINGS_TOKEN = 'example-token-value' Sync DSM secrets using Secret Identifiers with automatically name assignments If your app requires multiples secrets, it is not required to create multiple ExternalSecret resources, you can aggregate secrets using a single ExternalSecret resource In this method, every secret data in senhasegura creates an Kubernetes Secret .data.X field --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example-secret spec : refreshInterval : \"30s\" secretStoreRef : name : senhasegura kind : SecretStore target : name : example-secret dataFrom : # Define Kubernetes Secret key with any k/v pair in senhasegura Secret with identifier \"api-settings\" or \"db-settings\" - extract : key : api-settings - extract : key : db-settings Kubernetes Secret will be create with follow .data.X URL = 'https://example.com/api/example' TOKEN = 'example-token-value' DB_HOST = 'db.example' DB_PORT = '5432' DB_USERNAME = 'example' DB_PASSWORD = 'example'","title":"DevOps Secrets Management (DSM)"},{"location":"provider/senhasegura-dsm/#senhasegura-devops-secrets-management-dsm","text":"External Secrets Operator integrates with senhasegura DevOps Secrets Management (DSM) module to sync application secrets to secrets held on the Kubernetes cluster.","title":"senhasegura DevOps Secrets Management (DSM)"},{"location":"provider/senhasegura-dsm/#authentication","text":"Authentication in senhasegura uses DevOps Secrets Management (DSM) application authorization schema You need to create an Kubernetes Secret with desired auth parameters, for example: Instructions to setup authorizations and secrets in senhasegura DSM can be found at senhasegura docs for DSM and senhasegura YouTube channel --- apiVersion : v1 kind : Secret metadata : name : senhasegura-dsm-auth stringData : CLIENT_SECRET : \"CHANGEME\"","title":"Authentication"},{"location":"provider/senhasegura-dsm/#examples","text":"To sync secrets between senhasegura and Kubernetes with External Secrets, we need to define an SecretStore or ClusterSecretStore resource with senhasegura provider, setting authentication in DSM module with Secret defined before","title":"Examples"},{"location":"provider/senhasegura-dsm/#secretstore","text":"--- apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : senhasegura spec : provider : senhasegura : url : \"https://senhasegura.changeme.com\" module : DSM # Select senhasegura DSM module to sync secrets auth : clientId : \"CHANGEME\" clientSecretSecretRef : name : senhasegura-dsm-auth key : CLIENT_SECRET ignoreSslCertificate : false # Optional","title":"SecretStore"},{"location":"provider/senhasegura-dsm/#clustersecretstore","text":"--- apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : senhasegura spec : provider : senhasegura : url : \"https://senhasegura.changeme.com\" module : DSM # Select senhasegura DSM module to sync secrets auth : clientId : \"CHANGEME\" clientSecretSecretRef : name : senhasegura-dsm-auth key : CLIENT_SECRET namespace : senhasegura # Namespace of Secret \"senhasegura-dsm-auth\" ignoreSslCertificate : false # Optional","title":"ClusterSecretStore"},{"location":"provider/senhasegura-dsm/#syncing-secrets","text":"In examples below, consider that three secrets (api-settings, db-settings and hsm-settings) are defined in senhasegura DSM Secret Identifier: api-settings Secret data: URL = https://example.com/api/example TOKEN = example-token-value Secret Identifier: db-settings Secret data: DB_HOST = 'db.example' DB_PORT = '5432' DB_USERNAME = 'example' DB_PASSWORD = 'example' Secret Identifier: hsm-settings Secret data: HSM_ADDRESS = 'hsm.example' HSM_PORT = '9223'","title":"Syncing secrets"},{"location":"provider/senhasegura-dsm/#sync-dsm-secrets-using-secret-identifiers","text":"You can fetch all key/value pairs for a given secret identifier If you leave the remoteRef.property empty. This returns the json-encoded secret value for that path. If you only need a specific key, you can select it using remoteRef.property as the key name. In this method, you can overwrites data name in Kubernetes Secret object (e.g API_SETTINGS and API_SETTINGS_TOKEN) --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example-secret spec : refreshInterval : \"30s\" secretStoreRef : name : senhasegura kind : SecretStore target : name : example-secret data : # Define API_SETTINGS Kubernetes Secret key, with json-encoded values from senhasegura secret with identifier \"api-settings\" - secretKey : API_SETTINGS remoteRef : key : api-settings # Secret Identifier in senhasegura # Define API_SETTINGS_TOKEN Kubernetes Secret key, with single secret key (TOKEN) from senhasegura as string - secretKey : API_SETTINGS_TOKEN remoteRef : key : api-settings # Secret Identifier in senhasegura property : TOKEN # Optional, Key name within secret Kubernetes Secret will be create with follow .data.X API_SETTINGS = '[{\"TOKEN\":\"example-token-value\",\"URL\":\"https://example.com/api/example\"}]' API_SETTINGS_TOKEN = 'example-token-value'","title":"Sync DSM secrets using Secret Identifiers"},{"location":"provider/senhasegura-dsm/#sync-dsm-secrets-using-secret-identifiers-with-automatically-name-assignments","text":"If your app requires multiples secrets, it is not required to create multiple ExternalSecret resources, you can aggregate secrets using a single ExternalSecret resource In this method, every secret data in senhasegura creates an Kubernetes Secret .data.X field --- apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : example-secret spec : refreshInterval : \"30s\" secretStoreRef : name : senhasegura kind : SecretStore target : name : example-secret dataFrom : # Define Kubernetes Secret key with any k/v pair in senhasegura Secret with identifier \"api-settings\" or \"db-settings\" - extract : key : api-settings - extract : key : db-settings Kubernetes Secret will be create with follow .data.X URL = 'https://example.com/api/example' TOKEN = 'example-token-value' DB_HOST = 'db.example' DB_PORT = '5432' DB_USERNAME = 'example' DB_PASSWORD = 'example'","title":"Sync DSM secrets using Secret Identifiers with automatically name assignments"},{"location":"provider/webhook/","text":"Generic Webhook External Secrets Operator can integrate with simple web apis by specifying the endpoint Example First, create a SecretStore with a webhook backend. We'll use a static user/password root : apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : webhook-backend spec : provider : webhook : url : \"http://httpbin.org/get?parameter={{ .remoteRef.key }}\" result : jsonPath : \"$.args.parameter\" headers : Content-Type : application/json Authorization : Basic {{ print .auth.username \":\" .auth.password | b64enc }} secrets : - name : auth secretRef : name : webhook-credentials --- apiVersion : v1 kind : Secret metadata : name : webhook-credentials data : username : dGVzdA== # \"test\" password : dGVzdA== # \"test\" NB: This is obviously not practical because it just returns the key as the result, but it shows how it works NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in all secrets references with the namespaces where the secrets reside. Now create an ExternalSecret that uses the above SecretStore: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : webhook-example spec : refreshInterval : \"15s\" secretStoreRef : name : webhook-backend kind : SecretStore target : name : example-sync data : - secretKey : foobar remoteRef : key : secret --- # will create a secret with: kind : Secret metadata : name : example-sync data : foobar : c2VjcmV0 Limitations Webhook does not support authorization, other than what can be sent by generating http headers Templating Generic WebHook provider uses the templating engine to generate the API call. It can be used in the url, headers, body and result.jsonPath fields. The provider inserts the secret to be retrieved in the object named remoteRef . In addition, secrets can be added as named objects, for example to use in authorization headers. Each secret has a name property which determines the name of the object in the templating engine. All Parameters apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : statervault spec : provider : webhook : # Url to call. Use templating engine to fill in the request parameters url : <url> # http method, defaults to GET method : <method> # Timeout in duration (1s, 1m, etc) timeout : 1s result : # [jsonPath](https://jsonpath.com) syntax, which also can be templated jsonPath : <jsonPath> # Map of headers, can be templated headers : <Header-Name> : <header contents> # Body to sent as request, can be templated (optional) body : <body> # List of secrets to expose to the templating engine secrets : # Use this name to refer to this secret in templating, above - name : <name> secretRef : namespace : <namespace> # Only used in ClusterSecretStores name : <name> # Add CAs here for the TLS handshake caBundle : <base64 encoded cabundle> caProvider : type : Secret or COnfigMap name : <name of secret or configmap> namespace : <namespace> # Only used in ClusterSecretStores key : <key inside secret>","title":"Webhook"},{"location":"provider/webhook/#generic-webhook","text":"External Secrets Operator can integrate with simple web apis by specifying the endpoint","title":"Generic Webhook"},{"location":"provider/webhook/#example","text":"First, create a SecretStore with a webhook backend. We'll use a static user/password root : apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : webhook-backend spec : provider : webhook : url : \"http://httpbin.org/get?parameter={{ .remoteRef.key }}\" result : jsonPath : \"$.args.parameter\" headers : Content-Type : application/json Authorization : Basic {{ print .auth.username \":\" .auth.password | b64enc }} secrets : - name : auth secretRef : name : webhook-credentials --- apiVersion : v1 kind : Secret metadata : name : webhook-credentials data : username : dGVzdA== # \"test\" password : dGVzdA== # \"test\" NB: This is obviously not practical because it just returns the key as the result, but it shows how it works NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in all secrets references with the namespaces where the secrets reside. Now create an ExternalSecret that uses the above SecretStore: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : webhook-example spec : refreshInterval : \"15s\" secretStoreRef : name : webhook-backend kind : SecretStore target : name : example-sync data : - secretKey : foobar remoteRef : key : secret --- # will create a secret with: kind : Secret metadata : name : example-sync data : foobar : c2VjcmV0","title":"Example"},{"location":"provider/webhook/#limitations","text":"Webhook does not support authorization, other than what can be sent by generating http headers","title":"Limitations"},{"location":"provider/webhook/#templating","text":"Generic WebHook provider uses the templating engine to generate the API call. It can be used in the url, headers, body and result.jsonPath fields. The provider inserts the secret to be retrieved in the object named remoteRef . In addition, secrets can be added as named objects, for example to use in authorization headers. Each secret has a name property which determines the name of the object in the templating engine.","title":"Templating"},{"location":"provider/webhook/#all-parameters","text":"apiVersion : external-secrets.io/v1beta1 kind : ClusterSecretStore metadata : name : statervault spec : provider : webhook : # Url to call. Use templating engine to fill in the request parameters url : <url> # http method, defaults to GET method : <method> # Timeout in duration (1s, 1m, etc) timeout : 1s result : # [jsonPath](https://jsonpath.com) syntax, which also can be templated jsonPath : <jsonPath> # Map of headers, can be templated headers : <Header-Name> : <header contents> # Body to sent as request, can be templated (optional) body : <body> # List of secrets to expose to the templating engine secrets : # Use this name to refer to this secret in templating, above - name : <name> secretRef : namespace : <namespace> # Only used in ClusterSecretStores name : <name> # Add CAs here for the TLS handshake caBundle : <base64 encoded cabundle> caProvider : type : Secret or COnfigMap name : <name of secret or configmap> namespace : <namespace> # Only used in ClusterSecretStores key : <key inside secret>","title":"All Parameters"},{"location":"provider/yandex-certificate-manager/","text":"Yandex Certificate Manager External Secrets Operator integrates with Yandex Certificate Manager for secret management. Prerequisites External Secrets Operator installed Yandex.Cloud CLI installed Authentication At the moment, authorized key authentication is only supported: Create a service account in Yandex.Cloud: yc iam service-account create --name eso-service-account Create an authorized key for the service account and save it to authorized-key.json file: yc iam key create \\ --service-account-name eso-service-account \\ --output authorized-key.json Create a k8s secret containing the authorized key saved above: kubectl create secret generic yc-auth --from-file = authorized-key = authorized-key.json Create a SecretStore pointing to yc-auth k8s secret: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secret-store spec : provider : yandexcertificatemanager : auth : authorizedKeySecretRef : name : yc-auth key : authorized-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in all authorizedKeySecretRef with the namespace where the secret resides. Creating external secret To make External Secrets Operator sync a k8s secret with a Certificate Manager certificate: Create a Certificate Manager certificate (follow the instructions ), if not already created. Assign the certificate-manager.certificates.downloader role for accessing the certificate content to the service account used for authentication ( ***** is the certificate ID): yc cm certificate add-access-binding \\ --id ***** \\ --service-account-name eso-service-account \\ --role certificate-manager.certificates.downloader Run the following command to ensure that the correct access binding has been added: yc cm certificate list-access-bindings --id ***** Create an ExternalSecret pointing to secret-store and the certificate in Certificate Manager: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : external-secret spec : refreshInterval : 1h secretStoreRef : name : secret-store kind : SecretStore target : name : k8s-secret # the target k8s secret name template : type : kubernetes.io/tls data : - secretKey : tls.crt # the target k8s secret key remoteRef : key : ***** # the certificate ID property : chain - secretKey : tls.key # the target k8s secret key remoteRef : key : ***** # the certificate ID property : privateKey The following property values are possible: chain \u2013 to fetch PEM-encoded certificate chain privateKey \u2013 to fetch PEM-encoded private key chainAndPrivateKey or missing property \u2013 to fetch both chain and private key The operator will fetch the Yandex Certificate Manager certificate and inject it as a Kind=Secret kubectl get secret k8s-secret -ojson | jq '.\"data\".\"tls.crt\"' -r | base64 --decode kubectl get secret k8s-secret -ojson | jq '.\"data\".\"tls.key\"' -r | base64 --decode","title":"Certificate Manager"},{"location":"provider/yandex-certificate-manager/#yandex-certificate-manager","text":"External Secrets Operator integrates with Yandex Certificate Manager for secret management.","title":"Yandex Certificate Manager"},{"location":"provider/yandex-certificate-manager/#prerequisites","text":"External Secrets Operator installed Yandex.Cloud CLI installed","title":"Prerequisites"},{"location":"provider/yandex-certificate-manager/#authentication","text":"At the moment, authorized key authentication is only supported: Create a service account in Yandex.Cloud: yc iam service-account create --name eso-service-account Create an authorized key for the service account and save it to authorized-key.json file: yc iam key create \\ --service-account-name eso-service-account \\ --output authorized-key.json Create a k8s secret containing the authorized key saved above: kubectl create secret generic yc-auth --from-file = authorized-key = authorized-key.json Create a SecretStore pointing to yc-auth k8s secret: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secret-store spec : provider : yandexcertificatemanager : auth : authorizedKeySecretRef : name : yc-auth key : authorized-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in all authorizedKeySecretRef with the namespace where the secret resides.","title":"Authentication"},{"location":"provider/yandex-certificate-manager/#creating-external-secret","text":"To make External Secrets Operator sync a k8s secret with a Certificate Manager certificate: Create a Certificate Manager certificate (follow the instructions ), if not already created. Assign the certificate-manager.certificates.downloader role for accessing the certificate content to the service account used for authentication ( ***** is the certificate ID): yc cm certificate add-access-binding \\ --id ***** \\ --service-account-name eso-service-account \\ --role certificate-manager.certificates.downloader Run the following command to ensure that the correct access binding has been added: yc cm certificate list-access-bindings --id ***** Create an ExternalSecret pointing to secret-store and the certificate in Certificate Manager: apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : external-secret spec : refreshInterval : 1h secretStoreRef : name : secret-store kind : SecretStore target : name : k8s-secret # the target k8s secret name template : type : kubernetes.io/tls data : - secretKey : tls.crt # the target k8s secret key remoteRef : key : ***** # the certificate ID property : chain - secretKey : tls.key # the target k8s secret key remoteRef : key : ***** # the certificate ID property : privateKey The following property values are possible: chain \u2013 to fetch PEM-encoded certificate chain privateKey \u2013 to fetch PEM-encoded private key chainAndPrivateKey or missing property \u2013 to fetch both chain and private key The operator will fetch the Yandex Certificate Manager certificate and inject it as a Kind=Secret kubectl get secret k8s-secret -ojson | jq '.\"data\".\"tls.crt\"' -r | base64 --decode kubectl get secret k8s-secret -ojson | jq '.\"data\".\"tls.key\"' -r | base64 --decode","title":"Creating external secret"},{"location":"provider/yandex-lockbox/","text":"Yandex Lockbox External Secrets Operator integrates with Yandex Lockbox for secret management. Prerequisites External Secrets Operator installed Yandex.Cloud CLI installed Authentication At the moment, authorized key authentication is only supported: Create a service account in Yandex.Cloud: yc iam service-account create --name eso-service-account Create an authorized key for the service account and save it to authorized-key.json file: yc iam key create \\ --service-account-name eso-service-account \\ --output authorized-key.json Create a k8s secret containing the authorized key saved above: kubectl create secret generic yc-auth --from-file = authorized-key = authorized-key.json Create a SecretStore pointing to yc-auth k8s secret: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secret-store spec : provider : yandexlockbox : auth : authorizedKeySecretRef : name : yc-auth key : authorized-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in all authorizedKeySecretRef with the namespace where the secret resides. Creating external secret To make External Secrets Operator sync a k8s secret with a Lockbox secret: Create a Lockbox secret, if not already created: yc lockbox secret create \\ --name lockbox-secret \\ --payload '[{\"key\": \"password\",\"textValue\": \"p@$$w0rd\"}]' Assign the lockbox.payloadViewer role for accessing the lockbox-secret payload to the service account used for authentication: yc lockbox secret add-access-binding \\ --name lockbox-secret \\ --service-account-name eso-service-account \\ --role lockbox.payloadViewer Run the following command to ensure that the correct access binding has been added: yc lockbox secret list-access-bindings --name lockbox-secret Create an ExternalSecret pointing to secret-store and lockbox-secret : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : external-secret spec : refreshInterval : 1h secretStoreRef : name : secret-store kind : SecretStore target : name : k8s-secret # the target k8s secret name data : - secretKey : password # the target k8s secret key remoteRef : key : ***** # ID of lockbox-secret property : password # (optional) payload entry key of lockbox-secret The operator will fetch the Yandex Lockbox secret and inject it as a Kind=Secret kubectl get secret k8s-secret -n <namespace> | -o jsonpath='{.data.password}' | base64 -d","title":"Lockbox"},{"location":"provider/yandex-lockbox/#yandex-lockbox","text":"External Secrets Operator integrates with Yandex Lockbox for secret management.","title":"Yandex Lockbox"},{"location":"provider/yandex-lockbox/#prerequisites","text":"External Secrets Operator installed Yandex.Cloud CLI installed","title":"Prerequisites"},{"location":"provider/yandex-lockbox/#authentication","text":"At the moment, authorized key authentication is only supported: Create a service account in Yandex.Cloud: yc iam service-account create --name eso-service-account Create an authorized key for the service account and save it to authorized-key.json file: yc iam key create \\ --service-account-name eso-service-account \\ --output authorized-key.json Create a k8s secret containing the authorized key saved above: kubectl create secret generic yc-auth --from-file = authorized-key = authorized-key.json Create a SecretStore pointing to yc-auth k8s secret: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secret-store spec : provider : yandexlockbox : auth : authorizedKeySecretRef : name : yc-auth key : authorized-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in all authorizedKeySecretRef with the namespace where the secret resides.","title":"Authentication"},{"location":"provider/yandex-lockbox/#creating-external-secret","text":"To make External Secrets Operator sync a k8s secret with a Lockbox secret: Create a Lockbox secret, if not already created: yc lockbox secret create \\ --name lockbox-secret \\ --payload '[{\"key\": \"password\",\"textValue\": \"p@$$w0rd\"}]' Assign the lockbox.payloadViewer role for accessing the lockbox-secret payload to the service account used for authentication: yc lockbox secret add-access-binding \\ --name lockbox-secret \\ --service-account-name eso-service-account \\ --role lockbox.payloadViewer Run the following command to ensure that the correct access binding has been added: yc lockbox secret list-access-bindings --name lockbox-secret Create an ExternalSecret pointing to secret-store and lockbox-secret : apiVersion : external-secrets.io/v1beta1 kind : ExternalSecret metadata : name : external-secret spec : refreshInterval : 1h secretStoreRef : name : secret-store kind : SecretStore target : name : k8s-secret # the target k8s secret name data : - secretKey : password # the target k8s secret key remoteRef : key : ***** # ID of lockbox-secret property : password # (optional) payload entry key of lockbox-secret The operator will fetch the Yandex Lockbox secret and inject it as a Kind=Secret kubectl get secret k8s-secret -n <namespace> | -o jsonpath='{.data.password}' | base64 -d","title":"Creating external secret"},{"location":"snippets/provider-aws-access/","text":"AWS Authentication Controller's Pod Identity Note: If you are using Parameter Store replace service: SecretsManager with service: ParameterStore in all examples below. This is basicially a zero-configuration authentication method that inherits the credentials from the runtime environment using the aws sdk default credential chain . You can attach a role to the pod using IRSA , kiam or kube2iam . When no other authentication method is configured in the Kind=Secretstore this role is used to make all API calls against AWS Secrets Manager or SSM Parameter Store. Based on the Pod's identity you can do a sts:assumeRole before fetching the secrets to limit access to certain keys in your provider. This is optional. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: do a sts:assumeRole before fetching secrets role : team-b Access Key ID & Secret Access Key You can store Access Key ID & Secret Access Key in a Kind=Secret and reference it from a SecretStore. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: assume role before fetching secrets role : team-b auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef , secretAccessKeySecretRef with the namespaces where the secrets reside. EKS Service Account credentials This feature lets you use short-lived service account tokens to authenticate with AWS. You must have Service Account Volume Projection enabled - it is by default on EKS. See EKS guide on how to set up IAM roles for service accounts. The big advantage of this approach is that ESO runs without any credentials. apiVersion : v1 kind : ServiceAccount metadata : annotations : eks.amazonaws.com/role-arn : arn:aws:iam::123456789012:role/team-a name : my-serviceaccount namespace : default Reference the service account from above in the Secret Store: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : eu-central-1 auth : jwt : serviceAccountRef : name : my-serviceaccount NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for serviceAccountRef with the namespace where the service account resides. Custom Endpoints You can define custom AWS endpoints if you want to use regional, vpc or custom endpoints. See List of endpoints for Secrets Manager , Secure Systems Manager and Security Token Service . Use the following environment variables to point the controller to your custom endpoints. Note: All resources managed by this controller are affected. ENV VAR DESCRIPTION AWS_SECRETSMANAGER_ENDPOINT Endpoint for the Secrets Manager Service. The controller uses this endpoint to fetch secrets from AWS Secrets Manager. AWS_SSM_ENDPOINT Endpoint for the AWS Secure Systems Manager. The controller uses this endpoint to fetch secrets from SSM Parameter Store. AWS_STS_ENDPOINT Endpoint for the Security Token Service. The controller uses this endpoint when creating a session and when doing assumeRole or assumeRoleWithWebIdentity calls.","title":"Provider aws access"},{"location":"snippets/provider-aws-access/#aws-authentication","text":"","title":"AWS Authentication"},{"location":"snippets/provider-aws-access/#controllers-pod-identity","text":"Note: If you are using Parameter Store replace service: SecretsManager with service: ParameterStore in all examples below. This is basicially a zero-configuration authentication method that inherits the credentials from the runtime environment using the aws sdk default credential chain . You can attach a role to the pod using IRSA , kiam or kube2iam . When no other authentication method is configured in the Kind=Secretstore this role is used to make all API calls against AWS Secrets Manager or SSM Parameter Store. Based on the Pod's identity you can do a sts:assumeRole before fetching the secrets to limit access to certain keys in your provider. This is optional. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: do a sts:assumeRole before fetching secrets role : team-b","title":"Controller's Pod Identity"},{"location":"snippets/provider-aws-access/#access-key-id-secret-access-key","text":"You can store Access Key ID & Secret Access Key in a Kind=Secret and reference it from a SecretStore. apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : team-b-store spec : provider : aws : service : SecretsManager region : eu-central-1 # optional: assume role before fetching secrets role : team-b auth : secretRef : accessKeyIDSecretRef : name : awssm-secret key : access-key secretAccessKeySecretRef : name : awssm-secret key : secret-access-key NOTE: In case of a ClusterSecretStore , Be sure to provide namespace in accessKeyIDSecretRef , secretAccessKeySecretRef with the namespaces where the secrets reside.","title":"Access Key ID &amp; Secret Access Key"},{"location":"snippets/provider-aws-access/#eks-service-account-credentials","text":"This feature lets you use short-lived service account tokens to authenticate with AWS. You must have Service Account Volume Projection enabled - it is by default on EKS. See EKS guide on how to set up IAM roles for service accounts. The big advantage of this approach is that ESO runs without any credentials. apiVersion : v1 kind : ServiceAccount metadata : annotations : eks.amazonaws.com/role-arn : arn:aws:iam::123456789012:role/team-a name : my-serviceaccount namespace : default Reference the service account from above in the Secret Store: apiVersion : external-secrets.io/v1beta1 kind : SecretStore metadata : name : secretstore-sample spec : provider : aws : service : SecretsManager region : eu-central-1 auth : jwt : serviceAccountRef : name : my-serviceaccount NOTE: In case of a ClusterSecretStore , Be sure to provide namespace for serviceAccountRef with the namespace where the service account resides.","title":"EKS Service Account credentials"},{"location":"snippets/provider-aws-access/#custom-endpoints","text":"You can define custom AWS endpoints if you want to use regional, vpc or custom endpoints. See List of endpoints for Secrets Manager , Secure Systems Manager and Security Token Service . Use the following environment variables to point the controller to your custom endpoints. Note: All resources managed by this controller are affected. ENV VAR DESCRIPTION AWS_SECRETSMANAGER_ENDPOINT Endpoint for the Secrets Manager Service. The controller uses this endpoint to fetch secrets from AWS Secrets Manager. AWS_SSM_ENDPOINT Endpoint for the AWS Secure Systems Manager. The controller uses this endpoint to fetch secrets from SSM Parameter Store. AWS_STS_ENDPOINT Endpoint for the Security Token Service. The controller uses this endpoint when creating a session and when doing assumeRole or assumeRoleWithWebIdentity calls.","title":"Custom Endpoints"}]}